{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('numpy', '1.13.3')\n",
      "('pandas', u'0.20.3')\n",
      "('scipy', '0.18.1')\n",
      "('sklearn', '0.18.1')\n",
      "('lightgbm', '2.0.6')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm \n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lightgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!** There is a huge chance that the assignment will be impossible to pass if the versions of `lighgbm` and `scikit-learn` are wrong. The versions being tested:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    scipy 0.19.1\n",
    "    sklearn 0.19.0\n",
    "    ligthgbm 2.0.6\n",
    "    \n",
    "\n",
    "To install an older version of `lighgbm` you may use the following command:\n",
    "```\n",
    "pip uninstall lightgbm\n",
    "pip install lightgbm==2.0.6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment you are asked to implement two ensembling schemes: simple linear mix and stacking.\n",
    "\n",
    "We will spend several cells to load data and create feature matrix, you can scroll down this part or try to understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the hard drive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('./sales_train.csv.gz')\n",
    "shops = pd.read_csv('./shops.csv')\n",
    "items = pd.read_csv('./items.csv')\n",
    "item_cats = pd.read_csv('./item_categories.csv')\n",
    "test = pd.read_csv('./test.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use only 3 shops for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sales = sales[sales['shop_id'].isin([26, 27, 28])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to prepare the features. This part is all implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = []\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = sales[sales.item_price<100000]\n",
    "sales = sales[sales.item_cnt_day<=1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales_m = sales.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': 'sum','item_price': np.mean}).reset_index()\n",
    "sales_m = pd.merge(grid,sales_m,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "# adding the category id too\n",
    "sales_m = pd.merge(sales_m,items,on=['item_id'],how='left')\n",
    "\n",
    "for type_id in ['item_id','shop_id','item_category_id']:\n",
    "    for column_id,aggregator,aggtype in [('item_price',np.mean,'avg'),('item_cnt_day',np.sum,'sum'),('item_cnt_day',np.mean,'avg')]:\n",
    "\n",
    "        mean_df = sales_m.groupby([type_id,'date_block_num']).aggregate(aggregator).reset_index()[[column_id,type_id,'date_block_num']]\n",
    "        mean_df.columns = [type_id+'_'+aggtype+'_'+column_id,type_id,'date_block_num']\n",
    "\n",
    "        sales_m = pd.merge(sales_m,mean_df,on=['date_block_num',type_id],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_m = downcast_dtypes(sales_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_means = sales_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shop_id',\n",
       " 'item_id',\n",
       " 'date_block_num',\n",
       " 'item_price',\n",
       " 'item_cnt_day',\n",
       " 'item_name',\n",
       " 'item_category_id',\n",
       " 'item_id_avg_item_price',\n",
       " 'item_id_sum_item_cnt_day',\n",
       " 'item_id_avg_item_cnt_day',\n",
       " 'shop_id_avg_item_price',\n",
       " 'shop_id_sum_item_cnt_day',\n",
       " 'shop_id_avg_item_cnt_day',\n",
       " 'item_category_id_avg_item_price',\n",
       " 'item_category_id_sum_item_cnt_day',\n",
       " 'item_category_id_avg_item_cnt_day']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) for i in sales_m.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "lag_variables  = list(sales_m.columns[7:])+['item_cnt_day']\n",
    "lags = [1 ,2 ,3 ,4]#, 5, 12]\n",
    "sales_means = sales_m[['date_block_num','shop_id','item_id']]\n",
    "for lag in lags:\n",
    "    print(lag)\n",
    "    gc.collect()\n",
    "    sales_new_df = sales_m.copy()\n",
    "    sales_new_df.date_block_num+=lag\n",
    "    sales_new_df = sales_new_df[['date_block_num','shop_id','item_id']+lag_variables]\n",
    "    sales_new_df.columns = ['date_block_num','shop_id','item_id']+ [lag_feat+'_lag_'+str(lag) for lag_feat in lag_variables]\n",
    "    sales_means = pd.merge(sales_means, sales_new_df,on=['date_block_num','shop_id','item_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_block_num',\n",
       " 'shop_id',\n",
       " 'item_id',\n",
       " 'item_id_avg_item_price_lag_1',\n",
       " 'item_id_sum_item_cnt_day_lag_1',\n",
       " 'item_id_avg_item_cnt_day_lag_1',\n",
       " 'shop_id_avg_item_price_lag_1',\n",
       " 'shop_id_sum_item_cnt_day_lag_1',\n",
       " 'shop_id_avg_item_cnt_day_lag_1',\n",
       " 'item_category_id_avg_item_price_lag_1',\n",
       " 'item_category_id_sum_item_cnt_day_lag_1',\n",
       " 'item_category_id_avg_item_cnt_day_lag_1',\n",
       " 'item_cnt_day_lag_1',\n",
       " 'item_id_avg_item_price_lag_2',\n",
       " 'item_id_sum_item_cnt_day_lag_2',\n",
       " 'item_id_avg_item_cnt_day_lag_2',\n",
       " 'shop_id_avg_item_price_lag_2',\n",
       " 'shop_id_sum_item_cnt_day_lag_2',\n",
       " 'shop_id_avg_item_cnt_day_lag_2',\n",
       " 'item_category_id_avg_item_price_lag_2',\n",
       " 'item_category_id_sum_item_cnt_day_lag_2',\n",
       " 'item_category_id_avg_item_cnt_day_lag_2',\n",
       " 'item_cnt_day_lag_2',\n",
       " 'item_id_avg_item_price_lag_3',\n",
       " 'item_id_sum_item_cnt_day_lag_3',\n",
       " 'item_id_avg_item_cnt_day_lag_3',\n",
       " 'shop_id_avg_item_price_lag_3',\n",
       " 'shop_id_sum_item_cnt_day_lag_3',\n",
       " 'shop_id_avg_item_cnt_day_lag_3',\n",
       " 'item_category_id_avg_item_price_lag_3',\n",
       " 'item_category_id_sum_item_cnt_day_lag_3',\n",
       " 'item_category_id_avg_item_cnt_day_lag_3',\n",
       " 'item_cnt_day_lag_3',\n",
       " 'item_id_avg_item_price_lag_4',\n",
       " 'item_id_sum_item_cnt_day_lag_4',\n",
       " 'item_id_avg_item_cnt_day_lag_4',\n",
       " 'shop_id_avg_item_price_lag_4',\n",
       " 'shop_id_sum_item_cnt_day_lag_4',\n",
       " 'shop_id_avg_item_cnt_day_lag_4',\n",
       " 'item_category_id_avg_item_price_lag_4',\n",
       " 'item_category_id_sum_item_cnt_day_lag_4',\n",
       " 'item_category_id_avg_item_cnt_day_lag_4',\n",
       " 'item_cnt_day_lag_4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) for i in sales_means.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feat in sales_means.columns:\n",
    "    if 'item_cnt' in feat:\n",
    "        sales_means[feat]=sales_means[feat].fillna(0)\n",
    "    elif 'item_price' in feat:\n",
    "        sales_means[feat]=sales_means[feat].fillna(sales_means[feat].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = lag_variables[:-1] + ['item_name','item_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id_avg_item_price',\n",
       " 'item_id_sum_item_cnt_day',\n",
       " 'item_id_avg_item_cnt_day',\n",
       " 'shop_id_avg_item_price',\n",
       " 'shop_id_sum_item_cnt_day',\n",
       " 'shop_id_avg_item_cnt_day',\n",
       " 'item_category_id_avg_item_price',\n",
       " 'item_category_id_sum_item_cnt_day',\n",
       " 'item_category_id_avg_item_cnt_day',\n",
       " 'item_name',\n",
       " 'item_price']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_means = sales_means[sales_means['date_block_num']>12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales_means = pd.merge(sales_means, sales_m[['date_block_num','shop_id','item_id', 'item_cnt_day']], how='left', on=['date_block_num','shop_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sales_means[sales_means['date_block_num']<33].drop(['item_cnt_day'], axis=1)\n",
    "X_cv =  sales_means[sales_means['date_block_num']==33].drop(['item_cnt_day'], axis=1)\n",
    "\n",
    "y_train = sales_means[sales_means['date_block_num']<33]['item_cnt_day']\n",
    "y_cv =  sales_means[sales_means['date_block_num']==33]['item_cnt_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_clip = y_train.apply(lambda x: clip(x))\n",
    "y_cv_clip = y_cv.apply(lambda x: clip(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    if x>40:\n",
    "        return 40\n",
    "    elif x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sales_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_copy = test.copy()\n",
    "test_copy['date_block_num'] = 34\n",
    "test_copy.drop(['ID'], axis=1, inplace=True)\n",
    "all_data = pd.concat([all_data, test_copy], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = sales_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_2</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_3</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_4</th>\n",
       "      <th>item_category_id_avg_item_price_lag_1</th>\n",
       "      <th>item_category_id_avg_item_price_lag_2</th>\n",
       "      <th>item_category_id_avg_item_price_lag_3</th>\n",
       "      <th>item_category_id_avg_item_price_lag_4</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_2</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_3</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_4</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>item_cnt_day_lag_1</th>\n",
       "      <th>item_cnt_day_lag_2</th>\n",
       "      <th>item_cnt_day_lag_3</th>\n",
       "      <th>item_cnt_day_lag_4</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_2</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_3</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_4</th>\n",
       "      <th>item_id_avg_item_price_lag_1</th>\n",
       "      <th>item_id_avg_item_price_lag_2</th>\n",
       "      <th>item_id_avg_item_price_lag_3</th>\n",
       "      <th>item_id_avg_item_price_lag_4</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_2</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_3</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_4</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_2</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_3</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_4</th>\n",
       "      <th>shop_id_avg_item_price_lag_1</th>\n",
       "      <th>shop_id_avg_item_price_lag_2</th>\n",
       "      <th>shop_id_avg_item_price_lag_3</th>\n",
       "      <th>shop_id_avg_item_price_lag_4</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_2</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_3</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.230756</td>\n",
       "      <td>0.620661</td>\n",
       "      <td>0.248574</td>\n",
       "      <td>0.201398</td>\n",
       "      <td>108.913513</td>\n",
       "      <td>182.898499</td>\n",
       "      <td>111.920395</td>\n",
       "      <td>87.213722</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>3683.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15242</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>131.152176</td>\n",
       "      <td>288.717377</td>\n",
       "      <td>122.711113</td>\n",
       "      <td>264.873901</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.594017</td>\n",
       "      <td>0.534519</td>\n",
       "      <td>183.184814</td>\n",
       "      <td>212.3069</td>\n",
       "      <td>158.768341</td>\n",
       "      <td>148.077576</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>4805.0</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.341238</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413962</td>\n",
       "      <td>53.044178</td>\n",
       "      <td>98.276047</td>\n",
       "      <td>45.573895</td>\n",
       "      <td>72.221169</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15200</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>10.847826</td>\n",
       "      <td>10.847826</td>\n",
       "      <td>36.764706</td>\n",
       "      <td>54.239132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534519</td>\n",
       "      <td>183.184814</td>\n",
       "      <td>212.3069</td>\n",
       "      <td>101.088631</td>\n",
       "      <td>148.077576</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.230756</td>\n",
       "      <td>0.620661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.913513</td>\n",
       "      <td>182.898499</td>\n",
       "      <td>45.573895</td>\n",
       "      <td>45.573895</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>3683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15279</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>1.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.210510</td>\n",
       "      <td>404.673920</td>\n",
       "      <td>36.764706</td>\n",
       "      <td>38.020409</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>183.184814</td>\n",
       "      <td>212.3069</td>\n",
       "      <td>101.088631</td>\n",
       "      <td>100.791565</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.341238</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.413962</td>\n",
       "      <td>53.044178</td>\n",
       "      <td>98.276047</td>\n",
       "      <td>77.181686</td>\n",
       "      <td>72.221169</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15202</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>10.847826</td>\n",
       "      <td>65.086960</td>\n",
       "      <td>33.266666</td>\n",
       "      <td>32.543480</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.594017</td>\n",
       "      <td>0.534519</td>\n",
       "      <td>183.184814</td>\n",
       "      <td>212.3069</td>\n",
       "      <td>158.768341</td>\n",
       "      <td>148.077576</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>4805.0</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.292980</td>\n",
       "      <td>0.223598</td>\n",
       "      <td>0.225813</td>\n",
       "      <td>42.582104</td>\n",
       "      <td>53.034184</td>\n",
       "      <td>44.199959</td>\n",
       "      <td>44.495491</td>\n",
       "      <td>10216.0</td>\n",
       "      <td>16186.0</td>\n",
       "      <td>11541.0</td>\n",
       "      <td>11852.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14888</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.630435</td>\n",
       "      <td>214.826080</td>\n",
       "      <td>211.956528</td>\n",
       "      <td>280.600006</td>\n",
       "      <td>295.350555</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>0.942058</td>\n",
       "      <td>0.594017</td>\n",
       "      <td>0.534519</td>\n",
       "      <td>183.184814</td>\n",
       "      <td>212.3069</td>\n",
       "      <td>158.768341</td>\n",
       "      <td>148.077576</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>4805.0</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_category_id_avg_item_cnt_day_lag_1  \\\n",
       "0              13                                 0.230756   \n",
       "1              13                                 0.341238   \n",
       "2              13                                 0.230756   \n",
       "3              13                                 0.341238   \n",
       "4              13                                 0.204124   \n",
       "\n",
       "   item_category_id_avg_item_cnt_day_lag_2  \\\n",
       "0                                 0.620661   \n",
       "1                                 0.747283   \n",
       "2                                 0.620661   \n",
       "3                                 0.747283   \n",
       "4                                 0.292980   \n",
       "\n",
       "   item_category_id_avg_item_cnt_day_lag_3  \\\n",
       "0                                 0.248574   \n",
       "1                                 0.000000   \n",
       "2                                 0.000000   \n",
       "3                                 0.255556   \n",
       "4                                 0.223598   \n",
       "\n",
       "   item_category_id_avg_item_cnt_day_lag_4  \\\n",
       "0                                 0.201398   \n",
       "1                                 0.413962   \n",
       "2                                 0.000000   \n",
       "3                                 0.413962   \n",
       "4                                 0.225813   \n",
       "\n",
       "   item_category_id_avg_item_price_lag_1  \\\n",
       "0                             108.913513   \n",
       "1                              53.044178   \n",
       "2                             108.913513   \n",
       "3                              53.044178   \n",
       "4                              42.582104   \n",
       "\n",
       "   item_category_id_avg_item_price_lag_2  \\\n",
       "0                             182.898499   \n",
       "1                              98.276047   \n",
       "2                             182.898499   \n",
       "3                              98.276047   \n",
       "4                              53.034184   \n",
       "\n",
       "   item_category_id_avg_item_price_lag_3  \\\n",
       "0                             111.920395   \n",
       "1                              45.573895   \n",
       "2                              45.573895   \n",
       "3                              77.181686   \n",
       "4                              44.199959   \n",
       "\n",
       "   item_category_id_avg_item_price_lag_4  \\\n",
       "0                              87.213722   \n",
       "1                              72.221169   \n",
       "2                              45.573895   \n",
       "3                              72.221169   \n",
       "4                              44.495491   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_1  \\\n",
       "0                                   1295.0   \n",
       "1                                   1036.0   \n",
       "2                                   1295.0   \n",
       "3                                   1036.0   \n",
       "4                                  10216.0   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_2  \\\n",
       "0                                   3683.0   \n",
       "1                                   3025.0   \n",
       "2                                   3683.0   \n",
       "3                                   3025.0   \n",
       "4                                  16186.0   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_3  \\\n",
       "0                                   1264.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                    920.0   \n",
       "4                                  11541.0   \n",
       "\n",
       "   item_category_id_sum_item_cnt_day_lag_4  item_cnt_day  item_cnt_day_lag_1  \\\n",
       "0                                   1297.0           2.0                 1.0   \n",
       "1                                   1352.0           1.0                 0.0   \n",
       "2                                      0.0           2.0                 2.0   \n",
       "3                                   1352.0           1.0                 0.0   \n",
       "4                                  11852.0           1.0                 2.0   \n",
       "\n",
       "   item_cnt_day_lag_2  item_cnt_day_lag_3  item_cnt_day_lag_4  item_id  \\\n",
       "0                 1.0                 0.0                 1.0    15242   \n",
       "1                 0.0                 0.0                 1.0    15200   \n",
       "2                 3.0                 0.0                 0.0    15279   \n",
       "3                 0.0                 0.0                 0.0    15202   \n",
       "4                 0.0                 1.0                 1.0    14888   \n",
       "\n",
       "   item_id_avg_item_cnt_day_lag_1  item_id_avg_item_cnt_day_lag_2  \\\n",
       "0                        0.195652                        0.608696   \n",
       "1                        0.021739                        0.021739   \n",
       "2                        1.043478                        1.130435   \n",
       "3                        0.043478                        0.326087   \n",
       "4                        0.456522                        0.695652   \n",
       "\n",
       "   item_id_avg_item_cnt_day_lag_3  item_id_avg_item_cnt_day_lag_4  \\\n",
       "0                        0.222222                        0.695652   \n",
       "1                        0.000000                        0.173913   \n",
       "2                        0.000000                        0.000000   \n",
       "3                        0.111111                        0.086957   \n",
       "4                        0.977778                        1.630435   \n",
       "\n",
       "   item_id_avg_item_price_lag_1  item_id_avg_item_price_lag_2  \\\n",
       "0                    131.152176                    288.717377   \n",
       "1                     10.847826                     10.847826   \n",
       "2                    399.210510                    404.673920   \n",
       "3                     10.847826                     65.086960   \n",
       "4                    214.826080                    211.956528   \n",
       "\n",
       "   item_id_avg_item_price_lag_3  item_id_avg_item_price_lag_4  \\\n",
       "0                    122.711113                    264.873901   \n",
       "1                     36.764706                     54.239132   \n",
       "2                     36.764706                     38.020409   \n",
       "3                     33.266666                     32.543480   \n",
       "4                    280.600006                    295.350555   \n",
       "\n",
       "   item_id_sum_item_cnt_day_lag_1  item_id_sum_item_cnt_day_lag_2  \\\n",
       "0                             9.0                            28.0   \n",
       "1                             1.0                             1.0   \n",
       "2                            48.0                            52.0   \n",
       "3                             2.0                            15.0   \n",
       "4                            21.0                            32.0   \n",
       "\n",
       "   item_id_sum_item_cnt_day_lag_3  item_id_sum_item_cnt_day_lag_4  shop_id  \\\n",
       "0                            10.0                            32.0       27   \n",
       "1                             0.0                             8.0       27   \n",
       "2                             0.0                             0.0       27   \n",
       "3                             5.0                             4.0       27   \n",
       "4                            44.0                            75.0       27   \n",
       "\n",
       "   shop_id_avg_item_cnt_day_lag_1  shop_id_avg_item_cnt_day_lag_2  \\\n",
       "0                        0.721891                        0.942058   \n",
       "1                        0.721891                        0.942058   \n",
       "2                        0.721891                        0.942058   \n",
       "3                        0.721891                        0.942058   \n",
       "4                        0.721891                        0.942058   \n",
       "\n",
       "   shop_id_avg_item_cnt_day_lag_3  shop_id_avg_item_cnt_day_lag_4  \\\n",
       "0                        0.594017                        0.534519   \n",
       "1                        0.000000                        0.534519   \n",
       "2                        0.000000                        0.000000   \n",
       "3                        0.594017                        0.534519   \n",
       "4                        0.594017                        0.534519   \n",
       "\n",
       "   shop_id_avg_item_price_lag_1  shop_id_avg_item_price_lag_2  \\\n",
       "0                    183.184814                      212.3069   \n",
       "1                    183.184814                      212.3069   \n",
       "2                    183.184814                      212.3069   \n",
       "3                    183.184814                      212.3069   \n",
       "4                    183.184814                      212.3069   \n",
       "\n",
       "   shop_id_avg_item_price_lag_3  shop_id_avg_item_price_lag_4  \\\n",
       "0                    158.768341                    148.077576   \n",
       "1                    101.088631                    148.077576   \n",
       "2                    101.088631                    100.791565   \n",
       "3                    158.768341                    148.077576   \n",
       "4                    158.768341                    148.077576   \n",
       "\n",
       "   shop_id_sum_item_cnt_day_lag_1  shop_id_sum_item_cnt_day_lag_2  \\\n",
       "0                          5451.0                          7983.0   \n",
       "1                          5451.0                          7983.0   \n",
       "2                          5451.0                          7983.0   \n",
       "3                          5451.0                          7983.0   \n",
       "4                          5451.0                          7983.0   \n",
       "\n",
       "   shop_id_sum_item_cnt_day_lag_3  shop_id_sum_item_cnt_day_lag_4  \n",
       "0                          4805.0                          4297.0  \n",
       "1                             0.0                          4297.0  \n",
       "2                             0.0                             0.0  \n",
       "3                          4805.0                          4297.0  \n",
       "4                          4805.0                          4297.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-698378596cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#y_val = all_data.loc[all_data.date_block_num == m, 'target']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    517\u001b[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[1;32m    518\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             copy=self.copy_X, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n\u001b[0;32m--> 168\u001b[0;31m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test prediction\n",
    "m_last = 34\n",
    "to_drop_cols = ['item_cnt_day']\n",
    "X_train = all_data.loc[all_data.date_block_num < m_last].drop(to_drop_cols, axis=1)\n",
    "y_train = all_data.loc[all_data.date_block_num < m_last, 'item_cnt_day']\n",
    "\n",
    "X_test = all_data.loc[all_data.date_block_num == m_last].drop(to_drop_cols, axis=1)\n",
    "#y_val = all_data.loc[all_data.date_block_num == m, 'target']\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "train_r2_score = r2_score(y_train, y_train_pred)\n",
    "train_rmse_score = rmse(y_train, y_train_pred)\n",
    "#val_score[i] = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"month %d train r2-score=%f rmse-score=%f\" % (m_last, train_r2_score, train_rmse_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.9406485221446301, 'reg_lambda': 0.02832037687027189, 'colsample_bytree': 0.9328528564046081, 'gamma': 0.45657498433206656, 'max_depth': 12.0, 'min_child_weight': 9.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "\n",
    "reload(hp)\n",
    "\n",
    "def objective(space):\n",
    "    print(space)\n",
    "    clf = xgb.XGBRegressor(n_estimators =1000,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = .3,\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],)\n",
    "\n",
    "    eval_set  = [( X_train, y_train_clip), ( X_cv, y_cv_clip)]\n",
    "\n",
    "    clf.fit(X_train, y_train_clip,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = clf.predict(X_cv)\n",
    "    mse_scr = mean_squared_error(y_cv_clip, pred)\n",
    "    print \"SCORE:\", np.sqrt(mse_scr)\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse_scr, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.5),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\"\"\"\n",
    "\n",
    "dates = sales['date_block_num'].unique()\n",
    "#date_max = np.max(dates)\n",
    "# Add one more for test data\n",
    "#dates = np.append(dates, [date_max + 1])\n",
    "\n",
    "grid = []\n",
    "for block_num in dates:\n",
    "    #cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    #cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    #grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "    shop_item_unique_block_num = sales.loc[sales['date_block_num'] == block_num, ['shop_id', 'item_id']].drop_duplicates()\n",
    "    shop_item_unique_block_num['date_block_num'] = block_num\n",
    "    grid.append(shop_item_unique_block_num)\n",
    "grid = pd.concat(grid, axis=0)\n",
    "\"\"\"\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "# Fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "#del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item\n",
       "0       59    22154               0     1.0       2017.0         18.0\n",
       "1       59     2552               0     0.0       2017.0          0.0\n",
       "2       59     2554               0     0.0       2017.0          1.0\n",
       "3       59     2555               0     0.0       2017.0          2.0\n",
       "4       59     2564               0     0.0       2017.0          5.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id  date_block_num\n",
       "0   0        5     5037              34\n",
       "1   1        5     5320              34\n",
       "2   2        5     5233              34\n",
       "3   3        5     5232              34\n",
       "4   4        5     5268              34"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_copy = test.copy()\n",
    "test_copy['date_block_num'] = 34\n",
    "test_copy.drop(['ID'], axis=1, inplace=True)\n",
    "all_data = pd.concat([all_data, test_copy], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data shape before after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128050, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only necessary ship item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>target</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_shop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22154</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2552</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2554</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2555</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2564</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_id  shop_id  target  target_item  target_shop\n",
       "0               0    22154       59     1.0         18.0       2017.0\n",
       "1               0     2552       59     0.0          0.0       2017.0\n",
       "2               0     2554       59     0.0          1.0       2017.0\n",
       "3               0     2555       59     0.0          2.0       2017.0\n",
       "4               0     2564       59     0.0          5.0       2017.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a grid, we can calculate some features. We will use lags from [1, 2, 3, 4, 5, 12] months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "#shift_range = range(1, 13)\n",
    "\n",
    "import time\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    print month_shift\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "    time.sleep(.1)\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "    \n",
    "    del train_shift\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "#del train_shift\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end, we've created a feature matrix. It is stored in `all_data` variable. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921400, 25)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 33\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_item', 'target_shop', 'target', 'date_block_num']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_train = dates[dates <  last_block]\n",
    "dates_test  = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_test =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238172, 21)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935849, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given month m, use months 1 through m (excluding m) for training, and month m for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_3</th>\n",
       "      <th>target_item_lag_3</th>\n",
       "      <th>target_shop_lag_3</th>\n",
       "      <th>target_lag_4</th>\n",
       "      <th>target_item_lag_4</th>\n",
       "      <th>target_shop_lag_4</th>\n",
       "      <th>target_lag_5</th>\n",
       "      <th>target_item_lag_5</th>\n",
       "      <th>target_shop_lag_5</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>10297</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>10296</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>10298</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>10284</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0       54    10297              12     4.0       8198.0         23.0   \n",
       "1       54    10296              12     3.0       8198.0         17.0   \n",
       "2       54    10298              12    14.0       8198.0        182.0   \n",
       "3       54    10300              12     3.0       8198.0         26.0   \n",
       "4       54    10284              12     1.0       8198.0          3.0   \n",
       "\n",
       "   target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n",
       "0           3.0               42.0            10055.0           0.0   \n",
       "1           0.0                0.0                0.0           0.0   \n",
       "2          21.0              369.0            10055.0         119.0   \n",
       "3           1.0               54.0            10055.0          31.0   \n",
       "4           0.0                0.0                0.0           0.0   \n",
       "\n",
       "   target_item_lag_2  target_shop_lag_2  target_lag_3  target_item_lag_3  \\\n",
       "0                0.0                0.0           0.0                0.0   \n",
       "1                0.0                0.0           0.0                0.0   \n",
       "2             1309.0             7978.0           7.0              144.0   \n",
       "3              361.0             7978.0           0.0                0.0   \n",
       "4                0.0                0.0           0.0                0.0   \n",
       "\n",
       "   target_shop_lag_3  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n",
       "0                0.0           0.0                0.0                0.0   \n",
       "1                0.0           0.0                0.0                0.0   \n",
       "2             6676.0           0.0                0.0                0.0   \n",
       "3                0.0           0.0                0.0                0.0   \n",
       "4                0.0           0.0                0.0                0.0   \n",
       "\n",
       "   target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n",
       "0           0.0                0.0                0.0            0.0   \n",
       "1           0.0                0.0                0.0            0.0   \n",
       "2           0.0                0.0                0.0            0.0   \n",
       "3           0.0                0.0                0.0            0.0   \n",
       "4           0.0                0.0                0.0            0.0   \n",
       "\n",
       "   target_item_lag_12  target_shop_lag_12  item_category_id  \n",
       "0                 0.0                 0.0                37  \n",
       "1                 0.0                 0.0                38  \n",
       "2                 0.0                 0.0                40  \n",
       "3                 0.0                 0.0                37  \n",
       "4                 0.0                 0.0                57  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_item', 'target_shop', 'target', 'date_block_num']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33f48faa41ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_block_num\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drop_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_block_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drop_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_block_num\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_block_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = all_data.loc[all_data.date_block_num < m].drop(to_drop_cols, axis=1)\n",
    "X_val = all_data.loc[all_data.date_block_num == m].drop(to_drop_cols, axis=1)\n",
    "y_train = all_data.loc[all_data.date_block_num < m, 'target']\n",
    "y_val = all_data.loc[all_data.date_block_num == m, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34290, 21)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34290,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.615106, val score: 0.209080\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_val_pred = lr.predict(X_val)\n",
    "train_score = r2_score(y_train, y_train_pred)\n",
    "val_score = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"train score: %f, val score: %f\" % (train_score, val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_3</th>\n",
       "      <th>target_item_lag_3</th>\n",
       "      <th>target_shop_lag_3</th>\n",
       "      <th>target_lag_4</th>\n",
       "      <th>target_item_lag_4</th>\n",
       "      <th>target_shop_lag_4</th>\n",
       "      <th>target_lag_5</th>\n",
       "      <th>target_item_lag_5</th>\n",
       "      <th>target_shop_lag_5</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>target_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>10297</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>10296</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>10298</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>10284</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0       54    10297              12     4.0       8198.0         23.0   \n",
       "1       54    10296              12     3.0       8198.0         17.0   \n",
       "2       54    10298              12    14.0       8198.0        182.0   \n",
       "3       54    10300              12     3.0       8198.0         26.0   \n",
       "4       54    10284              12     1.0       8198.0          3.0   \n",
       "\n",
       "   target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n",
       "0           3.0               42.0            10055.0           0.0   \n",
       "1           0.0                0.0                0.0           0.0   \n",
       "2          21.0              369.0            10055.0         119.0   \n",
       "3           1.0               54.0            10055.0          31.0   \n",
       "4           0.0                0.0                0.0           0.0   \n",
       "\n",
       "   target_item_lag_2  target_shop_lag_2  target_lag_3  target_item_lag_3  \\\n",
       "0                0.0                0.0           0.0                0.0   \n",
       "1                0.0                0.0           0.0                0.0   \n",
       "2             1309.0             7978.0           7.0              144.0   \n",
       "3              361.0             7978.0           0.0                0.0   \n",
       "4                0.0                0.0           0.0                0.0   \n",
       "\n",
       "   target_shop_lag_3  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n",
       "0                0.0           0.0                0.0                0.0   \n",
       "1                0.0           0.0                0.0                0.0   \n",
       "2             6676.0           0.0                0.0                0.0   \n",
       "3                0.0           0.0                0.0                0.0   \n",
       "4                0.0           0.0                0.0                0.0   \n",
       "\n",
       "   target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n",
       "0           0.0                0.0                0.0            0.0   \n",
       "1           0.0                0.0                0.0            0.0   \n",
       "2           0.0                0.0                0.0            0.0   \n",
       "3           0.0                0.0                0.0            0.0   \n",
       "4           0.0                0.0                0.0            0.0   \n",
       "\n",
       "   target_item_lag_12  target_shop_lag_12  item_category_id  target_pred  \n",
       "0                 0.0                 0.0                37          5.7  \n",
       "1                 0.0                 0.0                38          2.2  \n",
       "2                 0.0                 0.0                40         14.5  \n",
       "3                 0.0                 0.0                37          5.4  \n",
       "4                 0.0                 0.0                57          1.0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320\n",
       "2   2        5     5233\n",
       "3   3        5     5232\n",
       "4   4        5     5268"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_data_merge = pd.merge(test, all_data, how='left', on=['shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "#pred_lgb = model.predict(X_test)\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "\n",
    "class LGB:\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = lgb.train(lgb_params, lgb.Dataset(X, label=y), 100)\n",
    "        return self.model\n",
    " \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LGB(lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "lr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
    "    max_depth=1, random_state=0, loss='ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y1, y2):\n",
    "    y1 = np.clip(y1, 0, 20)\n",
    "    return np.mean((y1-y2)**2)**0.5\n",
    "\n",
    "def r2_score_clipped(y1, y2):\n",
    "    y1 = np.clip(y1, 0, 20)\n",
    "    return r2_score(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month 16 train scores=(2.4047, -3.0175) val-scores=(2.0657, -2.3672)\n",
      "month 17 train scores=(2.3202, -2.8293) val-scores=(1.8467, -1.7224)\n",
      "month 18 train scores=(2.2886, -2.7930) val-scores=(1.9827, -2.7243)\n",
      "month 19 train scores=(2.2510, -2.7955) val-scores=(1.9858, -1.7849)\n",
      "month 20 train scores=(2.2513, -2.7687) val-scores=(2.2362, -2.3941)\n",
      "month 21 train scores=(2.2584, -2.7557) val-scores=(2.2945, -2.2351)\n",
      "month 22 train scores=(2.2889, -2.7829) val-scores=(2.4592, -2.4406)\n",
      "month 23 train scores=(2.3530, -2.9053) val-scores=(2.9049, -2.1592)\n",
      "month 24 train scores=(2.5560, -3.2848) val-scores=(3.5469, -7.1149)\n",
      "month 25 train scores=(2.5872, -3.3846) val-scores=(3.2464, -7.9949)\n",
      "month 26 train scores=(2.4726, -3.0641) val-scores=(2.2072, -3.1821)\n",
      "month 27 train scores=(2.3859, -2.8342) val-scores=(1.6715, -1.3377)\n",
      "month 28 train scores=(2.3578, -2.7816) val-scores=(2.6440, -4.9270)\n",
      "month 29 train scores=(2.3473, -2.7807) val-scores=(2.1418, -3.0832)\n",
      "month 30 train scores=(2.3260, -2.7471) val-scores=(1.6196, -1.6714)\n",
      "month 31 train scores=(2.3043, -2.7247) val-scores=(1.6548, -1.4252)\n",
      "month 32 train scores=(2.2862, -2.6943) val-scores=(1.8887, -1.6777)\n",
      "month 33 train scores=(2.2869, -2.7040) val-scores=(1.8749, -1.7232)\n",
      "train scores: [(2.4046943572552242, -3.0174935467289741), (2.3202154522650189, -2.8293027566303039), (2.2885974930009785, -2.7930435605317938), (2.2509668134378433, -2.7955335077432353), (2.2512770718437785, -2.7686618621244676), (2.2583753753427813, -2.7556641144642366), (2.2889024140546161, -2.782852020186207), (2.352962236343092, -2.90530155997291), (2.5559661498863573, -3.2847611622664674), (2.5871666602339309, -3.3846165173030158), (2.4726013952398795, -3.064143520620112), (2.3858536386677502, -2.8342083467408332), (2.3577763528986915, -2.7815926487340543), (2.3472925233793522, -2.7806867087671074), (2.3259804328576741, -2.7471173927716985), (2.3042501870699592, -2.7247304108857824), (2.286240205801279, -2.6943362464995912), (2.286888419304959, -2.7040178825618919)] \n",
      "\n",
      "val scores: [(2.0656941313498849, -2.3672110282510226), (1.8466630562009809, -1.722376991339047), (1.9827279782542171, -2.7242550895822228), (1.9857618200555733, -1.7848701308113148), (2.2362491999619478, -2.3940566407240582), (2.2944621618549057, -2.235089190704302), (2.4592046453910377, -2.4406376150007607), (2.9048872323052768, -2.159231618428445), (3.5468655269291918, -7.1148774341625263), (3.2464447668301228, -7.9948844012822597), (2.2072113746309587, -3.1820699474833143), (1.6714533436450449, -1.3376531910654244), (2.6439689307348235, -4.9269959497004114), (2.1418089998130161, -3.0831866852410057), (1.6196351031160736, -1.6714371885484991), (1.6548472558890983, -1.4252170822866974), (1.8887074412096605, -1.6777029390588982), (1.8748993919474954, -1.7232088170194428)]\n"
     ]
    }
   ],
   "source": [
    "#m_max = np.max(sales.date_block_num)\n",
    "#m_max = date_max\n",
    "m_max = 33\n",
    "m_vec = np.arange(m_max/2, m_max + 1)\n",
    "train_score = [0] * m_vec.shape[0] #np.zeros(m_vec.shape)\n",
    "val_score = [0] * m_vec.shape[0]#np.zeros(m_vec.shape)\n",
    "\n",
    "for i, m in enumerate(m_vec):\n",
    "    X_train = all_data.loc[all_data.date_block_num < m].drop(to_drop_cols, axis=1)\n",
    "    y_train = all_data.loc[all_data.date_block_num < m, 'target']\n",
    "    \n",
    "    X_val = all_data.loc[all_data.date_block_num == m].drop(to_drop_cols, axis=1)\n",
    "    y_val = all_data.loc[all_data.date_block_num == m, 'target']\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_train_pred = lr.predict(X_train)\n",
    "    y_val_pred = lr.predict(X_val)\n",
    "    train_score[i] = (rmse(y_train, y_train_pred), r2_score_clipped(y_train, y_train_pred))\n",
    "    val_score[i] = (rmse(y_val, y_val_pred), r2_score_clipped(y_val, y_val_pred))\n",
    "\n",
    "    print(\"month %d train scores=(%.4f, %.4f) val-scores=(%.4f, %.4f)\" % (m, train_score[i][0], train_score[i][1], \n",
    "                                                                val_score[i][0], val_score[i][1]))\n",
    "    \n",
    "print(\"train scores: %s \\n\\nval scores: %s\" % (str(train_score), str(val_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd7d8f1e710>,\n",
       " <matplotlib.lines.Line2D at 0x7fd7d8dfa110>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XecVNX9//HXmdnZXRZYei8CCqJi\nCayLRLHwVaNLjDGxl8QkSjRqNBpLbFGxd6OJJTHW/GKL0RgwGqJojO7CIkVAFARUOkjZwtaZz++P\nzwxb2D7tzuzn+XjMY+7M3HJ29s77nnvuufc6EcEYY0z68CW7AMYYY2LLgt0YY9KMBbsxxqQZC3Zj\njEkzFuzGGJNmLNiNMSbNWLAbY0yasWA3xpg0E7Ngd875nXPznXP/jNU8jTHGtF9GDOd1KfApkNva\niH379pURI0bEcNHGGJP+5s2bt0VE+rU2XkyC3Tk3FJgK3AZc3tr4I0aMoLi4OBaLNsaYTsM592Vb\nxotVU8yDwFVAqIUCTXPOFTvnijdv3hyjxRpjjGks6mB3zn0X2CQi81oaT0SeEJE8Ecnr16/VPQlj\njDEdFIsa+6HA95xzq4EXgCnOuedjMF9jjDEdEHWwi8hvRGSoiIwATgfeEZGzoy6ZMcaYDrF+7MYY\nk2Zi2d0REZkNzI7lPI0xxrSP1diNMSbNWLCbzmHVKvjd7+CjjyAYTHZpjImrmDbFGOM51dVw771w\n661QUaHv9e4N3/kOFBTos3W/NWnGauwmfc2eDQceCNddpyG+eDG88AKccAL85z9wzjkwYABMnAg3\n3wxz5kCo2XPsjEkZTkQSvtC8vDyxSwqYuNm0CX79a3juORg5Eh55RIO9vlAI5s+HmTP1UVQEIlp7\nj9Tmjz0W+vRJzt9gTBOcc/NEJK/V8SzYTdoIheCPf4RrroHycrjqKrj2WsjJaX3aLVvg7bfhzTfh\nX//S1z6f1uYLCuD44+Fb39L3jEkSC3bTucyfDxdeqDXvo46CP/wBxo7t2LyCQZg3T2vyb74Jc+dq\nbX7AADjuODj5ZPjud2NbfmPaoK3BbtUPk9pKSuCyyyAvT3u+PP+8tp93NNQB/H7Iz4ebbtINxYYN\n8OyzMGUKvPGGttHfemvM/gRjYs16xZjUJAIvvwy/+hWsXw8XXAC33Qa9esV+Wf3764HWc86B2lr4\n6U/hhhu0DDfcEPvlGRMlC3aTelasgIsvhrfe0nbvv/9da9iJkJEBTz0FzsGNN2q7/m9/m5hlG9NG\nFuwmdVRVwV13we23Q2YmPPQQ/OIXGraJ5PfDn/+s4X7TTVpzv+mmxJbBmBZYsJvUMGuWhvjy5XDa\naXD//TB4cPLK4/fDk09qL5mbb64Ld+eSVyZjwizYjbd9+inccoueWLTnntr8cuyxyS6V8vvhT3/S\nML/lFg33m2+2cDdJZ8FuvCcYhBkz4OGHtaaelaXt2NdcA9nZyS5dQz6f9p13DqZP1zb36dMt3E1S\nWbAb79i2TZs3/vAH7bo4ZIj2dDn/fG9fz8Xngyee0DC/7Tatud96q4W7SRoLdpN8n3yip/0/95xe\nqGvyZD1I+v3vQyCQ7NK1jc8Hjz+uz7ffruF+220W7iYpLNhNctTWwj/+oc0ts2drE8tZZ8Ell+iF\nu1KRzwePPqphfscd2ixzxx2pEe6hkJYzFcpqWmXBbhJryxY94Pjoo/DVVzB8ONx5J5x3nqcvuCUi\n1IaEqtoQDuia1cxPx+fTpiSfT/c6RPTv83JgbtmiZ9Nu2ABXXqknYHntWIZpFwt2kxgLFmjt/P/9\nP6is1Ou5PPigBkoc+6HXBEMs31jG4nU7+GJzGVU1Iapqg/ocDO16XV0boir8qK4Nhp8j7+nnoXqX\nVeqWlcHAHtkM6pHNwNzwc48u4edsBt3zAD0Ad/fdWhu++25vhvuaNdrLaNUqGDcOLrpID/5ecYWe\nzdutW7JLaDrAgt3ET02NnhX68MPwwQd6lcUf/1jPGh03LuaLq6wJ8un6EhavK2Hpuh0sXlvCZxtK\nqQ7qNdYz/T66ZPrJyvCRmeEjK8NHVoZ/13BulwCZfh9ZgchnDT+PTBcS2FhSyYYdlazfUcnyjVvY\nVFrZIPgBsnt/lzu+vZ6T7r2Xdz/dSPHFv2FgzxwG5Wr4D8jNpldOgAx/ki7ZtHw5HHMMbN2qV7Q8\n/HBtFrvtNq2533EHXHqpNo/F41INJm5S6uqOIoLzYq2nsxPRa6AvW6aPTz/V5/nz9f2RI7Um+NOf\nxiwgSitrWLpOQ3zJ2h0sWVfCis1lBMPp2jMnwLjBPdhvcC77DenBuMG5jOjTFZ8vPutPTTDE5tIq\n1u+IBH7FrueCP93J1Nmv8OTB32f6UT9rUHN3Dnp0CdCnayZ9umbRu2smvbtl0rdrZng4S4e7hV/n\nZMZmQ7BwoV53PhjUcwPGj2/4eWGhHgR+4w3o3l1PDvvVr/QKlyZp0vKyvdP/uZS/fbyG3l0z6dM1\nk145mfSJrPBds+jdNUDvrln6WXic7IA/Dn9BJ1Vbq7vsjQN82TLtqhiRk6NXV9xnHz1LtKBAT+bp\ngFBI2LqzWmvia0tYvG4HS9buYPU3O3eN0797FuPC4b3v4B6MG5LLkJ5dvFMJENErUP7ud5T/4mKW\nX30LG0oq2VhSxTfl1Wwtr2JreTVbyqrZWq6PbTurae6n2TMnsOs30LtrJrnZATLDexOZGT6y/HXD\nmX4fmRl+An63a8+j36JiDrzgbILdurPyL68ie48lM8OR4fPh9zl8PofPgd85MpYsput9d5P56iuQ\nlUXtT39G8PJf4/YYhs85/M6Fj7l65LtOc2kZ7G9+sp4Pv/iGreXVfFNexbbyGr4J/wiCjfeDw3Iy\n/eHgr/fIySS3S6De7rXunusu+O673ln1P/f7yQroDyZetb+kCoWgtFQvtNU4wJcv13uIRgwYoOE9\ndmxdkI8dC0OH7rohRXVtiNLKGkoqaympqKG0spaSypoWhvW5NDJ+VW2D4g3r3YX9Bml47zdEa+T9\nu6fAgT4RrfE+9JA2bzzwQItt7sGQsG2nhvw34cD/prxq17BuCHSDUFpZS3VQjwlEnptzxMp5PPb3\n21mX25dzTpvOutz+bSr+yK1rubDwZU5a8i6C49VxU3j0kJP5spde1sHnwO9zOOfI8Okj4PcR8PvI\n8Otwhs+R4feR6dfnyDiRzwN+3bhk+B0Bn49AeGMTiEzfaNrMDN+u8TPD88nw+XZtpHbNMzy+3+cI\n+B1+X6Qs4eX5HP7wMiPjeHVDlZbB3pxQSCiprNm1wn9TXs228PPWRsORR0VN9Heqz/SHNwABP9kB\nH9kBP13qDWdl6LC+V/d+dv3XGTrsj8FGwlVXEti2DX9pKf6yEvxlZfhLd5BRVoq/vIyMsjIySksI\nlJeSUV5GRlkpgbJSAjvLCJSXESgrIbCzHFdvnQj5/GwbOJRNQ0aycfAI1g3cgzWDRvB132Fsz+5W\n7yBkkOrwwcjq8OvIwcgWy+yge1YGuV0C5GYH6J69+3DPLgHGDuzOfoN70CMnRfq1N0UELr9cDxpf\ncomGfBwCRESoCUpd2IcfmX97mQEXnUfF2H1Z9ueX2NmzD9XBugPHwZAQDAkiEBQhJEIoJIRENzQh\nEXLWr2H/v/6RfWa8hC9Yy/IjCig8/eds3mM0IRGCIgSD2oOoJhiiJhiiNijUhITaYIiaoL5fG9Lh\n2mCI2pBQXavPDceRuunDrxPF59i10fCHN1RNhX1L+dncJ78/czyH7tW3Q+XqVMHeEbXB0K4gqusB\nEdzVCyISSk31moi8rgx/VlmjQVZRE6SyRl9Xht+v3PVe3fux+spzK8vIW7OU/K8Xk79mCeM2fEFm\nqLbFacoD2ZRl5VCWmUNpVg6lmTkNX4eHv+45gBV9hrGu92BcdtauPZfMBnsykV3+xgck68aNhHb3\n7AxyswMa2l0y6J4dIDc7g66ZGem559McEb0f6/33axfPe+6Bnj3jv9zHH9c7TE2erOcP9OgR3fw2\nbNC/4dFHoawMTjxRbxp+8MGxKW8TIl1Oa4J1G4XIRqD+hqDxZ8FQ3XNtSKgN6caiNvw6GJ42smHR\n5/Bn4Q1Qcy0C0PK2uamPzj5kD0YP6N6h7yBhwe6cGwY8CwxAN1JPiMhDLU3jhWBPFhHZtcHQ8NcN\nQqjlii0AGRvWk1P0ITlzPiKn6EOyli3FiSCBABUHTWDnxEnUDN8D6Z6L5IYf3XMhNxfpkYvr1h0y\nMna1ofqcw6Hto7teh9tLM8PttLHYkzCNiMBvfqP93Hv21KD/5S/1IGU83HmnLm/qVL05SZcusZv3\n1q3wu9/pY9s27WVz/fXaw8bEXFuDHRGJ6gEMAsaHh7sDnwP7tjTNhAkTpEPWrBHZsKFj06aaUEhk\n+XKRJ58UOfdckT33FNFIEOnaVeSYY0SmTxeZPVtk585kl9Z0xPz5IiecoP/TPn1E7r5bpLw8dvMP\nhUSuukrnf+aZItXVsZt3YyUlInfdJTJggC7vqKNE3nsvfsvrpIBiaUsut2Wk9jyA14FjWhqnw8F+\n8cVa5OHDRU4+WVekd9/VlSrVBYMiCxaIPPywyCmniAwcWBfkffqIfP/7IvfdJzJ3rkhNTbJLa2Kp\nqEjkO9/R//WAASIPPihSURHdPGtrRc47T+f5i1/o+pUIO3eKPPBA3fprAR9TbQ32mLaxO+dGAO8D\n40SkpLnxOtwUs2ABvPMOzJmjd45fuTKyYO2RkZ+vbXz5+XDAAXqXnViproYvv9TufitX6vOqVbBj\nRyR+dby6OG75df3hUEh7nWzfru8PG6ZtoYcfrs9jx+7qZWLS2Acf6D1UZ8/WK1tef732/W/velxV\nBWefDa+8ovO45ZbEn/VaUaHt+nfdpe3xRx2ll14+4ojEliPNJPzgqXOuG/AecJuIvNrE59OAaQDD\nhw+f8OWXX0a/0C1bNOAjQT9nDmzerJ9lZsJBB2nIRwJ/zJjmAzIU0psiRwK7fnivXAlr19YFcmT+\nI0boCTeRiydFfjzNvW7psxEjNMgPPxz22CP678akrnfe0YD/8ENdL264AX70o7ZdeqG8HH7wA3j7\nbbjvPu2Fk0wVFXpJ4zvvTO2A/+Yb3WBmZOg5GX5/3XDkOQGVr4QGu3MuAPwTeEtE7m9t/LgdPBXR\nWnX9sC8u1pUdIDcX8vI06Pv0aRjgq1frP67uj9Jbr40cCaNGNXweOVI/s1q0iRcRPSP0hht0HR49\nWgPx9NObP9lr2zY9QFpUpBda+8lPElvmlqRSwNfUaOvARx/p48MP9YJ1rXGu+dCvv0F4+mk48sgO\nFS2RvWIc8AywVUQua8s0Ce0VEwzqCTaRsJ8zBxYt0rMoe/WqC+r6oT1qlNaas7ISU0ZjmiOi3RNv\nvFHX23331Xur/vCHDSsW69frJQI++0xvI3jSSUkrcosaB/yRR+rfk8yA37ixLsQ/+kg3pBUV+tnQ\noTBpklYGu3fX3AgG657rD7f1vSuu0KbiDkhkr5jD0G6Oi4AF4UdBS9N0+OBprFRUiGzbltwyGNMe\nwaDISy+J7LOPHpk58ECR11/Xni9ffCEyapT2lpo1K9klbZudO/UgceQg65FHag+veKupEfn4Y5Hf\n/17krLP0e4sc7QoERCZOFLnsMpEXXxT56qv4l6edSMbB07bqzP3YjYlKMAh//aveNHvFCj12tGaN\nXgr5zTdh4sRkl7B9Kir0nrF33ql7HbGowYtoZ4eKCj15qn6zypw5dU2zgwZpbXzSJPj2t/VCaB6/\nDr2deWpMOquthWef1R4vNTXaHh+HSyEnTOOAP+IIDduKCt1oVVQ0P9z4vcrKhh0dQNu4DzqoYZAP\nH+7Na+S3wILdmM6gtlYfHq9ptlkk4O++Wy/5nJ2tZ8p26VI33J73cnK0K3Reng6nOAt2Y4xJM20N\nduuvZ4wxacaC3Rhj0owFuzHGpBkLdmOMSTMW7MYYk2Ys2I0xJs1YsBtjTJqxYDfGmDRjwW6MMWnG\ngt0YY9KMBbsxxqQZC3ZjjEkzFuzGGJNmLNiNMSbNWLAbY0yasWA3xpg0Y8FujDFpxoLdGGPSjAW7\nMcakGQt2Y4xJMxbsxhiTZizYjTEmzcQk2J1zxznnPnPOrXDOXROLeRpjjOmYqIPdOecHfg8cD+wL\nnOGc2zfa+RpjjOmYWNTY84EVIrJSRKqBF4ATYzBfY4wxHRCLYB8CfF3v9Zrwe8YYY5IgYQdPnXPT\nnHPFzrnizZs3J2qxxhjT6cQi2NcCw+q9Hhp+rwEReUJE8kQkr1+/fjFYrDHGmKbEItjnAqOdcyOd\nc5nA6cA/YjBfY4wxHZAR7QxEpNY5dzHwFuAH/iwiS6IumTHGmA6JOtgBRGQmMDMW8zLGGBMdO/PU\nGGPSjAW7McakGQt2Y4xJMxbsxhiTZizYjTEmzViwG2NMmrFgN8aYNGPBbowxacaC3Rhj0owFuzHG\npBkLdmOMSTMW7MYYk2Ys2I0xJs1YsBtjTJqxYDfGmDRjwW6MMWnGgt0YY9KMBbsxqeyhh+Dii5Nd\nCuMxFuzGpKpVq+Cqq+APf4AtW5JdGu/ZuBH++U9YuBCCwWSXJqFics9TY0wSXH011NaCCLz1Fpx1\nVrJLlDwisGIFfPAB/Pe/+rx8ed3nPXrAYYfB4YfrY/x4yMxMXnnjzILdmFT0wQfw8stwww3w+OMw\nc2bnCvbaWliwoGGQb9qkn/XuDYceCuefDxMnwldfwfvv63gzZug4XbrApEl1QT9xIuTkJO/viTEn\nIglfaF5enhQXFyd8ucakhVBIg2jdOvj8c7joInjjDQ02vz/ZpYuP8nIoKqoL8Y8+0vcARozQ2vhh\nh8HkyTB2LPiaaWXeuFGnf/99fSxcqLX9QADy8uqC/tBDtZbvMc65eSKS1+p4FuzGpJjnnoMf/Qie\neUafX3oJTjsN/vc/+Pa3k1262Ni2DWbPrquRf/yxtpM7BwccUBfkhx0GQ4d2fDnbt8OHH9YF/dy5\nujfgHBx0kG4oDj9cl9O/v76fRBbsLdmyBSoro1shjEmG8nLYe28YNEhrsD6fhlPfvtrmftttyS5h\n9NasgQkTdA8kK0v3TiIhPmkS9OwZv2Xv3AmFhboxef993TOoqNDPnIOuXZt+dOvW9s8OPFCbizqg\nrcHeudrYg0F49FG47jp9PXOm7nIl2zffaJtfGrXxmTi5915YuxZeeKGuuaFnT12PZ8xI/WCvrYUz\nz9QN2Ntva205Kytxy8/JgSlT9AFQXQ3z5mnYb92q5Yo8ysrqhjdv3v395irNb74Jxx0X1z+j8wR7\ncTFccIH+k449Flav1uc33qj7JybDe+/BiSdqsN91F5x9dvPtg6ZzW7sW7r4bTjlFa6/1TZ2qNfa1\na2HIkOSULxZuvllry889B8cck+zSaM+ZSZP00R4i2ipQf0MQCf0DDohPWRsuXzr8AO4BlgGLgL8D\nPdsy3YQJEyRhtm8XufhiEedEBg0SefFFkVBIZMMGkXHjRLKyRGbMSFx56nvlFV3+PvuI5OeLgMjE\niSJFRckpj/G2H/1IJDNTZOXK3T9bvFjXnyeeSHy5YmXWLP2dnntuskviWUCxtCWb2zJSsxPDsUBG\nePgu4K62TJeQYA+FRF54QWTgQBGfT+SSSzTk69uyRWTCBJFAQEM2kR55RFfib39b5JtvRIJBkaef\n1vKCrtzr1ye2TMa75s7V9eLqq5v+PBQSGT5c5PvfT2y5YmXDBpEBA0TGjhUpK0t2aTwrIcHeYEZw\nEvCXtowb92Bfvlzk2GP1z5swQX8Uzdm+XcPV7xd57rn4lktEf4DXXqtl+973RHbubPj5jh0iV12l\nG5vu3UXuuUekqir+5TLeFQqJHHaYSP/+un4058ILRbp2FamsTFzZYiEYFDnmGJHsbJFFi5JdGk9L\nRrC/AZzdwufTgGKgePjw4fH5qysrRW65RZs3cnO1Vlxb2/p0paUiU6ZoDfrxx+NTNhGR6mqRn/xE\nv/Zp00Rqapof97PPRKZO1XHHjElec5FJvpde0vWgtXXzjTd0vH//OzHlipXbb2/b32diF+zALGBx\nE48T641zXbiN3bVloXGpsf/nPxqAIHL66SLr1rVv+p07RQoKdPoHH4x9+crK6uZ/001aC2uLmTPr\n/q6CAg1803lUVIiMGCGy//6tV1LKy7VSc9lliSlbLHzwge4tn3Za238TnVjCauzAucBHQE5bp4lp\nsG/YIHL22fqn7LmnyFtvdXxeVVUiP/iBzuu222JXxs2b9eCozyfy2GMdK9e992rTTCAgcuWVLe+S\np4OdO/V/+etfi3z3uyKbNiW7RMlx5526Ps6a1bbxjztOZPTo+JYpVrZsERk2TGTUqPRfn2MkUQdP\njwOWAv3aM11Mgj0YFHn0UZGePbWnwI037t5e3RE1NXUbiuuui74WsWqV1rizs0X+/vfo5rV+fV1T\nzoABIk89pd9DLFRViSxdqmW87z7tPbR8eeJqUcGgyLx5GmT/939a8wStzYHIM88kphxesmGDbsxP\nOKHt0zz8sH5fn38ev3LFQiikx5gCgZaPgZkGEhXsK4CvgQXhx2NtmS7qYJ8/X7sFgraNL1sW3fwa\nCwZFzj9f53/ZZR0PtwULtJdLz54i//1v7Mo3Z47IIYdo+fLzRQoL2zZdKKRNVO++q3sOv/qVtuPv\ntVddgDZ+9OghcuSRIpdfLvKXv4h8+mnbjlu0xerVIn/8o8ipp4r06VO3zHHjtGwzZ4qUlGi4XXRR\nbJaZSqZNE8nIaF/z2xdfxK85MZYefFDL+cADyS5JSkn4wdP2PDoc7CUl+oP3+bSHwPPPx69GGQqJ\nXHqpfkU//3n7a8bvvKMHcIcO1T7GsRYMijz7rPbNB+3jHDmuUF6uG5UXX9SDyWedJZKXp+WpH9rZ\n2SIHHCByyiki11+v8ysq0qajjz/W0L3wQt14RGrQoD0vDj1U5Je/1C6aixa1fCA4Yvt23SP4xS+0\nuSAyv0GDtPzPPtv0sZEpU0QOPji235/XLVqk6/mll7Z/2rFjtVeYV82dqzX1733P2tXbKT2D/cwz\ntefKBReIbN3asXm0R/2uieec07bwEtFAzcwU2W8/ka+/jm8ZS0q0b3Nmpki3btqXuXGte9gwkaOP\n1lrv736nbderV7dvY1VdrWHz1FN6TsChh4rk5DTcSEycqBuCP/1JNwxlZSLvvy9yww26h+Hz1W0Y\nCgq0trZ4ces/7muu0SBItW58HRUK6f+rVy89x6G9rrhC14fS0tiXLVrbt2ub+rBhHfvbOrn0DPbP\nPxf56KOOTRuNW2/Vr+rkk1vvU/7QQ7rxmTw5MRufiOXLRX78Y62d33KLnpw1f358T/aordV2+eef\n1z2pI47QZpPGGxafT2v9110nMnt2+/vlv/qqzqeznJEb6bb40EMdm/4//9HpX389tuWKViikzW5+\nv/aGMe2WnsGeTA88oF/X1KnaBa2xUEhrziBy0kmxOZCbioJB3QC/8ILIb3+rZ/RGu4Fbs0a/14cf\njkkRPa26WmTvvfVRXd2xeVRV6QZ22rTYli1ajz+u/8fbb092SVJWW4O981wELFqXXaYX6rrwQjjh\nBHjtNb0EJ0BNDZx3Hjz7rF5o7JFH0veGB63x+WD0aH3EypAhMHgwzJkTu3l61aOPwmef6cXpAoGO\nzSMzUy+gNXOm7jMl+RriAHzyCVx6qZbr6quTXZq0Z5cRbI+f/1xvbvDOO/Cd78COHXq1thNO0FCf\nPl1vLNxZQz2e8vPTP9i3boWbboKjj9arNUZj6lS9rvknn8SkaFEpL4dTT9XLCz/3nF29NAGsxt5e\n55wD2dl6zeijj9ba0Lx58Mc/aq3dxEd+vu4lbd8e3xstJNPNN2tl4f77o69lH3+8Ps+YkZjLxLbk\n4ot1L+Tf/4YBA+K7rFAIQjUQrIZgTfhRBbXVUFvZaDj8XFsdfr+yhc+qdP4+Pzhf+BEe9vn1/1X/\nvV3v+8Kf1Xt/3+9BrxFx/Ros2DvilFO0Webkk7X28dprWmuPpVAovHLWe9RW1a2owerwStfo81AQ\nJAih2nrDwYbDuz4P1fu8NjwcAgnpSunPhIwsfd5tOBP8WeH3AuHh8GeR4YxsyOkL/hisZvn5+lxc\nrBvUdPPZZ7q3d/75sP/+0c9v0CAYP16bY37zm+bHC4WgphyqynQdaqDRjSKkqRtHNDFOKAi1Fbo+\nvvw6PP00/PxU6LcVPn4uHJhVdePsel0JNZV1r4NVEKzVcoVqGg1HHtW67kaCXIId+LKa4Qvo+h1Z\n70F/GxIK/45CDR8N3muhHAP2tWCPuaoy2LwMStaGV6KKeitTJdRUNP28a6WrN/4FfcEXgqWXwNJf\n6vydA1y9YfR1c8OR8SIrZ6SGEKpNzPcBdTUNn7/uOVSrP65ofyjOB90HQ4+hjR7D6oaze7ReQ80L\n3w1szpz0DPZf/1rv3nPLLe2brmQdbF0F1WVQVRp+LtPnvbvAi/+Dp86GrNqmx6kuZ7dwjpUtQXii\nHIb7of+b8Oq/mhjJQaBLOECzGz77w5WGzBwNWX+mVhL8meHXkUcm+MLv+wO7D++ab1ZdZaTxcFOf\nRdtkJNJ04Gd0iW6+bZC+wR4KwfbVsHFJ+LFYn7euosUV2Z+pX3xGFgSydTjynJkDOX3qXo/O1hVn\nV01GGg5D+HX94SbGEzRMd6sdh2vC9WvI/kDD8RrXpH0ZukL6MnYP6127h/7wePV2FZv9HoMt7C2E\n39tVu4oMh/cgaiqgdAPsWAM7voa1xbD0da1x1ZfZveXgzx2sd4wfOzY929lnzYJ//lPvoNW/f/Pj\n1VTC+oWwZg6smQtrirWC0pzufggJzP4vTBqm33O3/pA5CrK6QWb4ERnOyGJXZSNit3WjiXWl8Ti+\nDAj64Iwrods38MpfYNjwcMBmNwxwf8AbB3fjIdIE40v8Mbf0CPbKHbBxaV14b1wCm5ZqjQQAB71H\nwYBxcMDpMGA/6DkcAjmNwjs7Kf8ET/P5wddFa1WxEApB+aa6sN+xpt7ja1j3Mez8plEZAjD6WBgT\nvoGzV3p6xEIwCJdfDiNHaq+RCBHY/qWG95q58PUc2PBJ3Uax53AYfggMPRj6jYWs3Hph3VWfcfDq\nQAgdDhc8l9i/66KLYNlK3WDCDihAAAATSElEQVQdHOWBYNNuqRXsoSBsXVkX4BvCzzu+qhsnu6cG\n+EFnaYAPGAf9x+rKbpLP54PuA/UxtJmbrVfv1JpoJPg3LoUlr0LN17ChEp7+GUw5D4ZPSv2Af/JJ\n7bny1+dgfTjAI2FevknHCeTA4PEw6SIN8qEHQ/c2HoQ87ji9eXIwmLjeWn/7mx4vuOKK6Hv3mA5x\n0uQBkfjKy8uT4uLi9k/4+kUw/3kddn7oOyYc3uEAH7Cf7ran+o/d7C5YC68/Dj+8GM7oCWNCWms9\n4DTdC+u7V7JL2D4l62DRm3DCL6FvBpzlA0L6We89NbyHhUO8/34dPwD9wgtwxhnw0UdwyCExK36z\nVq2Cb30L9t5bb0qdmRn/ZXYizrl5ItJMjahOatXYDzwD9jhMA7zf3uE2QdMp+DNg6nmQeTkMPhdO\nmggLX4D/3gfv3wNDJmjAj/shdO2T7NLuTkT3NJfNhM9mwvoFMKsStlfDZYfD5GNgaL7+HbEs/7HH\n6l7SjBnxD3YR7Q4MukGxUE+a1KqxGzNxovYeefddfV2yHj55GRa9qMHpy4C9joEDT4Mxx+uxk2QJ\n1sDqD+CzN/Wx4yvAhZtS8uFH98DpZ+hJb/E0eTLs3KnnW8TTX/+q53c8+ST89KfxXVYn1dYauwW7\nSS2XXKL9ordv373NeMNiWPQCLHoZyjZAVg/Y70StyQ+flJgzHiu2w4pZWitfPguqduhB+VFHwdgC\nGP0dbR//1a/08gFffKGXTIinO+6Aa6+Fdeu0f3s8VFRo80vfvnqugZ1dGhfp2RRjTH6+Xotn2TLY\nb7+Gnw0cBwNvhaNvhlXvwcIX4ZO/wcfPQo/hGvK9RuqB224Dwo/+0Tfpbf8qXCufqTX0UK2emLXv\nCbB3gYZ6Zk7DaT78UJtG4h3qoAcwr71WD6LGqyZ9//3w9dd2yQCPsGA3qSVyBuqcObsHe4TPD3tO\n0Uf1/fDpP7Wp5qM/NH3CVZdedSHfbaA+Nwj/AVrLzu6pB+ZFtI38sze1zXxj+Hosfcdoz5W9p2qP\nn+a6zlZVwYIFemG5RNh/fxg6VNvZ4xHs69frXsEPfgBHHBH7+Zt2s2A3qWX0aD1Zac4c+MlPWh8/\ns6u2tx94mrZ5l2/RZpqyTXryVNmm8OuNULoRvi7S4drK3eflz9KQD1brNM4HwybCMdO1Zt7Wnjnz\n50N1dWJ6qYBujAoKtA28ujr2BzWvv16vcHr33bGdr+kwC3aTWnw+OPjgjp2B6g9A7iB9tEQEqko0\n6MsaPUo3alPLnlNgzHega9/2l6OwUJ8nTmz/tB01dSo88QR88AFMmRK7+X78MTz1lPZZ33PP2M3X\nRMWC3aSe/HytHVZU6MXYYs05vX5Ndg/oNyb28y8qgmHD9BrziTJlitbUZ8yIXbCL6Fmzffpord14\nhh3lMKknPx9qa7WdOhUVFiauGSaiWzc48ki92mOsvPYavPeeXrisR4/YzddEzYLdpJ76B1BTzcaN\nsHp1YpthIgoKtDfRypXRz6uqCq68Ug9gn39+9PMzMWXBblLPoEHayyMVg72oSJ8TXWOHuuu2xKLW\n/sgj2gf//vshw1p0vcaC3aSmVL1VXmGhBuH48Ylf9l57aa+iGTOim8/mzXobyIICvWSB8RwLdpOa\n8vNhxQq9T2gqKSqCAw+Mz0Hftpg6VS/HUF7e8XncdJPe6/fee2NWLBNbMQl259wVzjlxznWg75cx\nHRBpZ587N7nlaI9gUPcyktEMEzF1qraPR661015LlsBjj8GFF8I++8S2bCZmog5259ww4Fjgq9bG\nNSZmJkzQbomp1ByzdKnWdJNx4DRi8mTo2rXjzTFXXAG5uVprN54Vixr7A8BVxO3GicY0ITdXa4yp\nFOzJPHAakZUFxxyjB1DbewHAN9+Et96CG2/UvuvGs6IKdufcicBaEVnYhnGnOeeKnXPFmzdvjmax\nxqjIAdQkXKG0QwoLoXdvPYiZTAUF8NVX2qzSVjU1WlsfPVpve2c8rdVgd87Ncs4tbuJxInAtcGNb\nFiQiT4hInojk9evXL9pyG6PBvmmThlQqKCrSZphk3+GroECf29Mc88QT8OmnesDUbqDhea0Gu4gc\nLSLjGj+AlcBIYKFzbjUwFPjYOTcwvkU2JiyVTlQqKdEacjKbYSKGDNGeOW3tz75tG/z2t3opghNO\niG/ZTEx0uClGRD4Rkf4iMkJERgBrgPEisiFmpTOmJfvvr23GqRDsc+dqk1EyD5zWN3Uq/O9/Gtqt\nmT5du5Xef3/y9zZMm1g/dpO6MjP1xsmpEOyRA6eRvYxkKyjQ7pf//nfL4y1frmeZ/uxnWss3KSFm\nwR6uuW+J1fyMaZP8fL0VW21tskvSssJCvXVcr17JLok65BA9kNtaO/uVV+pe0fTpiSmXiQmrsZvU\nlp+vN2r+9NNkl6R5Ilpj90L7eoTfD8cdp10YQ6Gmx3n3XXj9db2t3kA7dJZKLNhNakuFA6irV2vv\nHS8FO2hzzObNusfTWDCoN9zeYw99NinFgt2ktr32gp49vR3sybhjUlscd5weDG2qOebpp2HhQr2h\nSXZ2wotmomPBblKbc96/0mNRkV70a//9k12Shvr00b2Ixt0eS0vhuuvg0EPhlFOSUzYTFQt2k/ry\n8+GTT7St3YsKCyEvz5vXLZ86VZtiNtTrpXzHHXpDkAcesO6NKcqC3aS+/HxtE54/P9kl2V1VlZbL\na+3rEZGzUP/1L31evVr7q599tt403KQkC3aT+iIB5MXmmAULoLrau8F+0EF6R6pIO/s114DPp7V2\nk7Is2E3qGzgQhg/3ZrB79cBphHNaa3/7bb0x9Ysvat/1oUOTXTITBQt2kx68egC1qEhDcsiQZJek\neVOn6rVsTj0VBg+Gq65KdolMlCzYTXrIz4eVK2GLx05+Liz0bm094uijIRDQvvZ33KE34jApzYLd\npAcv3ipv0yZYtcq77esR3bvD8cfDpEl60NSkPAt2kx4mTNCDfl5qjvHCHZPa6pVXYPZs/Q5NyvNg\nx1pjOqBbN9h3X28Fe2GhXpNl/Phkl6R1gUCyS2BiyDbPJn147VZ5RUV6qducnGSXxHQyFuwmfeTn\n68HT1auTXRI9YWrOHO8fODVpyYLdpA8vXelx2TK95koqtK+btGPBbtLHuHF6JUIvBHvkxCQLdpME\nFuwmfQQCeqDSK8HeqxeMHp3skphOyILdpJf8fJg3L/m3yisq0vZ1uzqiSQILdpNe8vOhogKWLEle\nGUpLYfFiO3BqksaC3aQXLxxALS7WLpfWvm6SxILdpJdRo6B37+QGe+TAaWQjY0yCWbCb9OKFW+UV\nFsKYMbqBMSYJLNhN+snP1zbu8vLEL1tED5xaM4xJIgt2k37y8yEUgo8/Tvyyv/xS7xdqB05NEkUd\n7M65S5xzy5xzS5xzd8eiUMZEJZm3yrMTk4wHRHV1R+fcUcCJwIEiUuWc6x+bYhkThf79YcSI5AR7\nURF06QL775/4ZRsTFm2N/ULgThGpAhCRTdEXyZgYSNYB1MJCvTa8XQbXJFG0wT4GmOycK3LOveec\nOzgWhTImavn5epXHTQmsa1RVwfz51gxjkq7Vphjn3CxgYBMfXReevjdwCHAw8JJzbpTI7hfEds5N\nA6YBDB8+PJoyG9O6+rfKmzo1MctcuFDD3Q6cmiRrtcYuIkeLyLgmHq8Da4BXRc0BQkDfZubzhIjk\niUhev379YvtXGNPY+PGJv1WeHTg1HhFtU8xrwFEAzrkxQCbgsdvEm06pa1e9jG8ig72oCIYMgaFD\nE7dMY5oQbbD/GRjlnFsMvAD8uKlmGGOSItG3yisstGYY4wlRBbuIVIvI2eGmmfEi8k6sCmZM1PLz\nYetWWLky/svavFmXY80wxgPszFOTvhJ5pceiIn22YDceYMFu0td+++nJQokI9sJC8Pu1D7sxSWbB\nbtJXRoYGbaJq7AccADk58V+WMa2wYDfpLT9fLwZWUxO/ZYRCuvGwA6fGIyzYTXrLz4fKSr2Mb7ws\nWwYlJda+bjzDgt2kt0QcQLUTk4zHWLCb9DZiBPTtG/9g79kTRo+O3zKMaQcLdpPeEnGrvKIibV/3\n2c/JeIOtiSb95efDkiVQWhr7eZeVafu9HTg1HmLBbtJffr5eViAet8orLtZeMda+bjzEgt2kv3je\nKi9y4DRykNYYD7BgN+mvb18YNSp+wT56NPTpE/t5G9NBFuymc4jHAVQRPXBqzTDGYyzYTeeQnw9f\nfQWzZ8dunl99BRs22IFT4zkW7KZzOOMMGDMGjj0WnnkmNvO0Kzoaj7JgN53DwIHaHj55Mpx7Lvzm\nN9qbJRqFhZCdrRf/MsZDLNhN59GrF/zrXzBtGtx5J5xyCpSXd3x+hYV69chAIHZlNCYGLNhN5xII\nwGOPwQMPwGuvweGHw9q17Z9PdbX2i7dmGONBFuym83EOLrsM/vEP+PxzPbA6b1775rFwIVRV2YFT\n40kW7KbzmjoVPvxQa/GTJ8Orr7Z9WjtwajzMgt10bvvvryF90EHwwx/CHXdo//TWFBbC4MEwdGj8\ny2hMO1mwGzNgALzzDpx5Jlx7rfaaqapqeZrCQm2GcS4hRTSmPSzYjQHttvj88zB9Ojz7LBx9NGze\n3PS4W7bAF19YM4zxLAt2YyKcg+uvhxdf1Ks2TpwIS5fuPl6kfd0OnBqPsmA3prFTT4X33oOKCpg0\nCd56q+HnRUV6U428vOSUz5hWRBXszrl859xc59wC51yxc86uXWrSQ+SiYSNHQkEBPPJI3WeFhXq2\nadeuySufMS2ItsZ+N3CjiBwE3Bh+bUx6GDYMPvgATjgBLrkELr5YT0yK3ArPGI+KNtg3ALnh4R7A\nuijnZ4y3dOum/duvugp+/3s49FAoKbEDp8bTMqKc/mrgf865e9GNxLejL5IxHuPzwV13wdix8POf\n63tWYzce1mqwO+dmAQOb+Og64BLgUhH5m3PuVOBJ4Ohm5jMNmAYwfPjwDhfYmKT5yU/0bknvvach\nb4xHOWnLWXbNTexcKZArIuKcc8AOEcltbbq8vDwpLi7u8HKNMaYzcs7NE5FWu2NF28a+AjgiPDwF\nWB7l/IwxxkQp2jb2acDvnXNZQGX4tTHGmCSKKthFZC5gfdeNMcZD7MxTY4xJMxbsxhiTZizYjTEm\nzViwG2NMmrFgN8aYNBPVCUodXqhzm4EvE77g9usLbEl2IdrJyhx/qVZesDInSrzLvIeI9GttpKQE\ne6pwzhW35SwvL7Eyx1+qlReszInilTJbU4wxxqQZC3ZjjEkzFuwteyLZBegAK3P8pVp5wcqcKJ4o\ns7WxG2NMmrEauzHGpJlOGezOuT875zY55xbXe+/F8E25FzjnVjvnFjQz7Wrn3CeRG3gnqLzDnHPv\nOueWOueWOOcuDb/f2zn3b+fc8vBzr2amP84595lzboVz7pokl/ke59wy59wi59zfnXM9m5neS9/z\nTc65tfXWj4JmpvfS9+zJ9dk5l+2cm+OcW+ic+9Q5d2f4fS+vy82V2bPrMiLS6R7A4cB4YHEzn9+H\n3qS7qc9WA30TXN5BwPjwcHfgc2Bf9Obh14Tfvwa4q4lp/cAXwCggE1gI7JvEMh8LZITfv6upMnvw\ne74J+HUr03rqe240jmfWZ8AB3cLDAaAImOzxdbm5Mnt2Xe6UNXYReR/Y2tRn4TtBnQr8NaGFaoGI\nrBeRj8PDpcCnwBDgROCZ8GjPAN9vYvJ8YIWIrBSRauCF8HRJKbOIvC0iteHRCoGh8S5LW7XwPbeF\np77nyOdeW59FlYVfBtCw3oa31+Umy+zldblTBnsrJgMbRaS5u0EJMMs5Ny98H9eEcs6NAL6F1hoG\niMj68EcbgAFNTDIE+Lre6zW0PaxiolGZ6/sp8GYzk3npewa4JLzL/edmmgm8+j17bn12zvnDTUOb\ngNkishiPr8vNlLk+T63LFuy7O4OWazeHichBwPHARc65wxNTLHDOdQP+BlwmIiX1PxPd5/NcF6fm\nyuycuw6oBf7SzKRe+p4fRXf/DwLWo00bntLCuuG59VlEguFlDgUmO+eOavS559bllsrsxXXZgr0e\n51wG8APgxebGEZG14edNwN9J0B2knHMB9If7FxF5Nfz2RufcoPDng9DaRGNrgWH1Xg8Nvxd3zZQZ\n59y5wHeBs8I/4t146XsWkY3hH3YI+GMzZfHi9+zZ9Tm8zO3ADCAPj6/LEY3K7Nl12YK9oaOBZSKy\npqkPnXNdnXPdI8PowZPGu2QxF24nfRL4VETur/fRP4Afh4d/DLzexORzgdHOuZHOuUzg9PB0cdVc\nmZ1zxwFXAd8TkZ3NTOup7zkSOGEnNVMWT33PYZ5bn51z/SK9R5xzXYBjgAV4e11ussxeXpcTdpTW\nSw9013Q9UIO20/0s/P7TwAWNxh0MzAwPj0KPxC8ElgDXJai8h6G7povQH8ECoADoA/wHWA7MAno3\nLnP4dQHaW+ILD5R5BdpOGnnvsRT4np8DPgm//w9gkNe/Z6+uz8ABwPzwMj8Brg6/7+V1ubkye3Zd\ntjNPjTEmzVhTjDHGpBkLdmOMSTMW7MYYk2Ys2I0xJs1YsBtjTJqxYDfGmDRjwW6MMWnGgt0YY9LM\n/wcna4wTXNGSNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7d8d8ad90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m_vec, train_score)\n",
    "plt.plot(m_vec, val_score, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month 34 train r2-score=0.453261 rmse-score=2.301218\n"
     ]
    }
   ],
   "source": [
    "#Test prediction\n",
    "m_last = 34\n",
    "X_train = all_data.loc[all_data.date_block_num < m_last].drop(to_drop_cols, axis=1)\n",
    "y_train = all_data.loc[all_data.date_block_num < m_last, 'target']\n",
    "\n",
    "X_test = all_data.loc[all_data.date_block_num == m_last].drop(to_drop_cols, axis=1)\n",
    "#y_val = all_data.loc[all_data.date_block_num == m, 'target']\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "train_r2_score = r2_score(y_train, y_train_pred)\n",
    "train_rmse_score = rmse(y_train, y_train_pred)\n",
    "#val_score[i] = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"month %d train r2-score=%f rmse-score=%f\" % (m_last, train_r2_score, train_rmse_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.595136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.101658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.234573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.118508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        0.595136\n",
       "1   1        0.101658\n",
       "2   2        0.955156\n",
       "3   3        0.234573\n",
       "4   4        0.118508"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submit = test.copy()\n",
    "test_submit['item_cnt_month'] = y_test_pred\n",
    "test_submit.drop(['shop_id', 'item_id'], axis=1, inplace=True)\n",
    "test_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.833267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.764578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.833267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.833267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.833267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        1.833267\n",
       "1   1        1.764578\n",
       "2   2        1.833267\n",
       "3   3        1.833267\n",
       "4   4        1.833267"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_submit.to_csv('submit_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement a basic stacking scheme. We have a time component here, so we will use ***scheme f)*** from the reading material. Recall, that we always use first level models to build two datasets: test meta-features and 2-nd level train-metafetures. Let's see how we get test meta-features first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firts, we will run *linear regression* on numeric columns and get predictions for the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for linreg is 0.258760\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(n_jobs=3)\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "\n",
    "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the we run *LightGBM*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.296426\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenate test predictions to get test meta-features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it is your turn to write the code**. You need to implement ***scheme f)*** from the reading material. Here, we will use duration **T** equal to month and **M=15**.  \n",
    "\n",
    "That is, you need to get predictions (meta-features) from *linear regression* and *LightGBM* for months 27, 28, 29, 30, 31, 32. Use the same parameters as in above models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
    "\n",
    "# That is how we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696174    27\n",
       "696175    27\n",
       "696176    27\n",
       "696177    27\n",
       "696178    27\n",
       "Name: date_block_num, dtype: int32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_train_level2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# And here we create 2nd level feeature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "lr_predict = []\n",
    "lgb_predict = []\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
    "    \n",
    "    print(cur_block_num)\n",
    "    \n",
    "    '''\n",
    "        1. Split `X_train` into parts\n",
    "           Remember, that corresponding dates are stored in `dates_train` \n",
    "        2. Fit linear regression \n",
    "        3. Fit LightGBM and put predictions          \n",
    "        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n",
    "           You can use `dates_train_level2` for it\n",
    "           Make sure the order of the meta-features is the same as in `X_test_level2`\n",
    "    '''      \n",
    "    X_train_level1 = X_train[dates_train < cur_block_num].values\n",
    "    y_train_level1 = y_train[dates_train < cur_block_num]\n",
    "    \n",
    "    X_train_cur = X_train[dates_train == cur_block_num].values\n",
    "    y_train_cur = y_train[dates_train == cur_block_num]\n",
    "    \n",
    "    lr.fit(X_train_level1, y_train_level1)\n",
    "    lr_predict.append(lr.predict(X_train_cur))\n",
    "\n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train_level1, label=y_train_level1), 100)\n",
    "    lgb_predict.append(model.predict(X_train_cur))\n",
    "    \n",
    "X_train_level2 = np.column_stack([np.concatenate(lr_predict, axis=0), np.concatenate(lgb_predict, axis=0)])\n",
    "\n",
    "# Sanity check\n",
    "#assert np.all(np.isclose(X_train_level2.mean(axis=0), [ 1.50148988,  1.38811989]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.22833413,  2.16345193])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31640942,  0.29100849])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[range(10), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[np.ones((3,)), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((3,)), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.row_stack([np.ones((3,)), np.ones((3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([np.ones((3,)), np.ones((3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((3, 1)), np.ones((3, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the ensembles work best, when first level models are diverse. We can qualitatively analyze the diversity by examinig *scatter plot* between the two metafeatures. Plot the scatter plot below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fed0eb13350>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAFkCAYAAACemWn9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOlBJ29apmoQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed0ea78c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "plt.scatter(X_train_level2[:, 0], X_train_level2[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the meta-features are created, we can ensemble our first level models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple convex mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with simple linear convex mix:\n",
    "\n",
    "$$\n",
    "mix= \\alpha\\cdot\\text{linreg_prediction}+(1-\\alpha)\\cdot\\text{lgb_prediction}\n",
    "$$\n",
    "\n",
    "We need to find an optimal $\\alpha$. And it is very easy, as it is feasible to do grid search. Next, find the optimal $\\alpha$ out of `alphas_to_try` array. Remember, that you need to use train meta-features (not test) when searching for $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.202020; Corresponding r2 score on train: 0.271253\n"
     ]
    }
   ],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 100)\n",
    "\n",
    "r2_scores = np.zeros(alphas_to_try.shape)\n",
    "# YOUR CODE GOES HERE\n",
    "for i, alpha in enumerate(alphas_to_try):\n",
    "    pred_train_level2 = X_train_level2.dot(np.array([alpha, 1-alpha]).reshape(2, 1)) \n",
    "    r2_scores[i] = r2_score(y_train_level2, pred_train_level2)\n",
    "best_alpha = alphas_to_try[np.argmax(r2_scores)]\n",
    "r2_train_simple_mix = np.max(r2_scores)\n",
    "\n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the $\\alpha$ you've found to compute predictions for the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for simple mix is 0.292831\n"
     ]
    }
   ],
   "source": [
    "test_preds = X_test_level2.dot(np.array([best_alpha, 1-best_alpha]).reshape(2, 1))\n",
    "r2_test_simple_mix = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Test R-squared for simple mix is %f' % r2_test_simple_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try a more advanced ensembling technique. Fit a linear regression model to the meta-features. Use the same parameters as in the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute R-squared on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for stacking is 0.271640\n",
      "Test  R-squared for stacking is 0.298013\n"
     ]
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train_level2)\n",
    "r2_train_stacking = r2_score(y_train_level2, train_preds)\n",
    "\n",
    "test_preds = lr.predict(X_test_level2)\n",
    "r2_test_stacking = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
    "print('Test  R-squared for stacking is %f' % r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12059072,  0.9346969 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, that the score turned out to be lower than in previous method. Although the model is very simple (just 3 parameters) and, in fact, mixes predictions linearly, it looks like it managed to overfit. **Examine and compare** train and test scores for the two methods. \n",
    "\n",
    "And of course this particular case does not mean simple mix is always better than stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all done! Submit everything we need to the grader now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task best_alpha is: 0.7647\n",
      "Current answer for task r2_train_simple_mix is: 0.62725506463\n",
      "Current answer for task r2_test_simple_mix is: 0.781177285514\n",
      "Current answer for task r2_train_stacking is: 0.632175561459\n",
      "Current answer for task r2_test_stacking is: 0.771297132342\n"
     ]
    }
   ],
   "source": [
    "from grader import Grader\n",
    "grader = Grader()\n",
    "\n",
    "grader.submit_tag('best_alpha', best_alpha)\n",
    "\n",
    "grader.submit_tag('r2_train_simple_mix', r2_train_simple_mix)\n",
    "grader.submit_tag('r2_test_simple_mix',  r2_test_simple_mix)\n",
    "\n",
    "grader.submit_tag('r2_train_stacking', r2_train_stacking)\n",
    "grader.submit_tag('r2_test_stacking',  r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these numbers:\n",
      "Task best_alpha: 0.7647\n",
      "Task r2_train_simple_mix: 0.62725506463\n",
      "Task r2_test_simple_mix: 0.781177285514\n",
      "Task r2_train_stacking: 0.632175561459\n",
      "Task r2_test_stacking: 0.771297132342\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = 'amnasri@gmail.com'\n",
    "STUDENT_TOKEN = 'O3dfSMV7L3TlAHPT'\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {
    "58236ccc24b44b8f8b1e6b9743fb7cfe": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
