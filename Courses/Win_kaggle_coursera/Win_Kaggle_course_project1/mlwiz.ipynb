{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('./sales_train.csv.gz')\n",
    "shops = pd.read_csv('./shops.csv')\n",
    "items = pd.read_csv('./items.csv')\n",
    "item_cats = pd.read_csv('./item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "# Fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "#del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = sales[sales.item_price<100000]\n",
    "sales = sales[sales.item_cnt_day<=1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales_m = sales.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': 'sum','item_price': np.mean}).reset_index()\n",
    "sales_m = pd.merge(grid, sales_m, on=['date_block_num','shop_id','item_id'], how='left').fillna(0)\n",
    "# adding the category id too\n",
    "sales_m = pd.merge(sales_m, items, on=['item_id'], how='left')\n",
    "\n",
    "for type_id in ['item_id','shop_id','item_category_id']:\n",
    "    for column_id,aggregator,aggtype in [('item_price',np.mean,'avg'),('item_cnt_day',np.sum,'sum'),('item_cnt_day',np.mean,'avg')]:\n",
    "\n",
    "        mean_df = sales_m.groupby([type_id,'date_block_num']).aggregate(aggregator).reset_index()[[column_id,type_id,'date_block_num']]\n",
    "        mean_df.columns = [type_id+'_'+aggtype+'_'+column_id,type_id,'date_block_num']\n",
    "\n",
    "        sales_m = pd.merge(sales_m,mean_df,on=['date_block_num',type_id],how='left')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_m = downcast_dtypes(sales_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lag_variables  = list(sales_m.columns[7:])+['item_cnt_day']\n",
    "lags = [1 ,2 ,3]# ,4, 5, 12]\n",
    "for lag in lags:\n",
    "    sales_new_df = sales_m.copy()\n",
    "    sales_new_df.date_block_num+=lag\n",
    "    sales_new_df = sales_new_df[['date_block_num','shop_id','item_id']+lag_variables]\n",
    "    sales_new_df.columns = ['date_block_num','shop_id','item_id']+ [lag_feat+'_lag_'+str(lag) for lag_feat in lag_variables]\n",
    "    sales_m = pd.merge(sales_m, sales_new_df,on=['date_block_num','shop_id','item_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_means = sales_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat in sales_means.columns:\n",
    "    if 'item_cnt' in feat:\n",
    "        sales_means[feat]=sales_means[feat].fillna(0)\n",
    "    elif 'item_price' in feat:\n",
    "        sales_means[feat]=sales_means[feat].fillna(sales_means[feat].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = lag_variables[:-1] + ['item_name','item_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sales_means[sales_means['date_block_num']<33].drop(cols_to_drop, axis=1)\n",
    "X_cv =  sales_means[sales_means['date_block_num']==33].drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def clip(x):\n",
    "    if x>40:\n",
    "        return 40\n",
    "    elif x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "X_train['item_cnt_day'] = X_train.apply(lambda x: clip(x['item_cnt_day']),axis=1)\n",
    "X_cv['item_cnt_day'] = X_cv.apply(lambda x: clip(x['item_cnt_day']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'shop_id', u'item_id', u'date_block_num', u'item_price',\n",
       "       u'item_cnt_day', u'item_name', u'item_category_id',\n",
       "       u'item_id_avg_item_price', u'item_id_sum_item_cnt_day',\n",
       "       u'item_id_avg_item_cnt_day', u'shop_id_avg_item_price',\n",
       "       u'shop_id_sum_item_cnt_day', u'shop_id_avg_item_cnt_day',\n",
       "       u'item_category_id_avg_item_price',\n",
       "       u'item_category_id_sum_item_cnt_day',\n",
       "       u'item_category_id_avg_item_cnt_day', u'item_id_avg_item_price_lag_1',\n",
       "       u'item_id_sum_item_cnt_day_lag_1', u'item_id_avg_item_cnt_day_lag_1',\n",
       "       u'shop_id_avg_item_price_lag_1', u'shop_id_sum_item_cnt_day_lag_1',\n",
       "       u'shop_id_avg_item_cnt_day_lag_1',\n",
       "       u'item_category_id_avg_item_price_lag_1',\n",
       "       u'item_category_id_sum_item_cnt_day_lag_1',\n",
       "       u'item_category_id_avg_item_cnt_day_lag_1', u'item_cnt_day_lag_1',\n",
       "       u'item_id_avg_item_price_lag_2', u'item_id_sum_item_cnt_day_lag_2',\n",
       "       u'item_id_avg_item_cnt_day_lag_2', u'shop_id_avg_item_price_lag_2',\n",
       "       u'shop_id_sum_item_cnt_day_lag_2', u'shop_id_avg_item_cnt_day_lag_2',\n",
       "       u'item_category_id_avg_item_price_lag_2',\n",
       "       u'item_category_id_sum_item_cnt_day_lag_2',\n",
       "       u'item_category_id_avg_item_cnt_day_lag_2', u'item_cnt_day_lag_2',\n",
       "       u'item_id_avg_item_price_lag_3', u'item_id_sum_item_cnt_day_lag_3',\n",
       "       u'item_id_avg_item_cnt_day_lag_3', u'shop_id_avg_item_price_lag_3',\n",
       "       u'shop_id_sum_item_cnt_day_lag_3', u'shop_id_avg_item_cnt_day_lag_3',\n",
       "       u'item_category_id_avg_item_price_lag_3',\n",
       "       u'item_category_id_sum_item_cnt_day_lag_3',\n",
       "       u'item_category_id_avg_item_cnt_day_lag_3', u'item_cnt_day_lag_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_means.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = sales_means[sales_means['date_block_num']<33]['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cv = sales_means[sales_means['date_block_num']==33]['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(X_train, open('X_train.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
