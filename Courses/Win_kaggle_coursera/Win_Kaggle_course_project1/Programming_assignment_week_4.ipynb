{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('numpy', '1.13.3')\n",
      "('pandas', u'0.18.1')\n",
      "('scipy', '1.0.0')\n",
      "('sklearn', '0.18.1')\n",
      "('lightgbm', '2.0.6')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm \n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lightgbm]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!** There is a huge chance that the assignment will be impossible to pass if the versions of `lighgbm` and `scikit-learn` are wrong. The versions being tested:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    scipy 0.19.1\n",
    "    sklearn 0.19.0\n",
    "    ligthgbm 2.0.6\n",
    "    \n",
    "\n",
    "To install an older version of `lighgbm` you may use the following command:\n",
    "```\n",
    "pip uninstall lightgbm\n",
    "pip install lightgbm==2.0.6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment you are asked to implement two ensembling schemes: simple linear mix and stacking.\n",
    "\n",
    "We will spend several cells to load data and create feature matrix, you can scroll down this part or try to understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the hard drive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('./sales_train.csv.gz')\n",
    "shops = pd.read_csv('./shops.csv')\n",
    "items = pd.read_csv('./items.csv')\n",
    "item_cats = pd.read_csv('./item_categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use only 3 shops for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = sales[sales['shop_id'].isin([26, 27, 28])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0  02.01.2013               0       59    22154      999.00           1.0\n",
       "1  03.01.2013               0       25     2552      899.00           1.0\n",
       "2  05.01.2013               0       25     2552      899.00          -1.0\n",
       "3  06.01.2013               0       25     2554     1709.05           1.0\n",
       "4  15.01.2013               0       25     2555     1099.00           1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to prepare the features. This part is all implemented for you."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 77,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\"\"\"\n",
    "grid = []\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    #cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    #cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    #grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "    shop_item_unique_block_num = sales.loc[sales['date_block_num'] == block_num, ['shop_id', 'item_id']].drop_duplicates()\n",
    "    shop_item_unique_block_num['date_block_num'] = block_num\n",
    "    grid.append(shop_item_unique_block_num)\n",
    "grid = pd.concat(grid, axis=0)\n",
    "\"\"\"\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "# Fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data shape before after:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 76,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1609124, 6)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10913850, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only necessary ship item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = [] \n",
    "n = 0\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    #cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    #cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    #grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "    shop_item_unique_block_num = sales.loc[sales['date_block_num'] == block_num, ['shop_id', 'item_id']].drop_duplicates()\n",
    "    shop_item_unique_block_num['date_block_num'] = block_num\n",
    "    grid.append(shop_item_unique_block_num)\n",
    "grid = pd.concat(grid, axis=0)\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "#grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1609124, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item\n",
       "0       59    22154               0     1.0       2017.0         18.0\n",
       "1       59     2552               0     0.0       2017.0          0.0\n",
       "2       59     2554               0     0.0       2017.0          1.0\n",
       "3       59     2555               0     0.0       2017.0          2.0\n",
       "4       59     2564               0     0.0       2017.0          5.0"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 7,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shop_id', 'item_id', 'date_block_num']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a grid, we can calculate some features. We will use lags from [1, 2, 3, 4, 5, 12] months ago."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "import time\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    print month_shift\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "    time.sleep(.1)\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "    \n",
    "    del train_shift\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "#del train_shift\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end, we've created a feature matrix. It is stored in `all_data` variable. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_3</th>\n",
       "      <th>target_item_lag_3</th>\n",
       "      <th>target_shop_lag_3</th>\n",
       "      <th>target_lag_4</th>\n",
       "      <th>target_item_lag_4</th>\n",
       "      <th>target_shop_lag_4</th>\n",
       "      <th>target_lag_5</th>\n",
       "      <th>target_item_lag_5</th>\n",
       "      <th>target_shop_lag_5</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>10297</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>10296</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>10298</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>10284</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8198.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6676.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0       54    10297              12     4.0       8198.0         23.0   \n",
       "1       54    10296              12     3.0       8198.0         17.0   \n",
       "2       54    10298              12    14.0       8198.0        182.0   \n",
       "3       54    10300              12     3.0       8198.0         26.0   \n",
       "4       54    10284              12     1.0       8198.0          3.0   \n",
       "\n",
       "   target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n",
       "0           3.0               42.0            10055.0           0.0   \n",
       "1           0.0               24.0            10055.0           0.0   \n",
       "2          21.0              369.0            10055.0         119.0   \n",
       "3           1.0               54.0            10055.0          31.0   \n",
       "4           0.0                4.0            10055.0           0.0   \n",
       "\n",
       "   target_item_lag_2  target_shop_lag_2  target_lag_3  target_item_lag_3  \\\n",
       "0                2.0             7978.0           0.0                0.0   \n",
       "1                0.0                0.0           0.0                0.0   \n",
       "2             1309.0             7978.0           7.0              144.0   \n",
       "3              361.0             7978.0           0.0               53.0   \n",
       "4                3.0             7978.0           0.0                5.0   \n",
       "\n",
       "   target_shop_lag_3  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n",
       "0                0.0           0.0                0.0                0.0   \n",
       "1                0.0           0.0                0.0                0.0   \n",
       "2             6676.0           0.0                0.0                0.0   \n",
       "3             6676.0           0.0                0.0                0.0   \n",
       "4             6676.0           0.0                3.0             7827.0   \n",
       "\n",
       "   target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n",
       "0           0.0                0.0                0.0            0.0   \n",
       "1           0.0                0.0                0.0            0.0   \n",
       "2           0.0                0.0                0.0            0.0   \n",
       "3           0.0                0.0                0.0            0.0   \n",
       "4           0.0               10.0             7792.0            0.0   \n",
       "\n",
       "   target_item_lag_12  target_shop_lag_12  item_category_id  \n",
       "0                 0.0                 0.0                37  \n",
       "1                 0.0                 0.0                38  \n",
       "2                 0.0                 0.0                40  \n",
       "3                 0.0                 0.0                37  \n",
       "4                 0.0                 0.0                57  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921400, 25)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 25)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 33,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of the programming assignment, let's artificially split the data into train and test. We will treat last month data as the test set."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 66,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 33\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 67,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_train = dates[dates <  last_block]\n",
    "dates_test  = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_test =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238172, 21)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935849, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement a basic stacking scheme. We have a time component here, so we will use ***scheme f)*** from the reading material. Recall, that we always use first level models to build two datasets: test meta-features and 2-nd level train-metafetures. Let's see how we get test meta-features first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firts, we will run *linear regression* on numeric columns and get predictions for the last month."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 68,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for linreg is 0.258760\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(n_jobs=3)\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "\n",
    "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the we run *LightGBM*."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 69,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.296426\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenate test predictions to get test meta-features."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 70,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_level2 = np.c_[pred_lr, pred_lgb] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it is your turn to write the code**. You need to implement ***scheme f)*** from the reading material. Here, we will use duration **T** equal to month and **M=15**.  \n",
    "\n",
    "That is, you need to get predictions (meta-features) from *linear regression* and *LightGBM* for months 27, 28, 29, 30, 31, 32. Use the same parameters as in above models."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 71,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
    "\n",
    "# That is how we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 72,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696174    27\n",
       "696175    27\n",
       "696176    27\n",
       "696177    27\n",
       "696178    27\n",
       "Name: date_block_num, dtype: int32"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 72,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_train_level2.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 73,
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "28\n"
     ]
<<<<<<< HEAD
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dac50b4f7c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlr_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_level1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mlgb_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
=======
>>>>>>> 5c57623c906d6f9fdee7b6135b809a8cb2f909a9
    }
   ],
   "source": [
    "# And here we create 2nd level feeature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "lr_predict = []\n",
    "lgb_predict = []\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
    "    \n",
    "    print(cur_block_num)\n",
    "    \n",
    "    '''\n",
    "        1. Split `X_train` into parts\n",
    "           Remember, that corresponding dates are stored in `dates_train` \n",
    "        2. Fit linear regression \n",
    "        3. Fit LightGBM and put predictions          \n",
    "        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n",
    "           You can use `dates_train_level2` for it\n",
    "           Make sure the order of the meta-features is the same as in `X_test_level2`\n",
    "    '''      \n",
    "    X_train_level1 = X_train[dates_train < cur_block_num].values\n",
    "    y_train_level1 = y_train[dates_train < cur_block_num]\n",
    "    \n",
    "    X_train_cur = X_train[dates_train == cur_block_num].values\n",
    "    y_train_cur = y_train[dates_train == cur_block_num]\n",
    "    \n",
    "    lr.fit(X_train_level1, y_train_level1)\n",
    "    lr_predict.append(lr.predict(X_train_cur))\n",
    "\n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train_level1, label=y_train_level1), 100)\n",
    "    lgb_predict.append(model.predict(X_train_cur))\n",
    "    \n",
    "X_train_level2 = np.column_stack([np.concatenate(lr_predict, axis=0), np.concatenate(lgb_predict, axis=0)])\n",
    "\n",
    "# Sanity check\n",
    "#assert np.all(np.isclose(X_train_level2.mean(axis=0), [ 1.50148988,  1.38811989]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.22833413,  2.16345193])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31640942,  0.29100849])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_level2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[range(10), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[np.ones((3,)), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((3,)), np.ones((3,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.row_stack([np.ones((3,)), np.ones((3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([np.ones((3,)), np.ones((3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((3, 1)), np.ones((3, 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the ensembles work best, when first level models are diverse. We can qualitatively analyze the diversity by examinig *scatter plot* between the two metafeatures. Plot the scatter plot below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fed0eb13350>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAFkCAYAAACemWn9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOlBJ29apmoQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed0ea78c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "plt.scatter(X_train_level2[:, 0], X_train_level2[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the meta-features are created, we can ensemble our first level models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple convex mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with simple linear convex mix:\n",
    "\n",
    "$$\n",
    "mix= \\alpha\\cdot\\text{linreg_prediction}+(1-\\alpha)\\cdot\\text{lgb_prediction}\n",
    "$$\n",
    "\n",
    "We need to find an optimal $\\alpha$. And it is very easy, as it is feasible to do grid search. Next, find the optimal $\\alpha$ out of `alphas_to_try` array. Remember, that you need to use train meta-features (not test) when searching for $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.202020; Corresponding r2 score on train: 0.271253\n"
     ]
    }
   ],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 100)\n",
    "\n",
    "r2_scores = np.zeros(alphas_to_try.shape)\n",
    "# YOUR CODE GOES HERE\n",
    "for i, alpha in enumerate(alphas_to_try):\n",
    "    pred_train_level2 = X_train_level2.dot(np.array([alpha, 1-alpha]).reshape(2, 1)) \n",
    "    r2_scores[i] = r2_score(y_train_level2, pred_train_level2)\n",
    "best_alpha = alphas_to_try[np.argmax(r2_scores)]\n",
    "r2_train_simple_mix = np.max(r2_scores)\n",
    "\n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the $\\alpha$ you've found to compute predictions for the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for simple mix is 0.292831\n"
     ]
    }
   ],
   "source": [
    "test_preds = X_test_level2.dot(np.array([best_alpha, 1-best_alpha]).reshape(2, 1))\n",
    "r2_test_simple_mix = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Test R-squared for simple mix is %f' % r2_test_simple_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try a more advanced ensembling technique. Fit a linear regression model to the meta-features. Use the same parameters as in the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_level2, y_train_level2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute R-squared on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for stacking is 0.271640\n",
      "Test  R-squared for stacking is 0.298013\n"
     ]
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train_level2)\n",
    "r2_train_stacking = r2_score(y_train_level2, train_preds)\n",
    "\n",
    "test_preds = lr.predict(X_test_level2)\n",
    "r2_test_stacking = r2_score(y_test, test_preds)\n",
    "\n",
    "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
    "print('Test  R-squared for stacking is %f' % r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12059072,  0.9346969 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, that the score turned out to be lower than in previous method. Although the model is very simple (just 3 parameters) and, in fact, mixes predictions linearly, it looks like it managed to overfit. **Examine and compare** train and test scores for the two methods. \n",
    "\n",
    "And of course this particular case does not mean simple mix is always better than stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all done! Submit everything we need to the grader now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task best_alpha is: 0.7647\n",
      "Current answer for task r2_train_simple_mix is: 0.62725506463\n",
      "Current answer for task r2_test_simple_mix is: 0.781177285514\n",
      "Current answer for task r2_train_stacking is: 0.632175561459\n",
      "Current answer for task r2_test_stacking is: 0.771297132342\n"
     ]
    }
   ],
   "source": [
    "from grader import Grader\n",
    "grader = Grader()\n",
    "\n",
    "grader.submit_tag('best_alpha', best_alpha)\n",
    "\n",
    "grader.submit_tag('r2_train_simple_mix', r2_train_simple_mix)\n",
    "grader.submit_tag('r2_test_simple_mix',  r2_test_simple_mix)\n",
    "\n",
    "grader.submit_tag('r2_train_stacking', r2_train_stacking)\n",
    "grader.submit_tag('r2_test_stacking',  r2_test_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these numbers:\n",
      "Task best_alpha: 0.7647\n",
      "Task r2_train_simple_mix: 0.62725506463\n",
      "Task r2_test_simple_mix: 0.781177285514\n",
      "Task r2_train_stacking: 0.632175561459\n",
      "Task r2_test_stacking: 0.771297132342\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = 'amnasri@gmail.com'\n",
    "STUDENT_TOKEN = 'O3dfSMV7L3TlAHPT'\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "58236ccc24b44b8f8b1e6b9743fb7cfe": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
