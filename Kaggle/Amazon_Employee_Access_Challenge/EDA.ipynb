{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA.ipynb  main.py  ro-2018-05-18.html\ttest.csv  train.csv  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION,RESOURCE,MGR_ID,ROLE_ROLLUP_1,ROLE_ROLLUP_2,ROLE_DEPTNAME,ROLE_TITLE,ROLE_FAMILY_DESC,ROLE_FAMILY,ROLE_CODE\r\n",
      "1,39353,85475,117961,118300,123472,117905,117906,290919,117908\r\n",
      "1,17183,1540,117961,118343,123125,118536,118536,308574,118539\r\n",
      "1,36724,14457,118219,118220,117884,117879,267952,19721,117880\r\n",
      "1,36135,5396,117961,118343,119993,118321,240983,290919,118322\r\n",
      "1,42680,5905,117929,117930,119569,119323,123932,19793,119325\r\n",
      "0,45333,14561,117951,117952,118008,118568,118568,19721,118570\r\n",
      "1,25993,17227,117961,118343,123476,118980,301534,118295,118982\r\n",
      "1,19666,4209,117961,117969,118910,126820,269034,118638,126822\r\n",
      "1,31246,783,117961,118413,120584,128230,302830,4673,128231\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "      <td>32769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.942110</td>\n",
       "      <td>42923.916171</td>\n",
       "      <td>25988.957979</td>\n",
       "      <td>116952.627788</td>\n",
       "      <td>118301.823156</td>\n",
       "      <td>118912.779914</td>\n",
       "      <td>125916.152644</td>\n",
       "      <td>170178.369648</td>\n",
       "      <td>183703.408893</td>\n",
       "      <td>119789.430132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.233539</td>\n",
       "      <td>34173.892702</td>\n",
       "      <td>35928.031650</td>\n",
       "      <td>10875.563591</td>\n",
       "      <td>4551.588572</td>\n",
       "      <td>18961.322917</td>\n",
       "      <td>31036.465825</td>\n",
       "      <td>69509.462130</td>\n",
       "      <td>100488.407413</td>\n",
       "      <td>5784.275516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4292.000000</td>\n",
       "      <td>23779.000000</td>\n",
       "      <td>4674.000000</td>\n",
       "      <td>117879.000000</td>\n",
       "      <td>4673.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "      <td>117880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20299.000000</td>\n",
       "      <td>4566.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>118102.000000</td>\n",
       "      <td>118395.000000</td>\n",
       "      <td>118274.000000</td>\n",
       "      <td>117906.000000</td>\n",
       "      <td>118363.000000</td>\n",
       "      <td>118232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>35376.000000</td>\n",
       "      <td>13545.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>118300.000000</td>\n",
       "      <td>118921.000000</td>\n",
       "      <td>118568.000000</td>\n",
       "      <td>128696.000000</td>\n",
       "      <td>119006.000000</td>\n",
       "      <td>118570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>74189.000000</td>\n",
       "      <td>42034.000000</td>\n",
       "      <td>117961.000000</td>\n",
       "      <td>118386.000000</td>\n",
       "      <td>120535.000000</td>\n",
       "      <td>120006.000000</td>\n",
       "      <td>235280.000000</td>\n",
       "      <td>290919.000000</td>\n",
       "      <td>119348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>312153.000000</td>\n",
       "      <td>311696.000000</td>\n",
       "      <td>311178.000000</td>\n",
       "      <td>286791.000000</td>\n",
       "      <td>286792.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>311867.000000</td>\n",
       "      <td>308574.000000</td>\n",
       "      <td>270691.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACTION       RESOURCE         MGR_ID  ROLE_ROLLUP_1  \\\n",
       "count  32769.000000   32769.000000   32769.000000   32769.000000   \n",
       "mean       0.942110   42923.916171   25988.957979  116952.627788   \n",
       "std        0.233539   34173.892702   35928.031650   10875.563591   \n",
       "min        0.000000       0.000000      25.000000    4292.000000   \n",
       "25%        1.000000   20299.000000    4566.000000  117961.000000   \n",
       "50%        1.000000   35376.000000   13545.000000  117961.000000   \n",
       "75%        1.000000   74189.000000   42034.000000  117961.000000   \n",
       "max        1.000000  312153.000000  311696.000000  311178.000000   \n",
       "\n",
       "       ROLE_ROLLUP_2  ROLE_DEPTNAME     ROLE_TITLE  ROLE_FAMILY_DESC  \\\n",
       "count   32769.000000   32769.000000   32769.000000      32769.000000   \n",
       "mean   118301.823156  118912.779914  125916.152644     170178.369648   \n",
       "std      4551.588572   18961.322917   31036.465825      69509.462130   \n",
       "min     23779.000000    4674.000000  117879.000000       4673.000000   \n",
       "25%    118102.000000  118395.000000  118274.000000     117906.000000   \n",
       "50%    118300.000000  118921.000000  118568.000000     128696.000000   \n",
       "75%    118386.000000  120535.000000  120006.000000     235280.000000   \n",
       "max    286791.000000  286792.000000  311867.000000     311867.000000   \n",
       "\n",
       "         ROLE_FAMILY      ROLE_CODE  \n",
       "count   32769.000000   32769.000000  \n",
       "mean   183703.408893  119789.430132  \n",
       "std    100488.407413    5784.275516  \n",
       "min      3130.000000  117880.000000  \n",
       "25%    118363.000000  118232.000000  \n",
       "50%    119006.000000  118570.000000  \n",
       "75%    290919.000000  119348.000000  \n",
       "max    308574.000000  270691.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return len(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4292</td>\n",
       "      <td>23779</td>\n",
       "      <td>4674</td>\n",
       "      <td>117879</td>\n",
       "      <td>4673</td>\n",
       "      <td>3130</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1</td>\n",
       "      <td>312153</td>\n",
       "      <td>311696</td>\n",
       "      <td>311178</td>\n",
       "      <td>286791</td>\n",
       "      <td>286792</td>\n",
       "      <td>311867</td>\n",
       "      <td>311867</td>\n",
       "      <td>308574</td>\n",
       "      <td>270691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7518</td>\n",
       "      <td>4243</td>\n",
       "      <td>128</td>\n",
       "      <td>177</td>\n",
       "      <td>449</td>\n",
       "      <td>343</td>\n",
       "      <td>2358</td>\n",
       "      <td>67</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "min       0         0      25           4292          23779           4674   \n",
       "max       1    312153  311696         311178         286791         286792   \n",
       "0         2      7518    4243            128            177            449   \n",
       "\n",
       "     ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "min      117879              4673         3130     117880  \n",
       "max      311867            311867       308574     270691  \n",
       "0           343              2358           67        343  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train.agg([min, max]).T, train.agg(f).to_frame()], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]\n",
    "X_test = test.iloc[:, 1:]\n",
    "\n",
    "X_total = pd.concat([X_train, X_test])\n",
    "\n",
    "X_total_ohe = ohe.fit_transform(X_total)\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "X_train_ohe = X_total_ohe[:n_train,]\n",
    "\n",
    "X_test_ohe = X_total_ohe[n_train:,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train_ohe, y_train)\n",
    "y_test_pred = clf.predict_proba(X_test_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=58921, step=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58921, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_submission_file(y_test_pred, filename=None):\n",
    "    submit_data = pd.DataFrame(columns=['ID', 'ACTION'])\n",
    "    submit_data['ID'] = xrange(1, len(y_test_pred)+1)\n",
    "    submit_data['ACTION'] = y_test_pred\n",
    "    if not filename:\n",
    "        filename = 'submit.csv'\n",
    "    submit_data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,ACTION\r\n",
      "1,0.0529831286064\r\n",
      "2,0.0404562637596\r\n",
      "3,0.0154604194242\r\n",
      "4,0.0252211356251\r\n",
      "5,1.07708565389e-05\r\n",
      "6,0.0231035286149\r\n",
      "7,0.0319142620812\r\n",
      "8,0.0061057089802\r\n",
      "9,0.0978558668646\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 submit.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87096568528451179]\n",
      "[0.87096568528451179, 0.84609594095940976]\n",
      "[0.87096568528451179, 0.84609594095940976, 0.85444967764640689]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "roc_auc_scores = [] \n",
    "for train_ind, cv_ind in KFold(X_train.shape[0]):\n",
    "    X_tr = X_train_ohe[train_ind]\n",
    "    y_tr = y_train[train_ind]\n",
    "    \n",
    "    X_cv = X_train_ohe[cv_ind]\n",
    "    y_cv = y_train[cv_ind]\n",
    "    \n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_cv_pred = clf.predict_proba(X_cv)\n",
    "    roc_auc_scores.append(roc_auc_score(y_cv, y_cv_pred[:, 1]))\n",
    "    print roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86976734,  0.84749794,  0.8581708 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = LogisticRegression(C=3)\n",
    "clf = gs.best_estimator_\n",
    "cross_val_score(clf, X_train_ohe, y_train, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"C\": np.logspace(0, 1, 10)}\n",
    "gs = GridSearchCV(clf, param_grid=param_grid, scoring=scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.     ,   1.29155,   1.6681 ,   2.15443,   2.78256,   3.59381,\n",
       "         4.64159,   5.99484,   7.74264,  10.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function scoring at 0x7f15c2fc05f0>, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.1544346900318838, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 16961)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEYCAYAAACk+XocAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15c05fee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, scoring=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, scoring=scoring, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "#estimator = SVC(gamma=0.01)\n",
    "#plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "#estimator = LogisticRegression(C=1)\n",
    "#estimator = gs.best_estimator_\n",
    "estimator = LogisticRegression(C=3, solver='newton-cg', max_iter=20)# class_weight = 'balanced')\n",
    "\n",
    "\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred[:, 1])\n",
    "   \n",
    "plot_learning_curve(estimator, title, X_train_ohe, y_train, \n",
    "                    scoring=scoring, n_jobs=4, cv=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 16961)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_xgb, X_cv_xgb, y_train_xgb, y_cv_xgb = train_test_split(X_train_ohe, y_train, test_size=0.33)\n",
    "train_xgb = xgb.DMatrix( X_train_xgb, y_train_xgb )\n",
    "cv_xgb = xgb.DMatrix( X_cv_xgb, y_cv_xgb )\n",
    "#Test = xgb.DMatrix( test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTrain-auc:0.540515\tVal-auc:0.526688\n",
      "Multiple eval metrics have been passed: 'Val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until Val-auc hasn't improved in 10 rounds.\n",
      "[24]\tTrain-auc:0.732082\tVal-auc:0.68053\n",
      "[ 0.96280175  0.96280175  0.94146627 ...,  0.96280175  0.96280175\n",
      "  0.96280175]\n",
      "score 0.514 params {'eval_metric': 'auc', 'alpha': '0.007', 'booster': 'gbtree', 'colsample_bytree': '0.654', 'silent': True, 'nthread': 8, 'min_child_weight': 24, 'subsample': '0.510', 'eta': '0.269', 'objective': 'reg:linear', 'max_depth': 3, 'gamma': '0.100', 'lambda': '0.213'}\n",
      "[0]\tTrain-auc:0.616261\tVal-auc:0.597113\n",
      "Multiple eval metrics have been passed: 'Val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until Val-auc hasn't improved in 10 rounds.\n",
      "[24]\tTrain-auc:0.733133\tVal-auc:0.710024\n",
      "[ 0.97754544  0.94048434  0.94472992 ...,  0.97354716  0.95231754\n",
      "  0.98525077]\n",
      "score 0.514 params {'eval_metric': 'auc', 'alpha': '0.256', 'booster': 'gbtree', 'colsample_bytree': '0.510', 'silent': True, 'nthread': 8, 'min_child_weight': 189, 'subsample': '0.821', 'eta': '0.703', 'objective': 'reg:linear', 'max_depth': 8, 'gamma': '0.188', 'lambda': '0.213'}\n",
      "[0]\tTrain-auc:0.62492\tVal-auc:0.609767\n",
      "Multiple eval metrics have been passed: 'Val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until Val-auc hasn't improved in 10 rounds.\n",
      "[24]\tTrain-auc:0.733593\tVal-auc:0.694806\n",
      "[ 0.97960407  0.90348899  0.9581033  ...,  0.97401065  0.9511112   0.9892875 ]\n",
      "score 0.510 params {'eval_metric': 'auc', 'alpha': '0.170', 'booster': 'gbtree', 'colsample_bytree': '0.781', 'silent': True, 'nthread': 8, 'min_child_weight': 169, 'subsample': '0.650', 'eta': '0.855', 'objective': 'reg:linear', 'max_depth': 6, 'gamma': '0.129', 'lambda': '0.192'}\n",
      "{'colsample_bytree': 0.7813452404103349, 'learning_rate': 0.8546734014893486, 'min_child_weight': 169.1972033113578, 'subsample': 0.6504913466226052, 'alpha': 0.1699830132319771, 'max_depth': 6.0, 'gamma': 0.12930614397840928, 'lambda': 0.19215351680360374}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def objective(params):\n",
    "    \n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'silent': True,\n",
    "        'nthread': 8,\n",
    "        \n",
    "        'eta': \"{:.3f}\".format(params['eta']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'min_child_weight': int(params['min_child_weight']),\n",
    "        'subsample': \"{:.3f}\".format(params['subsample']),        \n",
    "        'colsample_bytree': \"{:.3f}\".format(params['colsample_bytree']),\n",
    "        'lambda': \"{:.3f}\".format(params['lambda']),\n",
    "        'alpha': \"{:.3f}\".format(params['alpha']),\n",
    "          \n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'auc'\n",
    "        \n",
    "    }\n",
    "\n",
    "    watchlist = [(train_xgb, 'Train'), (cv_xgb, 'Val')]\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        train_xgb,\n",
    "        25,\n",
    "        evals=watchlist,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=100 )\n",
    "    \n",
    "    \n",
    "\n",
    "    y_cv_xgb_pred = model.predict(cv_xgb)\n",
    "    #score = np.sqrt( mean_squared_error(val['target'].clip(0, 20), y_pred.clip(0, 20)))\n",
    "    print(y_cv_xgb_pred)\n",
    "    score = roc_auc_score(y_cv, y_cv_xgb_pred)\n",
    "    #score = 1\n",
    "                    \n",
    "    print(\"score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'eta': hp.uniform('learning_rate', 0.01, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.5),'gamma': hp.uniform('gamma', 0.0, 0.3),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 12, 1),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 1, 200),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),    \n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'lambda': hp.uniform('lambda', 0.0, 0.3),\n",
    "    'alpha': hp.uniform('alpha', 0.0, 0.3),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=3)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_cv(X_train, y_train, random_state=0):\n",
    "    eta = 0.3\n",
    "    max_depth= 20 \n",
    "    subsample = 1\n",
    "    colsample_bytree = 1\n",
    "    min_chil_weight=1\n",
    "    lambda_ = 10\n",
    "    #start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"lambda\": lambda_,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"min_chil_weight\":min_chil_weight,\n",
    "        \"seed\": random_state,\n",
    "        #\"num_class\" : 22,\n",
    "    }\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "\n",
    "   \n",
    "    \n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=test_size)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_cv, y_cv)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    y_cv_pred = gbm.predict(xgb.DMatrix(X_cv), ntree_limit=gbm.best_iteration+1)\n",
    "    \n",
    "    score = roc_auc_score(y_cv, y_cv_pred)\n",
    "    print(\"score: %f\" % score)\n",
    "    \"\"\"\n",
    "    #area under the precision-recall curve\n",
    "    score = average_precision_score(X_valid[target].values, check)\n",
    "    print('area under the precision-recall curve: {:.6f}'.format(score))\n",
    "\n",
    "    \n",
    "    check2=check.round()\n",
    "    score = precision_score(X_valid[target].values, check2)\n",
    "    print('precision score: {:.6f}'.format(score))\n",
    "\n",
    "    score = recall_score(X_valid[target].values, check2)\n",
    "    print('recall score: {:.6f}'.format(score))\n",
    "    \n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set... \")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features],missing = -99), ntree_limit=gbm.best_iteration+1)\n",
    "    score = average_precision_score(test[target].values, test_prediction)\n",
    "    \"\"\"\n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef xgb_test(X_train, y_train, X_test, params, random_state=0):\\n    from xgb import XG\\n    num_boost_round = 1000\\n    early_stopping_rounds = 20\\n    test_size = 0.1\\n    dtrain = xgb.DMatrix(X_train, y_train)\\n    #dtest = xgb.DMatrix(X_cv, y_cv)\\n\\n    #watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\\n    watchlist = [(dtrain, 'train'), (dtrain, 'eval')]\\n    gbm = xgb.train(params, dtrain, num_boost_round, early_stopping_rounds=early_stopping_rounds)\\n\\n    y_test_pred = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration+1)\\n    \\n    make_submission_file(y_test_pred)\\n\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def xgb_test(X_train, y_train, X_test, params, random_state=0):\n",
    "    from xgb import XG\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    #dtest = xgb.DMatrix(X_cv, y_cv)\n",
    "\n",
    "    #watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(dtrain, 'train'), (dtrain, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    y_test_pred = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration+1)\n",
    "    \n",
    "    make_submission_file(y_test_pred)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "def xgb_test(X_train, y_train, X_test, params, random_state=0):\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    \n",
    "    xgb_clf = XGBClassifier(**params)\n",
    "    xgb_clf.fit(X_train, y_train,eval_metric='auc')\n",
    "\n",
    "    y_test_pred = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    make_submission_file(y_test_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost params. ETA: 0.3, MAX_DEPTH: 20, SUBSAMPLE: 1, COLSAMPLE_BY_TREE: 1\n",
      "[0]\ttrain-auc:0.599338\teval-auc:0.572438\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 20 rounds.\n",
      "[1]\ttrain-auc:0.629334\teval-auc:0.579927\n",
      "[2]\ttrain-auc:0.654401\teval-auc:0.617621\n",
      "[3]\ttrain-auc:0.703778\teval-auc:0.651439\n",
      "[4]\ttrain-auc:0.746956\teval-auc:0.699533\n",
      "[5]\ttrain-auc:0.769911\teval-auc:0.728424\n",
      "[6]\ttrain-auc:0.779138\teval-auc:0.735981\n",
      "[7]\ttrain-auc:0.813302\teval-auc:0.746069\n",
      "[8]\ttrain-auc:0.838319\teval-auc:0.769574\n",
      "[9]\ttrain-auc:0.847216\teval-auc:0.775306\n",
      "[10]\ttrain-auc:0.85147\teval-auc:0.784492\n",
      "[11]\ttrain-auc:0.860639\teval-auc:0.802519\n",
      "[12]\ttrain-auc:0.86414\teval-auc:0.79965\n",
      "[13]\ttrain-auc:0.868579\teval-auc:0.801176\n",
      "[14]\ttrain-auc:0.872111\teval-auc:0.806039\n",
      "[15]\ttrain-auc:0.874298\teval-auc:0.810431\n",
      "[16]\ttrain-auc:0.878275\teval-auc:0.811249\n",
      "[17]\ttrain-auc:0.87945\teval-auc:0.812733\n",
      "[18]\ttrain-auc:0.880757\teval-auc:0.813363\n",
      "[19]\ttrain-auc:0.881223\teval-auc:0.813824\n",
      "[20]\ttrain-auc:0.881948\teval-auc:0.814626\n",
      "[21]\ttrain-auc:0.883053\teval-auc:0.817147\n",
      "[22]\ttrain-auc:0.884225\teval-auc:0.819595\n",
      "[23]\ttrain-auc:0.884805\teval-auc:0.819429\n",
      "[24]\ttrain-auc:0.886449\teval-auc:0.821306\n",
      "[25]\ttrain-auc:0.887641\teval-auc:0.822755\n",
      "[26]\ttrain-auc:0.888633\teval-auc:0.8236\n",
      "[27]\ttrain-auc:0.88957\teval-auc:0.822888\n",
      "[28]\ttrain-auc:0.890039\teval-auc:0.823186\n",
      "[29]\ttrain-auc:0.890767\teval-auc:0.823969\n",
      "[30]\ttrain-auc:0.891266\teval-auc:0.825317\n",
      "[31]\ttrain-auc:0.891865\teval-auc:0.826871\n",
      "[32]\ttrain-auc:0.892635\teval-auc:0.828744\n",
      "[33]\ttrain-auc:0.893467\teval-auc:0.829719\n",
      "[34]\ttrain-auc:0.894187\teval-auc:0.830125\n",
      "[35]\ttrain-auc:0.894858\teval-auc:0.829574\n",
      "[36]\ttrain-auc:0.895498\teval-auc:0.830341\n",
      "[37]\ttrain-auc:0.895841\teval-auc:0.830758\n",
      "[38]\ttrain-auc:0.896443\teval-auc:0.831481\n",
      "[39]\ttrain-auc:0.896921\teval-auc:0.83226\n",
      "[40]\ttrain-auc:0.897543\teval-auc:0.831856\n",
      "[41]\ttrain-auc:0.897821\teval-auc:0.832258\n",
      "[42]\ttrain-auc:0.898209\teval-auc:0.832238\n",
      "[43]\ttrain-auc:0.89871\teval-auc:0.832004\n",
      "[44]\ttrain-auc:0.899513\teval-auc:0.833063\n",
      "[45]\ttrain-auc:0.900042\teval-auc:0.833048\n",
      "[46]\ttrain-auc:0.900507\teval-auc:0.833652\n",
      "[47]\ttrain-auc:0.901347\teval-auc:0.832273\n",
      "[48]\ttrain-auc:0.901639\teval-auc:0.831816\n",
      "[49]\ttrain-auc:0.902049\teval-auc:0.831555\n",
      "[50]\ttrain-auc:0.902349\teval-auc:0.831511\n",
      "[51]\ttrain-auc:0.902871\teval-auc:0.831673\n",
      "[52]\ttrain-auc:0.903164\teval-auc:0.83257\n",
      "[53]\ttrain-auc:0.903472\teval-auc:0.832971\n",
      "[54]\ttrain-auc:0.903919\teval-auc:0.833183\n",
      "[55]\ttrain-auc:0.904129\teval-auc:0.833644\n",
      "[56]\ttrain-auc:0.904424\teval-auc:0.833506\n",
      "[57]\ttrain-auc:0.90488\teval-auc:0.834346\n",
      "[58]\ttrain-auc:0.905164\teval-auc:0.834363\n",
      "[59]\ttrain-auc:0.905509\teval-auc:0.834617\n",
      "[60]\ttrain-auc:0.905745\teval-auc:0.834906\n",
      "[61]\ttrain-auc:0.906043\teval-auc:0.835374\n",
      "[62]\ttrain-auc:0.906147\teval-auc:0.835859\n",
      "[63]\ttrain-auc:0.906318\teval-auc:0.835714\n",
      "[64]\ttrain-auc:0.906581\teval-auc:0.836048\n",
      "[65]\ttrain-auc:0.906886\teval-auc:0.836606\n",
      "[66]\ttrain-auc:0.90723\teval-auc:0.835885\n",
      "[67]\ttrain-auc:0.907306\teval-auc:0.836113\n",
      "[68]\ttrain-auc:0.907629\teval-auc:0.836889\n",
      "[69]\ttrain-auc:0.907777\teval-auc:0.837121\n",
      "[70]\ttrain-auc:0.908305\teval-auc:0.838118\n",
      "[71]\ttrain-auc:0.908593\teval-auc:0.839507\n",
      "[72]\ttrain-auc:0.908978\teval-auc:0.839141\n",
      "[73]\ttrain-auc:0.909513\teval-auc:0.839491\n",
      "[74]\ttrain-auc:0.909763\teval-auc:0.839841\n",
      "[75]\ttrain-auc:0.909953\teval-auc:0.839999\n",
      "[76]\ttrain-auc:0.910089\teval-auc:0.840132\n",
      "[77]\ttrain-auc:0.910352\teval-auc:0.841209\n",
      "[78]\ttrain-auc:0.91065\teval-auc:0.841452\n",
      "[79]\ttrain-auc:0.911006\teval-auc:0.841372\n",
      "[80]\ttrain-auc:0.911229\teval-auc:0.841314\n",
      "[81]\ttrain-auc:0.911492\teval-auc:0.841668\n",
      "[82]\ttrain-auc:0.912172\teval-auc:0.842957\n",
      "[83]\ttrain-auc:0.912388\teval-auc:0.843039\n",
      "[84]\ttrain-auc:0.912791\teval-auc:0.843527\n",
      "[85]\ttrain-auc:0.912991\teval-auc:0.843741\n",
      "[86]\ttrain-auc:0.913101\teval-auc:0.84367\n",
      "[87]\ttrain-auc:0.913275\teval-auc:0.843972\n",
      "[88]\ttrain-auc:0.913803\teval-auc:0.843237\n",
      "[89]\ttrain-auc:0.914422\teval-auc:0.843092\n",
      "[90]\ttrain-auc:0.914544\teval-auc:0.843261\n",
      "[91]\ttrain-auc:0.914712\teval-auc:0.843388\n",
      "[92]\ttrain-auc:0.914933\teval-auc:0.843815\n",
      "[93]\ttrain-auc:0.915088\teval-auc:0.84402\n",
      "[94]\ttrain-auc:0.915192\teval-auc:0.844008\n",
      "[95]\ttrain-auc:0.9154\teval-auc:0.843944\n",
      "[96]\ttrain-auc:0.915614\teval-auc:0.843544\n",
      "[97]\ttrain-auc:0.916246\teval-auc:0.842356\n",
      "[98]\ttrain-auc:0.916415\teval-auc:0.842534\n",
      "[99]\ttrain-auc:0.91658\teval-auc:0.842587\n",
      "[100]\ttrain-auc:0.916705\teval-auc:0.842687\n",
      "[101]\ttrain-auc:0.916869\teval-auc:0.842797\n",
      "[102]\ttrain-auc:0.917007\teval-auc:0.843018\n",
      "[103]\ttrain-auc:0.9171\teval-auc:0.843011\n",
      "[104]\ttrain-auc:0.917211\teval-auc:0.842972\n",
      "[105]\ttrain-auc:0.917899\teval-auc:0.844161\n",
      "[106]\ttrain-auc:0.918094\teval-auc:0.844313\n",
      "[107]\ttrain-auc:0.918242\teval-auc:0.844472\n",
      "[108]\ttrain-auc:0.91848\teval-auc:0.844072\n",
      "[109]\ttrain-auc:0.918692\teval-auc:0.84385\n",
      "[110]\ttrain-auc:0.918803\teval-auc:0.843823\n",
      "[111]\ttrain-auc:0.919052\teval-auc:0.844367\n",
      "[112]\ttrain-auc:0.919464\teval-auc:0.844925\n",
      "[113]\ttrain-auc:0.919903\teval-auc:0.844593\n",
      "[114]\ttrain-auc:0.920052\teval-auc:0.844399\n",
      "[115]\ttrain-auc:0.92019\teval-auc:0.844434\n",
      "[116]\ttrain-auc:0.920421\teval-auc:0.844875\n",
      "[117]\ttrain-auc:0.920816\teval-auc:0.845255\n",
      "[118]\ttrain-auc:0.920961\teval-auc:0.845485\n",
      "[119]\ttrain-auc:0.921068\teval-auc:0.845855\n",
      "[120]\ttrain-auc:0.921451\teval-auc:0.845954\n",
      "[121]\ttrain-auc:0.921535\teval-auc:0.84592\n",
      "[122]\ttrain-auc:0.921808\teval-auc:0.845953\n",
      "[123]\ttrain-auc:0.921859\teval-auc:0.846007\n",
      "[124]\ttrain-auc:0.921937\teval-auc:0.846056\n",
      "[125]\ttrain-auc:0.92205\teval-auc:0.846332\n",
      "[126]\ttrain-auc:0.922206\teval-auc:0.846327\n",
      "[127]\ttrain-auc:0.922352\teval-auc:0.845877\n",
      "[128]\ttrain-auc:0.922541\teval-auc:0.846328\n",
      "[129]\ttrain-auc:0.922756\teval-auc:0.846445\n",
      "[130]\ttrain-auc:0.922818\teval-auc:0.846507\n",
      "[131]\ttrain-auc:0.922906\teval-auc:0.846597\n",
      "[132]\ttrain-auc:0.923033\teval-auc:0.846701\n",
      "[133]\ttrain-auc:0.92314\teval-auc:0.846804\n",
      "[134]\ttrain-auc:0.923278\teval-auc:0.846947\n",
      "[135]\ttrain-auc:0.923349\teval-auc:0.847033\n",
      "[136]\ttrain-auc:0.923424\teval-auc:0.847024\n",
      "[137]\ttrain-auc:0.923515\teval-auc:0.84686\n",
      "[138]\ttrain-auc:0.923625\teval-auc:0.846983\n",
      "[139]\ttrain-auc:0.924112\teval-auc:0.847589\n",
      "[140]\ttrain-auc:0.924369\teval-auc:0.847789\n",
      "[141]\ttrain-auc:0.924422\teval-auc:0.847988\n",
      "[142]\ttrain-auc:0.924578\teval-auc:0.848162\n",
      "[143]\ttrain-auc:0.924662\teval-auc:0.848334\n",
      "[144]\ttrain-auc:0.924753\teval-auc:0.848359\n",
      "[145]\ttrain-auc:0.924851\teval-auc:0.848519\n",
      "[146]\ttrain-auc:0.925158\teval-auc:0.847967\n",
      "[147]\ttrain-auc:0.925239\teval-auc:0.84755\n",
      "[148]\ttrain-auc:0.925577\teval-auc:0.847842\n",
      "[149]\ttrain-auc:0.925798\teval-auc:0.848307\n",
      "[150]\ttrain-auc:0.926075\teval-auc:0.848873\n",
      "[151]\ttrain-auc:0.92618\teval-auc:0.848945\n",
      "[152]\ttrain-auc:0.92625\teval-auc:0.849251\n",
      "[153]\ttrain-auc:0.92638\teval-auc:0.849359\n",
      "[154]\ttrain-auc:0.926495\teval-auc:0.849526\n",
      "[155]\ttrain-auc:0.926762\teval-auc:0.849402\n",
      "[156]\ttrain-auc:0.926882\teval-auc:0.849604\n",
      "[157]\ttrain-auc:0.926939\teval-auc:0.849792\n",
      "[158]\ttrain-auc:0.927066\teval-auc:0.850058\n",
      "[159]\ttrain-auc:0.927326\teval-auc:0.850578\n",
      "[160]\ttrain-auc:0.927436\teval-auc:0.850708\n",
      "[161]\ttrain-auc:0.927537\teval-auc:0.851103\n",
      "[162]\ttrain-auc:0.927838\teval-auc:0.851697\n",
      "[163]\ttrain-auc:0.928158\teval-auc:0.852339\n",
      "[164]\ttrain-auc:0.928449\teval-auc:0.852763\n",
      "[165]\ttrain-auc:0.928518\teval-auc:0.852827\n",
      "[166]\ttrain-auc:0.928657\teval-auc:0.853129\n",
      "[167]\ttrain-auc:0.928708\teval-auc:0.85307\n",
      "[168]\ttrain-auc:0.928748\teval-auc:0.853166\n",
      "[169]\ttrain-auc:0.928841\teval-auc:0.853323\n",
      "[170]\ttrain-auc:0.928956\teval-auc:0.85366\n",
      "[171]\ttrain-auc:0.929023\teval-auc:0.853701\n",
      "[172]\ttrain-auc:0.929159\teval-auc:0.853918\n",
      "[173]\ttrain-auc:0.929208\teval-auc:0.854013\n",
      "[174]\ttrain-auc:0.929278\teval-auc:0.853968\n",
      "[175]\ttrain-auc:0.929394\teval-auc:0.854134\n",
      "[176]\ttrain-auc:0.929484\teval-auc:0.854304\n",
      "[177]\ttrain-auc:0.929499\teval-auc:0.854407\n",
      "[178]\ttrain-auc:0.929667\teval-auc:0.854691\n",
      "[179]\ttrain-auc:0.929773\teval-auc:0.854927\n",
      "[180]\ttrain-auc:0.929856\teval-auc:0.854967\n",
      "[181]\ttrain-auc:0.929908\teval-auc:0.855038\n",
      "[182]\ttrain-auc:0.929976\teval-auc:0.854968\n",
      "[183]\ttrain-auc:0.930105\teval-auc:0.855506\n",
      "[184]\ttrain-auc:0.930206\teval-auc:0.855867\n",
      "[185]\ttrain-auc:0.930222\teval-auc:0.855864\n",
      "[186]\ttrain-auc:0.930304\teval-auc:0.855911\n",
      "[187]\ttrain-auc:0.93049\teval-auc:0.855966\n",
      "[188]\ttrain-auc:0.930646\teval-auc:0.856135\n",
      "[189]\ttrain-auc:0.930693\teval-auc:0.856278\n",
      "[190]\ttrain-auc:0.930819\teval-auc:0.856427\n",
      "[191]\ttrain-auc:0.930943\teval-auc:0.856399\n",
      "[192]\ttrain-auc:0.931029\teval-auc:0.856757\n",
      "[193]\ttrain-auc:0.931096\teval-auc:0.856688\n",
      "[194]\ttrain-auc:0.931213\teval-auc:0.856552\n",
      "[195]\ttrain-auc:0.931333\teval-auc:0.856074\n",
      "[196]\ttrain-auc:0.931402\teval-auc:0.856105\n",
      "[197]\ttrain-auc:0.931475\teval-auc:0.856115\n",
      "[198]\ttrain-auc:0.93152\teval-auc:0.856076\n",
      "[199]\ttrain-auc:0.931823\teval-auc:0.856283\n",
      "[200]\ttrain-auc:0.932098\teval-auc:0.856495\n",
      "[201]\ttrain-auc:0.932257\teval-auc:0.856121\n",
      "[202]\ttrain-auc:0.932299\teval-auc:0.855844\n",
      "[203]\ttrain-auc:0.932431\teval-auc:0.8559\n",
      "[204]\ttrain-auc:0.932629\teval-auc:0.855911\n",
      "[205]\ttrain-auc:0.932705\teval-auc:0.85594\n",
      "[206]\ttrain-auc:0.932805\teval-auc:0.855855\n",
      "[207]\ttrain-auc:0.932888\teval-auc:0.855994\n",
      "[208]\ttrain-auc:0.933069\teval-auc:0.856309\n",
      "[209]\ttrain-auc:0.933157\teval-auc:0.856418\n",
      "[210]\ttrain-auc:0.933201\teval-auc:0.85665\n",
      "[211]\ttrain-auc:0.933257\teval-auc:0.856566\n",
      "[212]\ttrain-auc:0.933334\teval-auc:0.856529\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-auc:0.931029\teval-auc:0.856757\n",
      "\n",
      "Validating...\n",
      "score: 0.856757\n"
     ]
    }
   ],
   "source": [
    "params = xgb_cv(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'colsample_bytree': 1,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'auc',\n",
       " 'lambda': 10,\n",
       " 'max_depth': 20,\n",
       " 'min_chil_weight': 1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'seed': 0,\n",
       " 'silent': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_test(X_train_ohe, y_train, X_test_ohe, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,ACTION\r\n",
      "1,0.573768019676\r\n",
      "2,0.970520675182\r\n",
      "3,0.974909067154\r\n",
      "4,0.980617165565\r\n",
      "5,0.994414329529\r\n",
      "6,0.977379858494\r\n",
      "7,0.971070706844\r\n",
      "8,0.992024421692\r\n",
      "9,0.691649436951\r\n"
     ]
    }
   ],
   "source": [
    "!head submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78766</td>\n",
       "      <td>72734</td>\n",
       "      <td>118079</td>\n",
       "      <td>118080</td>\n",
       "      <td>117878</td>\n",
       "      <td>117879</td>\n",
       "      <td>118177</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40644</td>\n",
       "      <td>4378</td>\n",
       "      <td>117961</td>\n",
       "      <td>118327</td>\n",
       "      <td>118507</td>\n",
       "      <td>118863</td>\n",
       "      <td>122008</td>\n",
       "      <td>118398</td>\n",
       "      <td>118865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>75443</td>\n",
       "      <td>2395</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>119488</td>\n",
       "      <td>118172</td>\n",
       "      <td>301534</td>\n",
       "      <td>249618</td>\n",
       "      <td>118175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>43219</td>\n",
       "      <td>19986</td>\n",
       "      <td>117961</td>\n",
       "      <td>118225</td>\n",
       "      <td>118403</td>\n",
       "      <td>120773</td>\n",
       "      <td>136187</td>\n",
       "      <td>118960</td>\n",
       "      <td>120774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42093</td>\n",
       "      <td>50015</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119598</td>\n",
       "      <td>118422</td>\n",
       "      <td>300136</td>\n",
       "      <td>118424</td>\n",
       "      <td>118425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0   1     78766   72734         118079         118080         117878   \n",
       "1   2     40644    4378         117961         118327         118507   \n",
       "2   3     75443    2395         117961         118300         119488   \n",
       "3   4     43219   19986         117961         118225         118403   \n",
       "4   5     42093   50015         117961         118343         119598   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117879            118177        19721     117880  \n",
       "1      118863            122008       118398     118865  \n",
       "2      118172            301534       249618     118175  \n",
       "3      120773            136187       118960     120774  \n",
       "4      118422            300136       118424     118425  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
