{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def generate_combs(s, k):\n",
    "    if k == 0 or k > len(s):\n",
    "        yield []\n",
    "        return \n",
    "    \n",
    "    for i in range(len(s)-k+1):\n",
    "        for c in generate_combs(s[i+1:], k-1):\n",
    "            yield [s[i]] + c\n",
    "                    \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_high_order_features(data, degree=2):\n",
    "    \"\"\"\n",
    "    Generate new features by concatinating existing features\n",
    "    from data. This is similiar to polinomial feature generation\n",
    "    but can be used with categorical data as well.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: numpy array, contains data with features to be concatinated\n",
    "    \n",
    "    degree: int, number of features to concatinate to generate each new\n",
    "    feature. For example, if there are three features 'a', 'b', and 'c'\n",
    "    and degree=2, generated features are 'ab', 'ac', 'bc'.\n",
    "    \n",
    "    \"\"\"\n",
    "    m, n = data.shape\n",
    "    \n",
    "    feature_combs = generate_combs(range(n), degree)\n",
    "    \n",
    "    return np.vstack(\n",
    "                    [np.array([hash(tuple(row)) \n",
    "                               for row in data[:, comb].tolist()])]\n",
    "                                   for comb in feature_combs\n",
    "    ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3713081593804632581, 3713081688086064931, 3713081652919157781,\n",
       "        ..., 3802992883545139856, 3802993053234181181,\n",
       "        3415903829100288256],\n",
       "       [3713081613378849631, 3713081632495158606, 3713081652919157781,\n",
       "        ..., 3802583751228827281, 3802584108805237706,\n",
       "        3468288415453038256],\n",
       "       [3713081599014825406, 3713081638629827781, 3713081652639866331,\n",
       "        ..., 3423292086759634856, 3423292121901643931,\n",
       "        3696722415271732506],\n",
       "       ...,\n",
       "       [3713081598711718406, 3713081618499192881, 3713081652919157781,\n",
       "        ..., 3833117828409294481, 3833117821922804681,\n",
       "        3802510451410774931],\n",
       "       [3713081708815336156, 3713081576308863531, 3713081652634453706,\n",
       "        ..., 3413839132170712606, 3413839515002431281,\n",
       "        3414695830855374706],\n",
       "       [3713081638602764656, 3713081589658561831, 3713081652872609206,\n",
       "        ..., 3798693361501076906, 3798693254492398131,\n",
       "        3696722416048985456]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_high_order_features(train.as_matrix(), degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]\n",
    "X_test = test.iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78766</td>\n",
       "      <td>72734</td>\n",
       "      <td>118079</td>\n",
       "      <td>118080</td>\n",
       "      <td>117878</td>\n",
       "      <td>117879</td>\n",
       "      <td>118177</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40644</td>\n",
       "      <td>4378</td>\n",
       "      <td>117961</td>\n",
       "      <td>118327</td>\n",
       "      <td>118507</td>\n",
       "      <td>118863</td>\n",
       "      <td>122008</td>\n",
       "      <td>118398</td>\n",
       "      <td>118865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>75443</td>\n",
       "      <td>2395</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>119488</td>\n",
       "      <td>118172</td>\n",
       "      <td>301534</td>\n",
       "      <td>249618</td>\n",
       "      <td>118175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>43219</td>\n",
       "      <td>19986</td>\n",
       "      <td>117961</td>\n",
       "      <td>118225</td>\n",
       "      <td>118403</td>\n",
       "      <td>120773</td>\n",
       "      <td>136187</td>\n",
       "      <td>118960</td>\n",
       "      <td>120774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42093</td>\n",
       "      <td>50015</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119598</td>\n",
       "      <td>118422</td>\n",
       "      <td>300136</td>\n",
       "      <td>118424</td>\n",
       "      <td>118425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0   1     78766   72734         118079         118080         117878   \n",
       "1   2     40644    4378         117961         118327         118507   \n",
       "2   3     75443    2395         117961         118300         119488   \n",
       "3   4     43219   19986         117961         118225         118403   \n",
       "4   5     42093   50015         117961         118343         119598   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117879            118177        19721     117880  \n",
       "1      118863            122008       118398     118865  \n",
       "2      118172            301534       249618     118175  \n",
       "3      120773            136187       118960     120774  \n",
       "4      118422            300136       118424     118425  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def make_poli_features(data, max_degree):\\n    data_matrix = data.as_matrix()\\n    data_poli_feature = [data_matrix]\\n    for d in range(2, max_degree+1):\\n        data_poli_feature.append(generate_high_order_features(data_matrix, degree=d))\\n\\n    return np.hstack(data_poli_feature)    \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def make_poli_features(data, max_degree):\n",
    "    data_matrix = data.as_matrix()\n",
    "    data_poli_feature = [data_matrix]\n",
    "    for d in range(2, max_degree+1):\n",
    "        data_poli_feature.append(generate_high_order_features(data_matrix, degree=d))\n",
    "\n",
    "    return np.hstack(data_poli_feature)    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class HighOrderFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2):\n",
    "        self.degree = degree\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.as_matrix()\n",
    "        elif isinstance(X, list):\n",
    "            X = np.array(X)\n",
    "            \n",
    "        X_poli_feature = [X]\n",
    "        for d in range(2, self.degree+1):\n",
    "            X_poli_feature.append(generate_high_order_features(X, degree=d))\n",
    "\n",
    "        return np.hstack(X_poli_feature)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        col_uniques = [np.unique(c) for c in X.T]\n",
    "        self.map = [dict(zip(c, range(len(c)))) for c in col_uniques]\n",
    "        self.fitted = True\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if not self.fitted:\n",
    "            raise Exception(\"Transformer not fitted.\")\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        if len(self.map) != n_features:\n",
    "            raise Exception(\"X must have the same number of columns \\\n",
    "                                as the matrix used to fit the transformer.\")\n",
    "        \n",
    "        res = []\n",
    "        for i, col in enumerate(X.T):\n",
    "            col_indices = np.vectorize(self.map[i].get)(col)\n",
    "            row_indices = np.arange(n_samples)\n",
    "            ones = np.ones(n_samples)\n",
    "            col_encoded = sparse.coo_matrix((ones, (row_indices, col_indices)))\n",
    "            res.append(col_encoded)\n",
    "            \n",
    "        return sparse.hstack(res).tocsr()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hof = HighOrderFeatures(degree=2)\n",
    "X_train_hof = hof.fit_transform(X_train)\n",
    "X_test_hof = hof.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import OneHotEncoder\n",
    "max_degree = 2\n",
    "X_train_poli = make_poli_features(X_train, max_degree)\n",
    "X_test_poli = make_poli_features(X_test, max_degree)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "\n",
    "ohe = OneHotEncoder() \n",
    "ohe.fit_transform(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<type 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_endcode(X_train, X_test):\n",
    "    ohe = OneHotEncoder()\n",
    "    X_total = np.vstack([X_train, X_test])\n",
    "    X_total_ohe = ohe.fit_transform(X_total)\n",
    "    n_train = X_train.shape[0]\n",
    "    X_train_ohe = X_total_ohe[:n_train,]\n",
    "    X_test_ohe = X_total_ohe[n_train:,]\n",
    "    return X_train_ohe, X_test_ohe\n",
    "\n",
    "X_train_ohe, X_test_ohe = one_hot_endcode(X_train_hof, X_test_hof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "gs = GridSearchCV(clf, param_grid={'C': np.logspace(-1, 1, 10)}, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([ 0.1    ,  0.16681,  0.27826,  0.46416,  0.77426,  1.29155,\n",
       "        2.15443,  3.59381,  5.99484, 10.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=<function scoring at 0x7fb356220488>, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.2782559402207124}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95294764, 0.94918978, 0.94964292])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#clf = LogisticRegression(C=3)\n",
    "clf = gs.best_estimator_\n",
    "cross_val_score(clf, X_train_ohe, y_train, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission_file(y_test_pred, filename=None):\n",
    "    submit_data = pd.DataFrame(columns=['ID', 'ACTION'])\n",
    "    submit_data['ID'] = xrange(1, len(y_test_pred)+1)\n",
    "    submit_data['ACTION'] = y_test_pred\n",
    "    if not filename:\n",
    "        filename = 'submit.csv'\n",
    "    submit_data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "n_stack = 2\n",
    "X_train_ohe_double = vstack([X_train_ohe for _ in range(n_stack)])\n",
    "y_train_double = np.vstack([y_train.reshape(-1, 1) for _ in range(n_stack)]).ravel()\n",
    "\n",
    "# Shuffle train data\n",
    "\n",
    "n_train = X_train_ohe_double.shape[0]\n",
    "shuffle_index = np.random.permutation(n_train)\n",
    "X_train_ohe = X_train_ohe_double[shuffle_index]\n",
    "y_train = y_train_double[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train_ohe, y_train)\n",
    "y_test_pred = clf.predict_proba(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_submission_file(y_test_pred, 'submit/submit_poli2_gs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##TODO\n",
    "## Try RF and XGB with GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "hof = HighOrderFeatures()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "estimators = [('hof', hof), ('clf', clf)]\n",
    "pl = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pl, param_grid={'clf__C': np.logspace(-1, 1, 10)}, scoring=scoring)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
