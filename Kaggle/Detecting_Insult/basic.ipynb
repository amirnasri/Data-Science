{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"@EephusBlue\\\\xa0Makes you want to say \"Mike MacWHOgal?\"\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Comment[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_with_solutions = pd.read_csv(\"data/test_with_solutions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verification_set = pd.read_csv(\"data/impermium_verification_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verif_set = pd.read_csv(\"data/impermium_verification_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impermium_verification_labels.csv  test.csv\r\n",
      "impermium_verification_set.csv\t   test_with_solutions.csv\r\n",
      "sample_submission_null.csv\t   train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\" \"I didn\\\\'t spend 25 years making 170 pictur...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>0</td>\n",
       "      <td>20120611234007Z</td>\n",
       "      <td>\"\" I have a job to do to defend the right of t...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0</td>\n",
       "      <td>20120610162824Z</td>\n",
       "      <td>\"\" Oh shit there's more ! \" Fucking perfection...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>20120609231946Z</td>\n",
       "      <td>\"\" we let you in\"? Who's we? YOU didn't let an...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620031414Z</td>\n",
       "      <td>\"\"...our country is in a pile of deep shit.\"\\x...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "1733       0              NaN   \n",
       "2356       0  20120611234007Z   \n",
       "724        0  20120610162824Z   \n",
       "273        1  20120609231946Z   \n",
       "786        0  20120620031414Z   \n",
       "\n",
       "                                                Comment        Usage  \n",
       "1733  \" \"I didn\\\\'t spend 25 years making 170 pictur...   PublicTest  \n",
       "2356  \"\" I have a job to do to defend the right of t...  PrivateTest  \n",
       "724   \"\" Oh shit there's more ! \" Fucking perfection...  PrivateTest  \n",
       "273   \"\" we let you in\"? Who's we? YOU didn't let an...  PrivateTest  \n",
       "786   \"\"...our country is in a pile of deep shit.\"\\x...  PrivateTest  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_with_solutions.sort_values(by='Comment').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1027</td>\n",
       "      <td>20120529011348Z</td>\n",
       "      <td>\" Are you trying to tell us something?????\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>628</td>\n",
       "      <td>20120601034035Z</td>\n",
       "      <td>\" Get your eyes checked! Fat is never beautifu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>20120602222445Z</td>\n",
       "      <td>\" No. you didn't talk about your IQ!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1878</td>\n",
       "      <td>20120527025100Z</td>\n",
       "      <td>\" Omg this looks like you MOM!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1837</td>\n",
       "      <td>20120602090351Z</td>\n",
       "      <td>\"!!! Is it from your camera?\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             Date                                            Comment\n",
       "1026  1027  20120529011348Z        \" Are you trying to tell us something?????\"\n",
       "627    628  20120601034035Z  \" Get your eyes checked! Fat is never beautifu...\n",
       "91      92  20120602222445Z              \" No. you didn't talk about your IQ!\"\n",
       "1877  1878  20120527025100Z                    \" Omg this looks like you MOM!\"\n",
       "1836  1837  20120602090351Z                      \"!!! Is it from your camera?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sort_values(by='Comment').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1027</td>\n",
       "      <td>0</td>\n",
       "      <td>20120529011348Z</td>\n",
       "      <td>\" Are you trying to tell us something?????\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>20120601034035Z</td>\n",
       "      <td>\" Get your eyes checked! Fat is never beautifu...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>20120602222445Z</td>\n",
       "      <td>\" No. you didn't talk about your IQ!\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1878</td>\n",
       "      <td>0</td>\n",
       "      <td>20120527025100Z</td>\n",
       "      <td>\" Omg this looks like you MOM!\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1837</td>\n",
       "      <td>0</td>\n",
       "      <td>20120602090351Z</td>\n",
       "      <td>\"!!! Is it from your camera?\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Insult             Date  \\\n",
       "1026  1027       0  20120529011348Z   \n",
       "627    628       1  20120601034035Z   \n",
       "91      92       0  20120602222445Z   \n",
       "1877  1878       0  20120527025100Z   \n",
       "1836  1837       0  20120602090351Z   \n",
       "\n",
       "                                                Comment        Usage  \n",
       "1026        \" Are you trying to tell us something?????\"  PrivateTest  \n",
       "627   \" Get your eyes checked! Fat is never beautifu...  PrivateTest  \n",
       "91                \" No. you didn't talk about your IQ!\"  PrivateTest  \n",
       "1877                    \" Omg this looks like you MOM!\"  PrivateTest  \n",
       "1836                      \"!!! Is it from your camera?\"  PrivateTest  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification_set.sort_values(by='Comment').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_public = test_with_solutions[test_with_solutions.Usage == \"PublicTest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_private = test_with_solutions[test_with_solutions.Usage == \"PrivateTest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_total = pd.concat([train, test_with_solutions.iloc[:, :-1]]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Insult             Date  \\\n",
       "0      0       1  20120618192155Z   \n",
       "1      1       0  20120528192215Z   \n",
       "2      2       0              NaN   \n",
       "3      3       0              NaN   \n",
       "4      4       0  20120619094753Z   \n",
       "\n",
       "                                             Comment  \n",
       "0                               \"You fuck your dad.\"  \n",
       "1  \"i really don't understand your point.\\xa0 It ...  \n",
       "2  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...  \n",
       "3  \"listen if you dont wanna get married to a man...  \n",
       "4  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidv = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidv.fit_transform(train_total.Comment)\n",
    "y_train = train_total.Insult\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression()\n",
    "\n",
    "logr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96251297888964227"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_test = tfidv.transform(test_with_solutions.Comment)\n",
    "y_test_pred = logr.predict_proba(X_test)[:, 1]\n",
    "y_test = test_with_solutions.Insult\n",
    "\n",
    "roc_auc_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75345864143185437"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_ver = tfidv.transform(verif_set.Comment)\n",
    "y_ver_pred = logr.predict_proba(X_ver)[:, 1]\n",
    "y_ver = verif_set.Insult\n",
    "\n",
    "roc_auc_score(y_ver, y_ver_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6594,), (6594, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('fu', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('fe', FeatureExtractor()), ('tfidv_char', TfidfVectorizer(analyzer='char', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=No...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pl.fit(train_total.Comment, train_total.Insult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2235,), (2235, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8169469821980393"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ver_pred = pl.predict_proba(verif_set.Comment)[:, 1]\n",
    "y_ver = verif_set.Insult\n",
    "\n",
    "roc_auc_score(y_ver, y_ver_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65956256023656845"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_ver = tfidv.transform(verif_set.Comment)\n",
    "y_ver_pred = clf.predict_proba(X_ver)[:, 1]\n",
    "y_ver = verif_set.Insult\n",
    "\n",
    "roc_auc_score(y_ver, y_ver_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = train_total.reset_index().Comment[4].replace('\\\\\\\\', '\\\\').replace('\\\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1eddng bi\\u1ec3u t\\xecnh 2011 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ? C\\xe1c ng\\u01b0 d\\xe2n ng\\u1ed3i cu\\xed \\u0111\\u1ea7u chi\\u1ee5 nh\\u1ee5c c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ? C\\xe1c n\\xf4ng d\\xe2n gi\\u1eef \\u0111\\u1ea5t \\u1edf V\\u0103n Giang, C\\u1ea7n Th\\u01a1 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ? ................. R\\u1ed1t cu\\u1ed9c \\u0111\\u01b0\\u1ee3c g\\xec\\xa0 th\\xec ch\\xfang ta \\u0111\\xe3 bi\\u1ebft ! Ai c\\u0169ng y\\xeau chu\\u1ed9ng ho\\xe0 b\\xecnh, nh\\u01b0ng \\u0111\\xf4i khi ho\\xe0 b\\xecnh ch\\u1ec9 th\\u1eadt s\\u1ef1 \\u0111\\u1ebfn sau chi\\u1ebfn tranh m\\xe0 th\\xf4i. Kh\\xf4ng c\\xf2n con \\u0111\\u01b0\\u1eddng n\\xe0o ch\\u1ecdn kh\\xe1c \\u0111\\xe2u, \\u0111\\u1eebng m\\u01a1 th\\xeam n\\u01b0\\xe3.\"\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import UnicodeDammit\n",
    "s = train.Comment[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import UnicodeDammit\n",
    "dammit = UnicodeDammit(s)\n",
    "print(dammit.unicode_markup)\n",
    "# Sacré bleu!\n",
    "dammit.original_encoding\n",
    "# 'utf-8'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f-df fff  '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "\n",
    "re.sub('[?.!-,]', ' ', 'f-df?fff!*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = train_total.Comment\n",
    "\n",
    "punc_re = re.compile('[?.!,]')\n",
    "\n",
    "comments = [punc_re.sub(' ', c) for c in comments]\n",
    "\n",
    "char_re = re.compile('[\\\"\\'-]')\n",
    "\n",
    "comments = [char_re.sub(' ', c) for c in comments]\n",
    "\n",
    "comments = [c.replace('\\\\\\\\', '\\\\').replace('\\\\n', '\\n') for c in comments]\n",
    "\n",
    "comments_non_alpha = []\n",
    "for c in comments:\n",
    "    comment = []\n",
    "    for w in c.split():\n",
    "        if not re.match('^[a-zA-Z\\']*$', w):\n",
    "            comment.append(w)\n",
    "    comments_non_alpha.append(comment)\n",
    "\n",
    "comments = [\" \".join(c.split()) for c in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really don t understand your point \\xa0 It seems that you are mixing apples and oranges\n"
     ]
    }
   ],
   "source": [
    "print(comments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_total_clean = train_total.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_total_clean.Comment = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.16227766017, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidv = TfidfVectorizer()\n",
    "\n",
    "#X_train = tfidv.fit_transform(train_total_clean.Comment)\n",
    "X_train = tfidv.fit_transform(train_total.Comment)\n",
    "y_train = train_total.Insult\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression(C=3.1622776601683795)\n",
    "\n",
    "logr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804013258860487"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_ver = tfidv.transform(verf_set.Comment)\n",
    "y_ver_pred = logr.predict_proba(X_ver)[:, 1]\n",
    "y_ver = verf_set.Insult\n",
    "\n",
    "roc_auc_score(y_ver, y_ver_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6594, 21934)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_re = re.compile(r\"(.)\\1{2,}\")\n",
    "remove_char_re = re.compile('[\\\"\\'-]')\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def preprocessor(s):\n",
    "    s = s.replace('\\\\\\\\', '\\\\').replace('\\\\n', '\\n')\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = dup_re.sub(\"\\g<1>\", s)\n",
    "    s = remove_char_re.sub(\" \", s)\n",
    "    #s = \" \".join([wordnet_lemmatizer.lemmatize(wordnet_lemmatizer.lemmatize(w, pos='v')) for w in s.split()])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "tfidv_char = TfidfVectorizer(ngram_range=(1, 5), analyzer='char', stop_words='english', preprocessor=preprocessor)\n",
    "tfidv_word = TfidfVectorizer(ngram_range=(1, 3), analyzer='word', stop_words='english', min_df=3, preprocessor=preprocessor)\n",
    "tfidv_word = None\n",
    "fe = FeatureExtractor()\n",
    "\n",
    "fu = FeatureUnion([('tfidv_char', tfidv_char), ('tfidv_word', tfidv_word)])\n",
    "fu = FeatureUnion([('fe', fe), ('tfidv_char', tfidv_char), ('tfidv_word', tfidv_word)])\n",
    "#clf_rf = RandomForestClassifier()\n",
    "clf_rf = LogisticRegression(C=20)\n",
    "\n",
    "estimators = [('fu', fu), ('clf', clf_rf)]\n",
    "pl = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4395,), (4395, 1))\n",
      "((2199,), (2199, 1))\n",
      "((4396,), (4396, 1))\n",
      "((2198,), (2198, 1))\n",
      "((4397,), (4397, 1))\n",
      "((2197,), (2197, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.89878763,  0.89957711,  0.90915808])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)\n",
    "    return roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "cross_val_score(pl, train_total.Comment, train_total.Insult, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "l = nltk.pos_tag(word_tokenize(comments[1]))\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "class FeatureExtractor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        with open('bad_words.txt') as f:\n",
    "            self.badwords = set(w.strip() for w in f.readlines())\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_transform(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.fit_transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "\n",
    "        pos_tags = [\"VB\", \"JJ\", \"RB\", \"NN\"]\n",
    "        def pos_tag_count(comment):\n",
    "            pos = nltk.pos_tag(word_tokenize(comment))\n",
    "            d = {}\n",
    "            for tag in pos_tags:\n",
    "                d[tag] = 0\n",
    "            for p in pos:\n",
    "                for tag in pos_tags:\n",
    "                    if p[1].startswith(tag):\n",
    "                        d[tag] += 1\n",
    "            return d.values()\n",
    "    \n",
    "        def bad_word_count(comment):\n",
    "            comment = \" \".join([wordnet_lemmatizer.lemmatize(wordnet_lemmatizer.lemmatize(w, pos='v')) \n",
    "                          for w in comment.split()])\n",
    "            cnt = 0\n",
    "            for w in comment.split():\n",
    "                if w.strip() in self.badwords:\n",
    "                    cnt += 1\n",
    "            return cnt\n",
    "        \n",
    "        comments_features = []\n",
    "        for c in X:\n",
    "            #features = pos_tag_count(c)\n",
    "            #features.append(bad_word_count(c))\n",
    "            features = [bad_word_count(c)]\n",
    "            comments_features.append(features)\n",
    "        \n",
    "        ret = sparse.csr_matrix(comments_features)\n",
    "        print(X.shape, ret.shape)\n",
    "        return ret\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6594,), (6594, 1))\n"
     ]
    }
   ],
   "source": [
    "bw_feature = fe.fit_transform(train_total.Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2abb58d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bw_feature.todense())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i really don t understand your point \\\\xa0 It seems that you are mixing apples and oranges'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter([i[1] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'CC': 1,\n",
       "         'IN': 1,\n",
       "         'JJ': 1,\n",
       "         'NN': 3,\n",
       "         'NNS': 2,\n",
       "         'PRP': 2,\n",
       "         'PRP$': 1,\n",
       "         'RB': 1,\n",
       "         'VB': 1,\n",
       "         'VBG': 1,\n",
       "         'VBP': 2,\n",
       "         'VBZ': 1})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/amir/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89708135,  0.89404637,  0.90332566])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pl, train_total_clean.Comment, train_total_clean.Insult, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4396,), (4396, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((2198,), (2198, 1))\n",
      "((2197,), (2197, 1))\n",
      "((2199,), (2199, 1))\n",
      "((2199,), (2199, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((2198,), (2198, 1))\n",
      "((2197,), (2197, 1))\n",
      "((2198,), (2198, 1))\n",
      "((2199,), (2199, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((2197,), (2197, 1))\n",
      "((2199,), (2199, 1))\n",
      "((2198,), (2198, 1))\n",
      "((2197,), (2197, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((2199,), (2199, 1))\n",
      "((2198,), (2198, 1))\n",
      "((2197,), (2197, 1))\n",
      "((4395,), (4395, 1))\n",
      "((4396,), (4396, 1))\n",
      "((4397,), (4397, 1))\n",
      "((6594,), (6594, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('fu', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('fe', FeatureExtractor()), ('tfidv_char', TfidfVectorizer(analyzer='char', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=No...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'clf__C': array([   0.1    ,    0.56234,    3.16228,   17.78279,  100.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function scoring at 0x7fb2aaa21410>, verbose=0)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {'clf__C':np.logspace(-1, 2, 5)}\n",
    "gs = GridSearchCV(pl, param_grid, scoring=scoring, n_jobs=4)\n",
    "gs.fit(train_total.Comment, train_total.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 17.782794100389228}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False], 'min_samples_leaf': [1, 2, 4], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'min_samples_split': [2, 5, 10], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [True, False],\n",
       " 'max_depth': [10, 20],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'n_estimators': [200, 400]}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20],#, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400],#, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "estimators = [('vec', tfidv), ('clf', clf_rf)]\n",
    "pl = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = dict([('clf__%s' % k,v) for k,v in random_grid.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4320 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-3523b780202c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInsult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#param_grid = {\"clf__%s\"%k, v for k, v in random_grid}\n",
    "\n",
    "gs = GridSearchCV(pl, param_grid, scoring=scoring, n_jobs=4, verbose=True)\n",
    "gs.fit(train_total.Comment, train_total.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SelectPercentile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3aa85d906e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectPercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m countvect_char = TfidfVectorizer(ngram_range=(1, 5),\n\u001b[1;32m      4\u001b[0m         analyzer=\"char\", binary=False)\n\u001b[1;32m      5\u001b[0m \u001b[0mbadwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBadWordCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SelectPercentile' is not defined"
     ]
    }
   ],
   "source": [
    "select = SelectPercentile(score_func=chi2, percentile=18)\n",
    "clf = LogisticRegression(tol=1e-8, penalty='l2', C=7)\n",
    "countvect_char = TfidfVectorizer(ngram_range=(1, 5),\n",
    "        analyzer=\"char\", binary=False)\n",
    "badwords = BadWordCounter()\n",
    "ft = FeatureStacker([(\"badwords\", badwords), (\"chars\", countvect_char), ])\n",
    "char_model = Pipeline([('vect', ft), ('select', select), ('logr', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "l = nltk.pos_tag(word_tokenize(comments[1]))\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "s1 = \" \".join([wordnet_lemmatizer.lemmatize(wordnet_lemmatizer.lemmatize(w, pos='v')) for w in s.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'i', 'NN'),\n",
       " (u'really', 'RB'),\n",
       " (u'don', 'JJ'),\n",
       " (u't', 'NN'),\n",
       " (u'understand', 'VB'),\n",
       " (u'your', 'PRP$'),\n",
       " (u'point', 'NN'),\n",
       " (u'\\\\xa0', 'VBP'),\n",
       " (u'It', 'PRP'),\n",
       " (u'seem', 'VBP'),\n",
       " (u'that', 'IN'),\n",
       " (u'you', 'PRP'),\n",
       " (u'be', 'VB'),\n",
       " (u'mix', 'VBN'),\n",
       " (u'apple', 'NN'),\n",
       " (u'and', 'CC'),\n",
       " (u'orange', 'NN')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what in the fdafasdfasdkkkkkkkkkkkkkkkkkkkkkkkkkkkkk'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([wordnet_lemmatizer.lemmatize(wordnet_lemmatizer.lemmatize(w, pos='v')) for w in s2.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fdfdfdf'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(r\"(.)\\1{2,}\")\n",
    "re.compile(r\"(.)\\1{2,}\").sub(\"\\g<1>\", \"fdfdfdffffffff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
