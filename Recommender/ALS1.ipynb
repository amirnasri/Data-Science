{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::1193::5::978300760\r\n",
      "1::661::3::978302109\r\n",
      "1::914::3::978301968\r\n",
      "1::3408::4::978300275\r\n",
      "1::2355::5::978824291\r\n",
      "1::1197::3::978302268\r\n",
      "1::1287::5::978302039\r\n",
      "1::2804::5::978300719\r\n",
      "1::594::4::978302268\r\n",
      "1::919::4::978301368\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 ml-1m/ratings.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter=\"::\", engine=\"python\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns = [\"UserID::MovieID::Rating::Timestamp\".split(\"::\")]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID       0\n",
       "MovieID      0\n",
       "Rating       0\n",
       "Timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(ratings['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do we have any duplicate ratings, i.e., a (userid, movieid) combination that is repeated more than once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_movie_pairs = zip(ratings['UserID'].values, ratings['MovieID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209 1000209\n"
     ]
    }
   ],
   "source": [
    "print len(user_movie_pairs), len(set(user_movie_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ..., 6038 6039 6040]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ratings['UserID'].unique()\n",
    "set(ratings['UserID'].unique()) == set(range(1, 6041))\n",
    "# User ids are range(1, 6041), i.e., are all values between 1 and 6040\n",
    "# We can use a simple mapping: user_index=UserID-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::Toy Story (1995)::Animation|Children's|Comedy\r\n",
      "2::Jumanji (1995)::Adventure|Children's|Fantasy\r\n",
      "3::Grumpier Old Men (1995)::Comedy|Romance\r\n",
      "4::Waiting to Exhale (1995)::Comedy|Drama\r\n",
      "5::Father of the Bride Part II (1995)::Comedy\r\n",
      "6::Heat (1995)::Action|Crime|Thriller\r\n",
      "7::Sabrina (1995)::Comedy|Romance\r\n",
      "8::Tom and Huck (1995)::Adventure|Children's\r\n",
      "9::Sudden Death (1995)::Action\r\n",
      "10::GoldenEye (1995)::Action|Adventure|Thriller\r\n"
     ]
    }
   ],
   "source": [
    "!head ml-1m/movies.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies.MovieID) == len(movies.MovieID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following movie id's are missing from movie table\n",
      "[91, 221, 323, 622, 646, 677, 686, 689, 740, 817, 883, 995, 1048, 1072, 1074, 1182, 1195, 1229, 1239, 1338, 1402, 1403, 1418, 1435, 1451, 1452, 1469, 1478, 1481, 1491, 1492, 1505, 1506, 1512, 1521, 1530, 1536, 1540, 1560, 1576, 1607, 1618, 1634, 1637, 1638, 1691, 1700, 1712, 1736, 1737, 1745, 1751, 1761, 1763, 1766, 1775, 1778, 1786, 1790, 1800, 1802, 1803, 1808, 1813, 1818, 1823, 1828, 1838, 3815]\n",
      "\n",
      "[51, 91, 109, 115, 143, 221, 284, 285, 323, 395, 399, 400, 403, 604, 620, 622, 625, 629, 636, 646, 654, 675, 676, 677, 683, 686, 689, 693, 699, 713, 721, 723, 727, 738, 739, 740, 752, 768, 770, 772, 773, 777, 794, 795, 797, 812, 816, 817, 819, 822, 825, 845, 855, 856, 857, 871, 873, 883, 890, 894, 979, 983, 995, 1001, 1045, 1048, 1052, 1065, 1072, 1074, 1075, 1106, 1108, 1109, 1110, 1122, 1137, 1140, 1141, 1143, 1146, 1155, 1156, 1157, 1158, 1159, 1166, 1182, 1195, 1229, 1239, 1308, 1309, 1314, 1318, 1319, 1338, 1368, 1400, 1402, 1403, 1418, 1424, 1435, 1443, 1448, 1451, 1452, 1462, 1467, 1469, 1478, 1481, 1491, 1492, 1505, 1506, 1512, 1521, 1524, 1530, 1536, 1540, 1557, 1559, 1560, 1568, 1576, 1577, 1578, 1607, 1618, 1628, 1634, 1637, 1638, 1691, 1697, 1698, 1700, 1705, 1706, 1708, 1710, 1712, 1716, 1723, 1736, 1737, 1738, 1740, 1742, 1745, 1751, 1757, 1761, 1763, 1765, 1766, 1768, 1774, 1775, 1776, 1778, 1781, 1786, 1789, 1790, 1800, 1802, 1803, 1808, 1813, 1818, 1819, 1823, 1828, 1838, 1847, 2030, 2199, 2216, 2220, 2222, 2224, 2225, 2228, 2229, 2230, 2270, 2274, 2319, 2489, 2508, 2547, 2564, 2588, 2595, 2601, 2603, 2604, 2680, 2684, 2698, 2832, 2838, 2910, 2954, 2957, 2958, 2980, 3009, 3023, 3059, 3080, 3170, 3191, 3193, 3195, 3226, 3227, 3231, 3234, 3278, 3279, 3332, 3348, 3356, 3369, 3383, 3411, 3455, 3541, 3558, 3560, 3561, 3582, 3583, 3589, 3630, 3650, 3750, 3815, 3829, 3856, 3907]\n",
      "[(3873, 3943), (3874, 3944), (3875, 3945), (3876, 3946), (3877, 3947), (3878, 3948), (3879, 3949), (3880, 3950), (3881, 3951), (3882, 3952)]\n",
      "[(3943, 3873), (3944, 3874), (3945, 3875), (3946, 3876), (3947, 3877), (3948, 3878), (3949, 3879), (3950, 3880), (3951, 3881), (3952, 3882)]\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', delimiter='::', engine='python', header=None)\n",
    "movies.columns = 'MovieID::Title::Genres'.split('::')\n",
    "movies.head()\n",
    "\n",
    "print \"The following movie id's are missing from movie table\"\n",
    "print sorted(set(range(1, 3953)) - set(movies.MovieID))\n",
    "print \n",
    "\n",
    "mi = ratings['MovieID'].unique()\n",
    "mi.sort()\n",
    "print sorted(set(range(1, 3953)) - set(mi)) \n",
    "# movie id have some missing values in addition to the missing values above\n",
    "# , i.e., there are movies that are not rated by any user.\n",
    "\n",
    "movie_index_to_ID = dict(zip(range(movies.MovieID.unique().shape[0]), movies.MovieID))\n",
    "#movie_ID_to_index = dict(zip(movies.MovieID, range(movies.MovieID.unique().shape[0])))\n",
    "movie_ID_to_index = {k: v for v, k in movie_index_to_ID.iteritems()}\n",
    "\n",
    "print movie_index_to_ID.items()[-10:]\n",
    "print movie_ID_to_index.items()[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "row = ratings['MovieID'].values\n",
    "col = ratings['UserID'].values\n",
    "data = ratings['Rating'].values\n",
    "ratings_array = csr_matrix((data, (row, col)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3953, 6041)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ratings_array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=5, init='random', random_state=0)\n",
    "W = model.fit_transform(ratings_array) \n",
    "H = model.components_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6041)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = ratings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trace_dot(X, Y):\n",
    "    \"\"\"Trace of np.dot(X, Y.T).\"\"\"\n",
    "    return np.dot(X.ravel(), Y.ravel())\n",
    "norm_X = np.dot(X.data, X.data)\n",
    "norm_WH = trace_dot(np.dot(np.dot(W.T, W), H), H)\n",
    "cross_prod = trace_dot((X * H.T), W)\n",
    "error = np.sqrt(norm_X + norm_WH - 2. * cross_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012841350131919519"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error/X.shape[0]/X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MF.calculate_learning_curve(ratings.values[:100, :120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "conf = SparkConf() \\\n",
    "        .setAppName(\"MovieLensALS\") \\\n",
    "        .set(\"spark.executor.memory\", \"1g\")\n",
    "sc = SparkContext(conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sc.setLogLevel(\"WARN\")\n",
    "\n",
    "def parse_data(line):\n",
    "    fields = line.split(\"::\")\n",
    "    tup =  (int(fields[0]), int(fields[1]), float(fields[2]), int(fields[3][-1]))\n",
    "    return tup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "1\n",
      "\n",
      "33\n",
      "2\n",
      "\n",
      "33\n",
      "3\n",
      "\n",
      "33\n",
      "4\n",
      "\n",
      "33\n",
      "5\n",
      "\n",
      "28\n",
      "6\n",
      "\n",
      "28\n",
      "7\n",
      "\n",
      "28\n",
      "8\n",
      "\n",
      "28\n",
      "9\n",
      "\n",
      "28\n",
      "10\n",
      "\n",
      "39\n",
      "11\n",
      "\n",
      "39\n",
      "12\n",
      "\n",
      "39\n",
      "13\n",
      "\n",
      "39\n",
      "14\n",
      "\n",
      "39\n",
      "15\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Evaluator instance has no attribute 'isLargerBetter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-203d80e39d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Run cross-validation, and choose the best set of parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amir/git/ds/Recommender/pyspark/ml/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/home/amir/git/ds/Recommender/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnFolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mbestIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Evaluator instance has no attribute 'isLargerBetter'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, np.logspace(-2, 2, 5)) \\\n",
    "    .build()\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "class Evaluator:\n",
    "    def evaluate(self, dataset):\n",
    "        global cnt\n",
    "        cnt += 1\n",
    "        print dataset.count()\n",
    "        print cnt\n",
    "        #print dataset['features'].collect()\n",
    "        #print dataset['label']\n",
    "        print\n",
    "        return 1\n",
    "    \n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(),\n",
    "                          evaluator=Evaluator(),\n",
    "                          numFolds=3)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='featuresCol', doc='features column name.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='fitIntercept', doc='whether to fit an intercept term.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='labelCol', doc='label column name.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='maxIter', doc='max number of iterations (>= 0).'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='predictionCol', doc='prediction column name.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='regParam', doc='regularization parameter (>= 0).'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='standardization', doc='whether to standardize the training features before fitting the model.'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='thresholds', doc=\"Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold.\"),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'),\n",
       " Param(parent=u'LogisticRegression_493d9d098c33c544652c', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "spark_home = os.environ['SPARK_HOME']\n",
    "training = spark.read.format(\"libsvm\").load(os.path.join(spark_home, \"data/mllib/sample_libsvm_data.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
