{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "credentials = pd.read_csv('credentials.csv')\n",
    "consumer_key = credentials['consumer_key'][0]\n",
    "consumer_secret = credentials['consumer_secret'][0]\n",
    "access_token = credentials['access_token'][0]\n",
    "access_secret = credentials['access_secret'][0]\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Simpsons_tweets: https://t.co/vg9Xo0pzqb\n",
      "Love #HeritageMinutes.  This is a great one!  Not crying at all.... https://t.co/Y4UJVstgTg\n",
      "test\n",
      "RT @LiveGreenTO: Do you live in an apartment, condo or co-op in Toronto? Make a difference by helping to reduce waste in your building by e…\n",
      "Awe the fact that Americans are getting the hashtag #ThanksCanada to trend is making my heart melt.\n",
      "\n",
      "Thanks all. https://t.co/TDWM0LxE6s\n",
      "RT @TwitterBusiness: #How #many #hashtags #is #too #many?\n",
      "\n",
      "https://t.co/xGcgpoHuQC\n",
      "RT @TorontoComms: Green bins are now being piloted in 20 #TOparks Off-Leash Dog Areas to reduce the amount of organic waste in public Blue…\n",
      "Aweeeeee! https://t.co/QWcTun37hB\n",
      "#NoPooinBlue https://t.co/jELSoiZjX8\n",
      "RT @TOAnimalService: Here's Potter with an important message: put dog poop in Green Bins in #TOparks. The City is piloting the use of Green…\n"
     ]
    }
   ],
   "source": [
    "for status in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_tweets = api.user_timeline(screen_name = \"amnasri2\",count=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_api',\n",
       " '_json',\n",
       " 'author',\n",
       " 'contributors',\n",
       " 'coordinates',\n",
       " 'created_at',\n",
       " 'destroy',\n",
       " 'entities',\n",
       " 'favorite',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'parse',\n",
       " 'parse_list',\n",
       " 'place',\n",
       " 'retweet',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'retweets',\n",
       " 'source',\n",
       " 'source_url',\n",
       " 'text',\n",
       " 'truncated',\n",
       " 'user']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(my_tweets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaster Words:\n",
    "\n",
    "Obtain disaster words from emdat website: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "r  = requests.get(\"https://www.emdat.be/classification\", verify=False)\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data, \"html\")\n",
    "tbody_list = soup.find_all('tbody')\n",
    "\n",
    "td_list = []\n",
    "for tbody in tbody_list:\n",
    "    td_list.extend(tbody.find_all('td'))\n",
    "\n",
    "disaster_words = [td.text.lower() for td in td_list[6:-9] if 1<=len(td.text.split()) <=3]\n",
    "\n",
    "disaster_words = [s.replace('/', ' ').strip() for s in disaster_words]\n",
    "\n",
    "\n",
    "import re\n",
    "disaster_words = set(re.sub('\\s+', ' ', s) for s in disaster_words) - set([u'disaster group',\n",
    " u'disaster subgroup',\n",
    " u'disaster main type',\n",
    " u'disaster sub-type',\n",
    " u'disaster sub-sub-type',])\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#porter_stemmer = PorterStemmer()\n",
    "#set([wordnet_lemmatizer.lemmatize(wordnet_lemmatizer.lemmatize(w, pos='v')) for w in disaster_words]) - disaster_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tweets from tweeter stream from a given location (bounding rectangle) that contain disaster words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ea583f6380d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_db = client.tweets_db.tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client.drop_database('db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': [-73.9685415, 40.780709],\n",
       " 'text': 'Was that @rmlimodriver69 I just seen at the #HallandOates #Train concert? #69 #68'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DuplicateKeyError",
     "evalue": "E11000 duplicate key error collection: tweets_db.tweets index: _id_ dup key: { : ObjectId('5b22fb2e8708dc2fe3c3124b') }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateKeyError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-9c77c071ee7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36minsert_one\u001b[0;34m(self, document, bypass_document_validation, session)\u001b[0m\n\u001b[1;32m    681\u001b[0m             self._insert(document,\n\u001b[1;32m    682\u001b[0m                          \u001b[0mbypass_doc_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbypass_document_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                          session=session),\n\u001b[0m\u001b[1;32m    684\u001b[0m             self.write_concern.acknowledged)\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_insert\u001b[0;34m(self, docs, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[1;32m    597\u001b[0m             return self._insert_one(\n\u001b[1;32m    598\u001b[0m                 \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanipulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                 bypass_doc_val, session)\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_insert_one\u001b[0;34m(self, doc, ordered, check_keys, manipulate, write_concern, op_id, bypass_doc_val, session)\u001b[0m\n\u001b[1;32m    578\u001b[0m             result = self.__database.client._retryable_write(\n\u001b[1;32m    579\u001b[0m                 True, _insert_command, session)\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0m_check_write_command_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pymongo/helpers.pyc\u001b[0m in \u001b[0;36m_check_write_command_response\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mwrite_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"writeErrors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0m_raise_last_write_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"writeConcernError\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pymongo/helpers.pyc\u001b[0m in \u001b[0;36m_raise_last_write_error\u001b[0;34m(write_errors)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"errmsg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mWriteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"errmsg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateKeyError\u001b[0m: E11000 duplicate key error collection: tweets_db.tweets index: _id_ dup key: { : ObjectId('5b22fb2e8708dc2fe3c3124b') }"
     ]
    }
   ],
   "source": [
    "tweets_db.insert_one(tweets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import numpy as np\n",
    "\n",
    "class MyListener(StreamListener):\n",
    " \n",
    "    def on_data(self, data):\n",
    "        global cnt\n",
    "        try:\n",
    "            tweet = json.loads(data)\n",
    "            tweets_collection.insert_one(tweet)\n",
    "            cnt += 1\n",
    "            if cnt % 1000 == 0:\n",
    "                print(cnt)\n",
    "            if cnt == max_count:\n",
    "                twitter_stream.disconnect()\n",
    "                print(\"done!\")\n",
    "                \n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "client = MongoClient()\n",
    "client.tweets_db.drop_collection('tweets')\n",
    "tweets_collection = client.tweets_db.tweets\n",
    "\n",
    "cnt = 0\n",
    "max_count = 10000\n",
    "twitter_stream = Stream(auth=auth, listener=MyListener())\n",
    "GEOBOX_US_CANADA = [-128.755117, 26.415893, -52.437305, 54.093165]\n",
    "twitter_stream.filter(locations=GEOBOX_US_CANADA, async=True)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "client.tweets_db.tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import numpy as np\n",
    "\n",
    "class MyListener(StreamListener):\n",
    " \n",
    "    def on_data(self, data):\n",
    "        global cnt\n",
    "        try:\n",
    "            #print('data: %s' % data)\n",
    "            tweet = json.loads(data)\n",
    "            '''\n",
    "            geo = tweet['geo']\n",
    "            user_location = tweet['user']['location'] \n",
    "            city = None\n",
    "            state = None\n",
    "            \n",
    "            try:\n",
    "                second_part = user_location.split(',')[1].lower()\n",
    "                if second_part in states_abbr:\n",
    "                    state = second_part\n",
    "                elif second_part in ['us', 'usa', 'canada']:\n",
    "                    country = second_part\n",
    "                city = user_location.split(',')[0].lower()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            if not geo and not city:\n",
    "                return\n",
    "                    \n",
    "            text = tweet['text']\n",
    "            #print(geo, \"%s, %s\" % (city, state), tweet['coordinates'], tweet['place'])\n",
    "            print(tweet['text'])\n",
    "            print\n",
    "            print(tweet['geo'])\n",
    "            print\n",
    "            print(tweet['coordinates'])\n",
    "            print\n",
    "            '''\n",
    "            coordinates = np.array(tweet['place']['bounding_box']['coordinates'][0]).mean(axis=0)\n",
    "            coordinates = coordinates.tolist()\n",
    "            #coordinates = coordinates.tolist()\n",
    "            #print(\"-----------------------------------------------------\\n\\n\")\n",
    "            \"\"\"\n",
    "            cnt = 0\n",
    "            words = [w.strip().lower() for w in text.split()]\n",
    "            for w in words:\n",
    "                if w in disaster_words:\n",
    "                    cnt += 1\n",
    "            if cnt != 0:\n",
    "                print(text)\n",
    "                print(\"%s\\n\" % cnt)\n",
    "            \"\"\"\n",
    "            \n",
    "            f_coordinates.write(\"%s,%s\\n\" % tuple(coordinates))\n",
    "            text = tweet['text'].encode('utf-8')\n",
    "            f_tweets.write(text)\n",
    "            tw = {}\n",
    "            tw['text'] = text\n",
    "            tw['loc'] = coordinates\n",
    "            tweets.append(tw)\n",
    "                \n",
    "            cnt += 1\n",
    "            if cnt % 1000 == 0:\n",
    "                print(cnt)\n",
    "            if cnt == max_count:\n",
    "                twitter_stream.disconnect()\n",
    "                print(\"done!\")\n",
    "                f_coordinates.close()\n",
    "                f_tweets.close()\n",
    "                \n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "\n",
    "f_coordinates = open('coordinates', 'w')\n",
    "f_tweets = open('tweets', 'w')\n",
    "tweets = []\n",
    "cnt = 0\n",
    "max_count = 10000\n",
    "twitter_stream = Stream(auth=auth, listener=MyListener())\n",
    "#twitter_stream.filter(track=['a'], async=True)\n",
    "#GEOBOX_GERMANY = [5.0770049095, 47.2982950435, 15.0403900146, 54.9039819757]\n",
    "GEOBOX_US_CANADA = [-128.755117, 26.415893, -52.437305, 54.093165]\n",
    "#twitter_stream.filter(locations=GEOBOX_GERMANY, async=True)\n",
    "#twitter_stream.filter(locations=[-6.38,49.87,1.77,55.81], async=True)\n",
    "twitter_stream.filter(locations=GEOBOX_US_CANADA, async=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_stream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you know the 9 letter encryption on the yellow frog sticker, you get to choose the next encrypted message on the next sticker | Joplin, MO\n",
      "\n",
      "\n",
      "it was a blessing to do both https://t.co/dsHCHboYqy | Washington, DC\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api = tweepy.API(auth)\n",
    "places = api.geo_search(query=\"USA\", granularity=\"country\", max_results=20)\n",
    "place_id = places[0].id\n",
    "\n",
    "tweets = api.search(q=\"place:%s\" % place_id)\n",
    "for tweet in tweets:\n",
    "    print tweet.text + \" | \" + (tweet.place.full_name if tweet.place else \"Undefined place\") + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmap.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmplot\n",
    "output_html = \"my_map.html\"\n",
    "apikey = \"AIzaSyAaN6JdzBYDQuN_P8U3xjAsg4V4GwSvB6Y\"\n",
    "center_long = (GEOBOX_US_CANADA[0] + GEOBOX_US_CANADA[2])/2\n",
    "center_lat = (GEOBOX_US_CANADA[1] + GEOBOX_US_CANADA[3])/2\n",
    "gmap = gmplot.GoogleMapPlotter(center_lat, center_long, 4, apikey=apikey)\n",
    "# Polygon\n",
    "golden_gate_park_lats, golden_gate_park_lons = zip(*[\n",
    "    (37.771269, -122.511015),\n",
    "    (37.773495, -122.464830),\n",
    "    (37.774797, -122.454538),\n",
    "    (37.771988, -122.454018),\n",
    "    (37.773646, -122.440979),\n",
    "    (37.772742, -122.440797),\n",
    "    (37.771096, -122.453889),\n",
    "    (37.768669, -122.453518),\n",
    "    (37.766227, -122.460213),\n",
    "    (37.764028, -122.510347),\n",
    "    (37.771269, -122.511015)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "#gmap.plot(golden_gate_park_lats, golden_gate_park_lons, 'cornflowerblue', edge_width=10)\n",
    "#gmap.heatmap(golden_gate_park_lats, golden_gate_park_lons, radius=30)\n",
    "\n",
    "\n",
    "locations_longs, locations_lats = zip(*[[-97.662618, 27.578509], \n",
    "                                        [-97.662618, 27.895793], \n",
    "                                        [-97.202232, 27.895793], \n",
    "                                        [-97.202232, 27.578509]])\n",
    "\n",
    "#locations_longs, locations_lats = zip(*pd.read_csv('coordinates', header=None).values.tolist())\n",
    "\n",
    "coordinates_list = []\n",
    "for tw in tweets_collection.find():\n",
    "    try:\n",
    "        coordinates = np.array(tw['place']['bounding_box']['coordinates'][0]).mean(axis=0)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    coordinates_list.append(coordinates.tolist())\n",
    "\n",
    "locations_longs, locations_lats = zip(*coordinates_list)\n",
    "\n",
    "\n",
    "#gmap.plot(locations_lats, locations_longs, 'cornflowerblue', edge_width=10)\n",
    "gmap.heatmap(locations_lats, locations_longs, radius=30)\n",
    "\n",
    "\"\"\"\n",
    "# Scatter points\n",
    "top_attraction_lats, top_attraction_lons = zip(*[\n",
    "    (37.769901, -122.498331),\n",
    "    (37.768645, -122.475328),\n",
    "    (37.771478, -122.468677),\n",
    "    (37.769867, -122.466102),\n",
    "    (37.767187, -122.467496),\n",
    "    (37.770104, -122.470436)\n",
    "    ])\n",
    "gmap.scatter(top_attraction_lats, top_attraction_lons, '#3B0B39', size=40, marker=False)\n",
    "\n",
    "# Marker\n",
    "hidden_gem_lat, hidden_gem_lon = 37.770776, -122.461689\n",
    "gmap.marker(hidden_gem_lat, hidden_gem_lon, 'cornflowerblue')\n",
    "\"\"\"\n",
    "\n",
    "# Draw\n",
    "gmap.draw(output_html)\n",
    "\n",
    "import os\n",
    "os.system(\"cp %s /var/www/html\" % output_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gmplot\n",
    "import os\n",
    "\n",
    "def plot_map(coordinates_list):\n",
    "    output_html = \"my_map.html\"\n",
    "    apikey = \"AIzaSyAaN6JdzBYDQuN_P8U3xjAsg4V4GwSvB6Y\"\n",
    "    center_long = (GEOBOX_US_CANADA[0] + GEOBOX_US_CANADA[2])/2\n",
    "    center_lat = (GEOBOX_US_CANADA[1] + GEOBOX_US_CANADA[3])/2\n",
    "    gmap = gmplot.GoogleMapPlotter(center_lat, center_long, 4, apikey=apikey)\n",
    "\n",
    "    locations_longs, locations_lats = zip(*coordinates_list)\n",
    "    gmap.scatter(locations_lats, locations_longs, 'cornflowerblue', edge_width=3)\n",
    "    gmap.draw(output_html)\n",
    "\n",
    "    os.system(\"cp %s /var/www/html\" % output_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates_list = tweets_df.iloc[clusters[4]]['coordinates']\n",
    "gmap = gmplot.GoogleMapPlotter(center_lat, center_long, 4, apikey=apikey)\n",
    "locations_longs, locations_lats = zip(*coordinates_list)\n",
    "gmap.scatter(locations_lats, locations_longs, '#3B0B39', size=80, marker=False)\n",
    "gmap.draw(output_html)\n",
    "\n",
    "os.system(\"cp %s /var/www/html\" % output_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinates_list = tweets_df.iloc[clusters[4]]['coordinates']\n",
    "coordinates_arr = np.array(coordinates_list.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244.5207289897558"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((coordinates_arr - coordinates_arr.mean(axis=0))**2, axis=1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277.2363503730319\n",
      "284.26972289828063\n",
      "277.60512634216934\n",
      "290.9394217711046\n",
      "244.5207289897558\n",
      "271.1420478904403\n",
      "265.9798483698981\n",
      "332.13631663905517\n"
     ]
    }
   ],
   "source": [
    "for center in range(km.n_clusters):\n",
    "    coordinates_list = tweets_df.iloc[clusters[center]]['coordinates']\n",
    "    coordinates_arr = np.array(coordinates_list.tolist())\n",
    "    pos_std = np.sum((coordinates_arr - coordinates_arr.mean(axis=0))**2, axis=1).std()\n",
    "    print(pos_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "<meta name=\"viewport\" content=\"initial-scale=1.0, user-scalable=no\" />\n",
       "<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\"/>\n",
       "<title>Google Maps - pygmaps </title>\n",
       "<script type=\"text/javascript\" src=\"https://maps.googleapis.com/maps/api/js?libraries=visualization&sensor=true_or_false&key=AIzaSyAaN6JdzBYDQuN_P8U3xjAsg4V4GwSvB6Y\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "\tfunction initialize() {\n",
       "\t\tvar centerlatlng = new google.maps.LatLng(37.766956, -122.438481);\n",
       "\t\tvar myOptions = {\n",
       "\t\t\tzoom: 13,\n",
       "\t\t\tcenter: centerlatlng,\n",
       "\t\t\tmapTypeId: google.maps.MapTypeId.ROADMAP\n",
       "\t\t};\n",
       "\t\tvar map = new google.maps.Map(document.getElementById(\"map_canvas\"), myOptions);\n",
       "\n",
       "var heatmap_points = [\n",
       "new google.maps.LatLng(7.993561, 53.501976),\n",
       "new google.maps.LatLng(7.993561, 53.637865),\n",
       "new google.maps.LatLng(8.171061, 53.637865),\n",
       "new google.maps.LatLng(8.171061, 53.501976),\n",
       "];\n",
       "\n",
       "var pointArray = new google.maps.MVCArray(heatmap_points);\n",
       "var heatmap;\n",
       "heatmap = new google.maps.visualization.HeatmapLayer({\n",
       "\n",
       "data: pointArray\n",
       "});\n",
       "heatmap.setMap(map);\n",
       "heatmap.set('threshold', 10);\n",
       "heatmap.set('radius', 30);\n",
       "heatmap.set('opacity', 0.600000);\n",
       "heatmap.set('dissipating', true);\n",
       "\t}\n",
       "</script>\n",
       "</head>\n",
       "<body style=\"margin:0px; padding:0px;\" onload=\"initialize()\">\n",
       "\t<div id=\"map_canvas\" style=\"width: 100%; height: 100%;\"></div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "f = open(output_html)\n",
    "s = f.read()\n",
    "display(HTML('<html>\\n<head>\\n<meta name=\"viewport\" content=\"initial-scale=1.0, user-scalable=no\" />\\n<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\"/>\\n<title>Google Maps - pygmaps </title>\\n<script type=\"text/javascript\" src=\"https://maps.googleapis.com/maps/api/js?libraries=visualization&sensor=true_or_false&key=AIzaSyAaN6JdzBYDQuN_P8U3xjAsg4V4GwSvB6Y\"></script>\\n<script type=\"text/javascript\">\\n\\tfunction initialize() {\\n\\t\\tvar centerlatlng = new google.maps.LatLng(37.766956, -122.438481);\\n\\t\\tvar myOptions = {\\n\\t\\t\\tzoom: 13,\\n\\t\\t\\tcenter: centerlatlng,\\n\\t\\t\\tmapTypeId: google.maps.MapTypeId.ROADMAP\\n\\t\\t};\\n\\t\\tvar map = new google.maps.Map(document.getElementById(\"map_canvas\"), myOptions);\\n\\nvar heatmap_points = [\\nnew google.maps.LatLng(7.993561, 53.501976),\\nnew google.maps.LatLng(7.993561, 53.637865),\\nnew google.maps.LatLng(8.171061, 53.637865),\\nnew google.maps.LatLng(8.171061, 53.501976),\\n];\\n\\nvar pointArray = new google.maps.MVCArray(heatmap_points);\\nvar heatmap;\\nheatmap = new google.maps.visualization.HeatmapLayer({\\n\\ndata: pointArray\\n});\\nheatmap.setMap(map);\\nheatmap.set(\\'threshold\\', 10);\\nheatmap.set(\\'radius\\', 30);\\nheatmap.set(\\'opacity\\', 0.600000);\\nheatmap.set(\\'dissipating\\', true);\\n\\t}\\n</script>\\n</head>\\n<body style=\"margin:0px; padding:0px;\" onload=\"initialize()\">\\n\\t<div id=\"map_canvas\" style=\"width: 100%; height: 100%;\"></div>\\n</body>\\n</html>\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.compile(r\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('states_abbr.txt')\n",
    "states_abbr = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  127  9233 69508 tweets\r\n"
     ]
    }
   ],
   "source": [
    "!wc tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Mentors Muses and Celebrities \\nDRIVE\\nLouie, Louis\\n\\nContemporary Art Museum St. Louis  \\nArt Up Late https://t.co/PvHFarRzUT'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_collection.find().next()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidv_word = TfidfVectorizer(ngram_range=(1, 3), analyzer='word', stop_words='english', min_df=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_id = []\n",
    "tweets_text = []\n",
    "tweets_coordinates = []\n",
    "\n",
    "for tw in tweets_collection.find():\n",
    "    try:\n",
    "        tid = tw['_id']\n",
    "        text = tw['text']\n",
    "        c = np.array(tw['place']['bounding_box']['coordinates'][0]).mean(axis=0)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    tweets_id.append(tid)\n",
    "    tweets_text.append(text)\n",
    "    tweets_coordinates.append(c.tolist())\n",
    "\n",
    "tweets_df = pd.DataFrame({'id': tweets_id, \n",
    "                          'text': tweets_text,\n",
    "                          'coordinates': tweets_coordinates\n",
    "                         })\n",
    "tweets_df = tweets_df[['id', 'text', 'coordinates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_text_vec = tfidv_word.fit_transform(tweets_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=8, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(tweets_text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00040532, 0.00021029, 0.00026364, ..., 0.00039316, 0.00037022,\n",
       "        0.00026133],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00262093, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9985, 4232)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 0, ..., 0, 5, 0], dtype=int32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "tweet_index = np.arange(len(tweets_text))\n",
    "for center in range(km.n_clusters):\n",
    "    clusters[center] = tweet_index[km.labels_ == center]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([  12,   61,   71,   80,   90,  151,  192,  197,  229,  241,  257,\n",
       "         286,  316,  340,  424,  484,  499,  508,  518,  575,  581,  595,\n",
       "         607,  612,  638,  654,  670,  673,  699,  705,  789,  824,  904,\n",
       "         907,  934,  949,  974, 1009, 1067, 1074, 1085, 1148, 1154, 1160,\n",
       "        1181, 1221, 1255, 1259, 1310, 1312, 1340, 1379, 1424, 1461, 1476,\n",
       "        1490, 1502, 1545, 1563, 1624, 1625, 1652, 1665, 1703, 1764, 1785,\n",
       "        1829, 1903, 2045, 2060, 2068, 2097, 2125, 2155, 2169, 2202, 2231,\n",
       "        2251, 2260, 2315, 2324, 2326, 2399, 2465, 2559, 2564, 2588, 2632,\n",
       "        2725, 2728, 2732, 2844, 2912, 2918, 2947, 2954, 2961, 2967, 2984,\n",
       "        3075, 3132, 3151, 3172, 3233, 3287, 3291, 3296, 3310, 3321, 3355,\n",
       "        3364, 3399, 3405, 3417, 3451, 3458, 3500, 3533, 3601, 3634, 3726,\n",
       "        3815, 3825, 3845, 3889, 3937, 3983, 4087, 4162, 4172, 4213, 4214,\n",
       "        4215, 4278, 4320, 4330, 4421, 4451, 4517, 4564, 4574, 4575, 4702,\n",
       "        4776, 4794, 4796, 4799, 4804, 4851, 4854, 4863, 4876, 4877, 4943,\n",
       "        4964, 4988, 5024, 5076, 5088, 5183, 5194, 5221, 5248, 5250, 5288,\n",
       "        5294, 5350, 5356, 5382, 5396, 5424, 5443, 5477, 5518, 5525, 5553,\n",
       "        5557, 5568, 5659, 5669, 5723, 5764, 5801, 5821, 5830, 5837, 5839,\n",
       "        5864, 5866, 5934, 5935, 5939, 5944, 6010, 6016, 6027, 6029, 6039,\n",
       "        6049, 6082, 6140, 6151, 6155, 6156, 6169, 6171, 6172, 6209, 6229,\n",
       "        6246, 6325, 6444, 6454, 6507, 6555, 6574, 6603, 6651, 6724, 6726,\n",
       "        6753, 6859, 6925, 6932, 6981, 7035, 7079, 7083, 7084, 7129, 7173,\n",
       "        7183, 7207, 7213, 7216, 7218, 7244, 7250, 7292, 7299, 7311, 7339,\n",
       "        7350, 7359, 7369, 7439, 7453, 7458, 7476, 7480, 7491, 7500, 7574,\n",
       "        7582, 7586, 7615, 7671, 7749, 7767, 7779, 7814, 7840, 7895, 7939,\n",
       "        7945, 7968, 7986, 8008, 8039, 8065, 8095, 8101, 8103, 8110, 8111,\n",
       "        8147, 8174, 8180, 8186, 8226, 8229, 8240, 8243, 8257, 8266, 8282,\n",
       "        8297, 8313, 8318, 8362, 8471, 8475, 8484, 8559, 8634, 8639, 8647,\n",
       "        8655, 8658, 8659, 8690, 8725, 8780, 8834, 8840, 8846, 8852, 8920,\n",
       "        8952, 8954, 8967, 9011, 9101, 9126, 9160, 9235, 9309, 9321, 9344,\n",
       "        9355, 9395, 9409, 9438, 9443, 9477, 9523, 9554, 9644, 9650, 9684,\n",
       "        9686, 9692, 9737, 9738, 9814, 9830, 9871, 9907, 9926, 9947, 9952,\n",
       "        9975]),\n",
       " 1: array([  35,   64,  370,  493,  533,  620,  708,  792,  810,  816,  880,\n",
       "         889,  945,  980, 1155, 1183, 1211, 1398, 1460, 1592, 1609, 1706,\n",
       "        1748, 1865, 1892, 1914, 1938, 1950, 2224, 2276, 2309, 2313, 2387,\n",
       "        2418, 2451, 2467, 2471, 2491, 2493, 2494, 2512, 2624, 2625, 2754,\n",
       "        2878, 3178, 3189, 3237, 3284, 3340, 3392, 3528, 3642, 3647, 3669,\n",
       "        3824, 3843, 3854, 3929, 3950, 3971, 4066, 4085, 4104, 4138, 4315,\n",
       "        4482, 4483, 4485, 4536, 4550, 4619, 4711, 4748, 4824, 4980, 5068,\n",
       "        5073, 5128, 5159, 5182, 5211, 5249, 5295, 5301, 5341, 5377, 5380,\n",
       "        5431, 5502, 5693, 5757, 5800, 5816, 5903, 5949, 5986, 6022, 6165,\n",
       "        6179, 6268, 6283, 6358, 6398, 6401, 6497, 6502, 6536, 6599, 6800,\n",
       "        6860, 6928, 7004, 7074, 7152, 7263, 7274, 7374, 7433, 7493, 7499,\n",
       "        7509, 7551, 7583, 7608, 7632, 7659, 7711, 7729, 7812, 7932, 7989,\n",
       "        8109, 8210, 8247, 8396, 8492, 8648, 8727, 8737, 8748, 8775, 8785,\n",
       "        8809, 8850, 8987, 9093, 9251, 9265, 9271, 9278, 9288, 9424, 9473,\n",
       "        9752, 9858]),\n",
       " 2: array([   1,    4,   21,   32,   36,   58,   59,   72,   97,  110,  120,\n",
       "         171,  194,  201,  205,  207,  208,  212,  225,  227,  246,  278,\n",
       "         288,  306,  325,  334,  349,  397,  429,  435,  442,  445,  447,\n",
       "         455,  472,  534,  568,  570,  573,  580,  599,  628,  669,  675,\n",
       "         684,  700,  701,  702,  717,  722,  725,  755,  763,  793,  811,\n",
       "         843,  851,  858,  886,  931,  947,  969,  981,  997, 1019, 1026,\n",
       "        1031, 1037, 1056, 1062, 1109, 1110, 1119, 1175, 1176, 1177, 1192,\n",
       "        1205, 1225, 1228, 1244, 1268, 1277, 1290, 1316, 1335, 1337, 1356,\n",
       "        1373, 1376, 1380, 1388, 1391, 1402, 1405, 1406, 1418, 1434, 1437,\n",
       "        1440, 1467, 1469, 1497, 1498, 1539, 1572, 1580, 1590, 1622, 1629,\n",
       "        1677, 1686, 1693, 1695, 1713, 1715, 1716, 1730, 1735, 1746, 1752,\n",
       "        1758, 1759, 1767, 1779, 1803, 1835, 1866, 1876, 1891, 1900, 1901,\n",
       "        1941, 1953, 1955, 1959, 1970, 1976, 1996, 1999, 2014, 2024, 2047,\n",
       "        2094, 2110, 2157, 2165, 2166, 2167, 2183, 2186, 2210, 2219, 2221,\n",
       "        2229, 2230, 2271, 2277, 2296, 2310, 2314, 2316, 2325, 2330, 2345,\n",
       "        2349, 2373, 2397, 2403, 2406, 2434, 2435, 2443, 2460, 2472, 2482,\n",
       "        2511, 2518, 2519, 2557, 2581, 2591, 2612, 2630, 2633, 2662, 2666,\n",
       "        2673, 2678, 2718, 2731, 2742, 2750, 2756, 2758, 2780, 2798, 2802,\n",
       "        2805, 2813, 2832, 2840, 2857, 2859, 2862, 2877, 2880, 2887, 2894,\n",
       "        2895, 2903, 2911, 2920, 2921, 2949, 2953, 2985, 2992, 3004, 3037,\n",
       "        3058, 3060, 3066, 3082, 3087, 3097, 3114, 3122, 3126, 3128, 3160,\n",
       "        3181, 3214, 3219, 3229, 3232, 3248, 3251, 3269, 3271, 3275, 3281,\n",
       "        3318, 3320, 3341, 3344, 3345, 3360, 3369, 3381, 3388, 3398, 3415,\n",
       "        3425, 3426, 3467, 3488, 3512, 3558, 3573, 3575, 3599, 3608, 3623,\n",
       "        3628, 3633, 3650, 3671, 3674, 3682, 3692, 3693, 3711, 3718, 3721,\n",
       "        3729, 3732, 3734, 3742, 3753, 3762, 3789, 3830, 3834, 3837, 3852,\n",
       "        3870, 3919, 3941, 3948, 3968, 3982, 3991, 4017, 4034, 4047, 4060,\n",
       "        4061, 4070, 4071, 4088, 4097, 4101, 4108, 4121, 4129, 4151, 4181,\n",
       "        4189, 4202, 4205, 4223, 4241, 4254, 4261, 4265, 4266, 4280, 4286,\n",
       "        4314, 4322, 4325, 4346, 4347, 4360, 4362, 4364, 4368, 4369, 4376,\n",
       "        4384, 4386, 4388, 4402, 4411, 4425, 4449, 4455, 4495, 4520, 4521,\n",
       "        4544, 4572, 4578, 4600, 4604, 4610, 4622, 4625, 4626, 4642, 4667,\n",
       "        4684, 4686, 4691, 4696, 4703, 4713, 4754, 4755, 4774, 4817, 4840,\n",
       "        4845, 4859, 4861, 4896, 4917, 4918, 4947, 5019, 5029, 5054, 5065,\n",
       "        5092, 5106, 5107, 5113, 5138, 5142, 5164, 5168, 5177, 5178, 5208,\n",
       "        5209, 5212, 5224, 5296, 5320, 5332, 5336, 5337, 5369, 5394, 5409,\n",
       "        5450, 5463, 5474, 5476, 5490, 5517, 5520, 5527, 5544, 5551, 5555,\n",
       "        5558, 5562, 5569, 5577, 5602, 5613, 5631, 5635, 5641, 5651, 5662,\n",
       "        5684, 5716, 5720, 5735, 5751, 5789, 5792, 5798, 5818, 5832, 5834,\n",
       "        5835, 5840, 5851, 5858, 5878, 5896, 5904, 5923, 5924, 5941, 6032,\n",
       "        6066, 6067, 6071, 6077, 6103, 6105, 6111, 6124, 6159, 6166, 6170,\n",
       "        6214, 6219, 6220, 6224, 6225, 6227, 6234, 6240, 6241, 6243, 6266,\n",
       "        6289, 6291, 6351, 6378, 6380, 6388, 6406, 6447, 6460, 6466, 6470,\n",
       "        6491, 6499, 6501, 6509, 6520, 6521, 6545, 6546, 6558, 6562, 6641,\n",
       "        6656, 6669, 6697, 6719, 6760, 6776, 6777, 6789, 6801, 6835, 6865,\n",
       "        6867, 6875, 6876, 6888, 6903, 6904, 6912, 6914, 6935, 6938, 6949,\n",
       "        6984, 7001, 7010, 7034, 7036, 7042, 7054, 7055, 7058, 7078, 7090,\n",
       "        7100, 7109, 7124, 7141, 7148, 7153, 7155, 7175, 7178, 7184, 7193,\n",
       "        7202, 7208, 7224, 7233, 7238, 7249, 7261, 7319, 7368, 7372, 7373,\n",
       "        7395, 7407, 7465, 7470, 7473, 7486, 7518, 7540, 7547, 7553, 7565,\n",
       "        7601, 7647, 7665, 7685, 7709, 7713, 7715, 7719, 7722, 7735, 7736,\n",
       "        7743, 7750, 7781, 7785, 7795, 7796, 7835, 7853, 7854, 7872, 7894,\n",
       "        7919, 7920, 7924, 7935, 7958, 7980, 7985, 7996, 7998, 8000, 8002,\n",
       "        8012, 8045, 8080, 8085, 8129, 8161, 8184, 8187, 8201, 8208, 8217,\n",
       "        8251, 8261, 8278, 8321, 8323, 8352, 8353, 8361, 8393, 8400, 8402,\n",
       "        8412, 8422, 8423, 8439, 8446, 8451, 8459, 8476, 8487, 8494, 8501,\n",
       "        8508, 8511, 8512, 8513, 8514, 8525, 8529, 8534, 8536, 8548, 8550,\n",
       "        8567, 8609, 8611, 8617, 8644, 8667, 8675, 8685, 8696, 8720, 8729,\n",
       "        8757, 8798, 8808, 8820, 8838, 8847, 8848, 8861, 8915, 8968, 9000,\n",
       "        9002, 9004, 9045, 9053, 9065, 9078, 9079, 9087, 9110, 9120, 9141,\n",
       "        9169, 9174, 9186, 9212, 9217, 9219, 9249, 9253, 9270, 9297, 9308,\n",
       "        9312, 9327, 9342, 9350, 9352, 9362, 9388, 9394, 9396, 9399, 9404,\n",
       "        9423, 9447, 9461, 9508, 9549, 9552, 9555, 9557, 9561, 9563, 9574,\n",
       "        9597, 9617, 9621, 9624, 9629, 9632, 9651, 9654, 9655, 9665, 9683,\n",
       "        9703, 9709, 9716, 9717, 9726, 9732, 9777, 9780, 9785, 9815, 9821,\n",
       "        9826, 9840, 9844, 9845, 9851, 9859, 9887, 9900, 9905, 9912, 9919,\n",
       "        9957, 9959, 9983]),\n",
       " 3: array([  18,   41,   48,  117,  135,  172,  183,  245,  254,  259,  275,\n",
       "         315,  344,  355,  360,  382,  458,  511,  526,  553,  614,  639,\n",
       "         657,  692,  762,  782,  786,  822,  834,  835,  897,  905,  922,\n",
       "         943,  946,  977, 1018, 1023, 1042, 1077, 1080, 1081, 1122, 1140,\n",
       "        1149, 1189, 1220, 1231, 1272, 1279, 1282, 1324, 1355, 1426, 1482,\n",
       "        1526, 1541, 1591, 1602, 1637, 1659, 1660, 1688, 1699, 1718, 1762,\n",
       "        1781, 1800, 1826, 1859, 1864, 1926, 1937, 2041, 2051, 2057, 2141,\n",
       "        2156, 2159, 2200, 2222, 2298, 2299, 2300, 2312, 2375, 2378, 2412,\n",
       "        2415, 2505, 2527, 2546, 2580, 2601, 2642, 2645, 2657, 2773, 2826,\n",
       "        2847, 2876, 2879, 2889, 2909, 2932, 2935, 2993, 3005, 3039, 3053,\n",
       "        3054, 3124, 3138, 3149, 3180, 3182, 3192, 3201, 3207, 3211, 3240,\n",
       "        3295, 3307, 3374, 3453, 3505, 3516, 3522, 3532, 3543, 3581, 3605,\n",
       "        3645, 3646, 3708, 3722, 3775, 3794, 3857, 3946, 3970, 3996, 4020,\n",
       "        4041, 4053, 4095, 4120, 4168, 4179, 4188, 4198, 4250, 4262, 4298,\n",
       "        4311, 4324, 4435, 4442, 4480, 4500, 4501, 4549, 4593, 4599, 4614,\n",
       "        4630, 4638, 4644, 4650, 4657, 4672, 4715, 4765, 4766, 4793, 4795,\n",
       "        4797, 4807, 4831, 4835, 4843, 4855, 4903, 4927, 4935, 4956, 4975,\n",
       "        5009, 5093, 5096, 5137, 5170, 5180, 5222, 5251, 5255, 5269, 5287,\n",
       "        5307, 5358, 5362, 5366, 5370, 5376, 5401, 5465, 5466, 5479, 5543,\n",
       "        5611, 5689, 5713, 5747, 5781, 5797, 5820, 5852, 5860, 5940, 5964,\n",
       "        6012, 6035, 6038, 6040, 6045, 6060, 6062, 6065, 6107, 6112, 6129,\n",
       "        6139, 6143, 6164, 6252, 6273, 6303, 6312, 6320, 6334, 6367, 6385,\n",
       "        6390, 6403, 6433, 6437, 6463, 6469, 6478, 6616, 6633, 6674, 6689,\n",
       "        6702, 6722, 6755, 6811, 6817, 6836, 6895, 6929, 6947, 6978, 6983,\n",
       "        6992, 7048, 7069, 7116, 7118, 7323, 7355, 7362, 7386, 7388, 7394,\n",
       "        7422, 7442, 7501, 7541, 7549, 7557, 7561, 7566, 7577, 7592, 7634,\n",
       "        7635, 7656, 7664, 7677, 7716, 7731, 7737, 7740, 7748, 7763, 7791,\n",
       "        7798, 7823, 7898, 7913, 7928, 7930, 7934, 7951, 8046, 8060, 8078,\n",
       "        8159, 8219, 8245, 8314, 8328, 8389, 8408, 8477, 8479, 8499, 8527,\n",
       "        8607, 8630, 8649, 8671, 8679, 8683, 8698, 8744, 8763, 8794, 8799,\n",
       "        8803, 8851, 8894, 8912, 8922, 8923, 8936, 8959, 8989, 8991, 8993,\n",
       "        8997, 9012, 9050, 9066, 9098, 9115, 9129, 9168, 9176, 9256, 9261,\n",
       "        9272, 9318, 9324, 9337, 9356, 9359, 9360, 9402, 9412, 9414, 9420,\n",
       "        9432, 9488, 9498, 9501, 9506, 9573, 9630, 9661, 9688, 9721, 9725,\n",
       "        9747, 9753, 9783, 9787, 9789, 9864, 9870, 9875, 9892, 9894, 9928,\n",
       "        9929, 9935, 9943, 9964]),\n",
       " 4: array([   0,    2,    3, ..., 9981, 9982, 9984]),\n",
       " 5: array([ 177,  426,  542,  979, 1010, 1079, 1265, 1387, 1522, 1742, 1772,\n",
       "        1824, 1878, 2177, 2318, 2461, 2707, 2927, 3001, 3099, 3191, 3226,\n",
       "        3258, 3315, 3319, 3606, 3643, 3687, 3705, 3823, 3927, 3985, 4096,\n",
       "        4152, 4232, 4334, 4355, 4889, 5098, 5202, 5229, 5414, 5603, 5645,\n",
       "        5718, 5729, 5776, 5802, 5806, 5828, 5854, 5968, 6059, 6133, 6308,\n",
       "        6349, 6487, 6590, 6734, 6936, 7021, 7025, 7290, 7308, 7324, 7327,\n",
       "        7348, 7353, 7484, 7568, 7628, 7657, 7832, 7923, 7973, 8059, 8108,\n",
       "        8117, 8124, 8133, 8145, 8164, 8449, 8564, 8889, 8902, 8958, 9023,\n",
       "        9040, 9088, 9149, 9283, 9484, 9659, 9677, 9756, 9813]),\n",
       " 6: array([   8,   22,   91,  141,  206,  270,  338,  393,  449,  478,  507,\n",
       "         632,  636,  683,  689,  719,  853,  890,  896,  932,  958, 1060,\n",
       "        1087, 1092, 1102, 1120, 1194, 1202, 1329, 1381, 1385, 1419, 1436,\n",
       "        1485, 1503, 1512, 1557, 1618, 1639, 1647, 1649, 1672, 1673, 1692,\n",
       "        1697, 1705, 1709, 1755, 1791, 1798, 1812, 1884, 1940, 1961, 2042,\n",
       "        2043, 2087, 2111, 2182, 2285, 2304, 2308, 2335, 2369, 2409, 2427,\n",
       "        2476, 2514, 2584, 2616, 2670, 2709, 2772, 2871, 2885, 2941, 3095,\n",
       "        3156, 3164, 3167, 3252, 3273, 3352, 3365, 3414, 3475, 3479, 3546,\n",
       "        3587, 3588, 3617, 3676, 3689, 3712, 3720, 3754, 3757, 3767, 3777,\n",
       "        3790, 3803, 3850, 3891, 3917, 3933, 3954, 4006, 4008, 4076, 4090,\n",
       "        4133, 4176, 4236, 4240, 4269, 4373, 4380, 4390, 4431, 4524, 4528,\n",
       "        4568, 4632, 4714, 4758, 4891, 4899, 4920, 4929, 4933, 4979, 4982,\n",
       "        5006, 5028, 5030, 5053, 5057, 5058, 5063, 5097, 5161, 5245, 5262,\n",
       "        5317, 5328, 5353, 5360, 5526, 5554, 5559, 5594, 5666, 5737, 5740,\n",
       "        5790, 5812, 5875, 5880, 5890, 5905, 6024, 6055, 6123, 6144, 6163,\n",
       "        6180, 6181, 6262, 6330, 6337, 6368, 6422, 6450, 6451, 6456, 6554,\n",
       "        6561, 6588, 6664, 6723, 6782, 6842, 6851, 6921, 6937, 6951, 7006,\n",
       "        7033, 7102, 7110, 7199, 7248, 7251, 7284, 7287, 7424, 7532, 7567,\n",
       "        7572, 7670, 7673, 7890, 7891, 7976, 8014, 8019, 8042, 8089, 8125,\n",
       "        8127, 8197, 8230, 8234, 8237, 8264, 8300, 8302, 8331, 8367, 8371,\n",
       "        8406, 8463, 8593, 8605, 8704, 8769, 8796, 8814, 8903, 8948, 9010,\n",
       "        9031, 9032, 9052, 9114, 9121, 9125, 9150, 9179, 9226, 9227, 9255,\n",
       "        9257, 9303, 9374, 9415, 9453, 9474, 9476, 9495, 9560, 9583, 9631,\n",
       "        9637, 9668, 9674, 9794, 9820, 9906]),\n",
       " 7: array([  88,  170,  174,  249,  267,  319,  329,  359,  366,  501,  644,\n",
       "         685,  767,  808,  812,  838,  874,  927,  960, 1073, 1093, 1146,\n",
       "        1199, 1254, 1300, 1403, 1550, 1585, 1635, 1906, 1962, 1990, 2119,\n",
       "        2149, 2174, 2234, 2320, 2331, 2504, 2537, 2555, 2664, 2682, 2683,\n",
       "        2686, 2744, 2749, 2771, 2827, 3042, 3068, 3120, 3169, 3171, 3221,\n",
       "        3242, 3255, 3262, 3285, 3302, 3359, 3363, 3411, 3418, 3420, 3455,\n",
       "        3462, 3503, 3524, 3590, 3781, 3904, 3923, 3945, 3984, 4003, 4058,\n",
       "        4158, 4264, 4281, 4359, 4385, 4406, 4440, 4444, 4456, 4491, 4498,\n",
       "        4511, 4541, 4577, 4608, 4649, 4809, 4812, 4869, 4875, 4930, 4944,\n",
       "        5062, 5067, 5104, 5206, 5231, 5264, 5506, 5522, 5616, 5652, 5654,\n",
       "        5745, 5758, 5769, 5795, 5811, 5859, 5873, 5911, 5932, 5974, 6196,\n",
       "        6260, 6418, 6522, 6579, 6584, 6632, 6684, 6766, 6791, 6802, 6820,\n",
       "        6852, 6855, 6881, 6930, 7022, 7056, 7094, 7140, 7156, 7163, 7304,\n",
       "        7334, 7347, 7363, 7387, 7495, 7579, 7637, 7641, 7829, 7842, 7844,\n",
       "        7936, 7965, 7977, 7994, 8013, 8203, 8304, 8320, 8404, 8431, 8442,\n",
       "        8474, 8570, 8587, 8645, 8745, 8764, 8813, 8817, 8883, 8896, 8956,\n",
       "        8976, 9022, 9074, 9102, 9111, 9151, 9156, 9191, 9241, 9244, 9298,\n",
       "        9361, 9365, 9448, 9567, 9598, 9761, 9762, 9763, 9779, 9896, 9898,\n",
       "        9901])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinates_list = tweets_df.iloc[clusters[0]]['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_map(coordinates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_stemming(text, stem=True):\n",
    "    result = lemmatizer.lemmatize(text, pos='v')\n",
    "    if stem:\n",
    "        result = stemmer.stem(result)\n",
    "    return result\n",
    "    \n",
    "def preprocess(text):\n",
    "    \n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS \\\n",
    "            and len(token) > 3 and len(token) < 40 \\\n",
    "            and token.isalpha:\n",
    "            result.append(lemmatize_stemming(token, stem=False))\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = [preprocess(tw['text']) for tw in tweets_collection.find()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "https\n",
      "Topic 1:\n",
      "https\n",
      "Topic 2:\n",
      "https\n",
      "Topic 3:\n",
      "https\n",
      "Topic 4:\n",
      "https\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic %d:\" % (topic_idx)\n",
    "        print \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 5\n",
    "\n",
    "# Run NMF\n",
    "#nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=15, learning_method='online', learning_decay=.9, learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 10\n",
    "#display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
